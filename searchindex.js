Search.setIndex({"docnames": ["appendix/acknowledgement", "appendix/adult_census_description", "appendix/datasets_intro", "appendix/glossary", "appendix/notebook_timings", "appendix/toc_redirect", "concluding_remarks", "concluding_remarks_video", "ensemble/bagging_slides", "ensemble/boosting_slides", "ensemble/ensemble_boosting_index", "ensemble/ensemble_bootstrap_index", "ensemble/ensemble_hyperparameters_index", "ensemble/ensemble_module_intro", "ensemble/ensemble_module_take_away", "ensemble/ensemble_quiz_m6_01", "ensemble/ensemble_quiz_m6_02", "ensemble/ensemble_quiz_m6_03", "ensemble/ensemble_wrap_up_quiz", "evaluation/cross_validation_baseline_index", "evaluation/cross_validation_choices_index", "evaluation/cross_validation_nested_index", "evaluation/evaluation_module_intro", "evaluation/evaluation_module_take_away", "evaluation/evaluation_quiz_m7_01", "evaluation/evaluation_quiz_m7_02", "evaluation/evaluation_quiz_m7_03", "evaluation/evaluation_quiz_m7_04", "evaluation/evaluation_quiz_m7_05", "evaluation/evaluation_wrap_up_quiz", "evaluation/metrics_classification_index", "evaluation/metrics_regression_index", "feature_selection/feature_selection_limitation_index", "feature_selection/feature_selection_module_intro", "feature_selection/feature_selection_module_take_away", "feature_selection/feature_selection_quiz", "index", "interpretation/interpretation_quiz", "linear_models/linear_models_intuitions_index", "linear_models/linear_models_module_intro", "linear_models/linear_models_module_take_away", "linear_models/linear_models_non_linear_index", "linear_models/linear_models_quiz_m4_01", "linear_models/linear_models_quiz_m4_02", "linear_models/linear_models_quiz_m4_03", "linear_models/linear_models_quiz_m4_04", "linear_models/linear_models_quiz_m4_05", "linear_models/linear_models_regularization_index", "linear_models/linear_models_slides", "linear_models/linear_models_wrap_up_quiz", "linear_models/regularized_linear_models_slides", "ml_concepts/quiz_intro_01", "ml_concepts/slides", "overfit/bias_vs_variance_quiz_m2_03", "overfit/bias_vs_variance_slides", "overfit/learning_validation_curves_quiz_m2_02", "overfit/learning_validation_curves_slides", "overfit/overfit_bias_variance_index", "overfit/overfit_module_intro", "overfit/overfit_overfitting_underfitting_index", "overfit/overfit_take_away", "overfit/overfit_validation_learning_curves_index", "overfit/overfit_wrap_up_quiz", "overfit/overfitting_vs_under_fitting_quiz_m2_01", "overfit/overfitting_vs_under_fitting_slides", "predictive_modeling_pipeline/01_tabular_data_exploration_index", "predictive_modeling_pipeline/01_tabular_data_exploration_quiz_m1_01", "predictive_modeling_pipeline/02_numerical_pipeline_index", "predictive_modeling_pipeline/02_numerical_pipeline_quiz_m1_02", "predictive_modeling_pipeline/02_numerical_pipeline_video_cross_validation", "predictive_modeling_pipeline/03_categorical_pipeline_index", "predictive_modeling_pipeline/03_categorical_pipeline_quiz_m1_03", "predictive_modeling_pipeline/03_categorical_pipeline_visualization_video", "predictive_modeling_pipeline/predictive_modeling_module_intro", "predictive_modeling_pipeline/predictive_modeling_module_take_away", "predictive_modeling_pipeline/wrap_up_quiz", "python_scripts/01_tabular_data_exploration", "python_scripts/01_tabular_data_exploration_ex_01", "python_scripts/01_tabular_data_exploration_sol_01", "python_scripts/02_numerical_pipeline_cross_validation", "python_scripts/02_numerical_pipeline_ex_00", "python_scripts/02_numerical_pipeline_ex_01", "python_scripts/02_numerical_pipeline_hands_on", "python_scripts/02_numerical_pipeline_introduction", "python_scripts/02_numerical_pipeline_scaling", "python_scripts/02_numerical_pipeline_sol_00", "python_scripts/02_numerical_pipeline_sol_01", "python_scripts/03_categorical_pipeline", "python_scripts/03_categorical_pipeline_column_transformer", "python_scripts/03_categorical_pipeline_ex_01", "python_scripts/03_categorical_pipeline_ex_02", "python_scripts/03_categorical_pipeline_sol_01", "python_scripts/03_categorical_pipeline_sol_02", "python_scripts/03_categorical_pipeline_visualization", "python_scripts/cross_validation_baseline", "python_scripts/cross_validation_ex_01", "python_scripts/cross_validation_ex_02", "python_scripts/cross_validation_grouping", "python_scripts/cross_validation_learning_curve", "python_scripts/cross_validation_nested", "python_scripts/cross_validation_sol_01", "python_scripts/cross_validation_sol_02", "python_scripts/cross_validation_stratification", "python_scripts/cross_validation_time", "python_scripts/cross_validation_train_test", "python_scripts/cross_validation_validation_curve", "python_scripts/datasets_ames_housing", "python_scripts/datasets_bike_rides", "python_scripts/datasets_blood_transfusion", "python_scripts/datasets_california_housing", "python_scripts/dev_features_importance", "python_scripts/ensemble_adaboost", "python_scripts/ensemble_bagging", "python_scripts/ensemble_ex_01", "python_scripts/ensemble_ex_02", "python_scripts/ensemble_ex_03", "python_scripts/ensemble_ex_04", "python_scripts/ensemble_gradient_boosting", "python_scripts/ensemble_hist_gradient_boosting", "python_scripts/ensemble_hyperparameters", "python_scripts/ensemble_introduction", "python_scripts/ensemble_random_forest", "python_scripts/ensemble_sol_01", "python_scripts/ensemble_sol_02", "python_scripts/ensemble_sol_03", "python_scripts/ensemble_sol_04", "python_scripts/feature_selection_ex_01", "python_scripts/feature_selection_introduction", "python_scripts/feature_selection_limitation_model", "python_scripts/feature_selection_sol_01", "python_scripts/linear_models_ex_01", "python_scripts/linear_models_ex_02", "python_scripts/linear_models_ex_03", "python_scripts/linear_models_feature_engineering_classification", "python_scripts/linear_models_regularization", "python_scripts/linear_models_sol_01", "python_scripts/linear_models_sol_02", "python_scripts/linear_models_sol_03", "python_scripts/linear_regression_in_sklearn", "python_scripts/linear_regression_non_linear_link", "python_scripts/linear_regression_without_sklearn", "python_scripts/logistic_regression", "python_scripts/logistic_regression_non_linear", "python_scripts/metrics_classification", "python_scripts/metrics_ex_01", "python_scripts/metrics_ex_02", "python_scripts/metrics_regression", "python_scripts/metrics_sol_01", "python_scripts/metrics_sol_02", "python_scripts/parameter_tuning_ex_02", "python_scripts/parameter_tuning_ex_03", "python_scripts/parameter_tuning_grid_search", "python_scripts/parameter_tuning_manual", "python_scripts/parameter_tuning_nested", "python_scripts/parameter_tuning_parallel_plot", "python_scripts/parameter_tuning_randomized_search", "python_scripts/parameter_tuning_sol_02", "python_scripts/parameter_tuning_sol_03", "python_scripts/trees_classification", "python_scripts/trees_dataset", "python_scripts/trees_ex_01", "python_scripts/trees_ex_02", "python_scripts/trees_hyperparameters", "python_scripts/trees_regression", "python_scripts/trees_sol_01", "python_scripts/trees_sol_02", "toc", "trees/slides", "trees/trees_classification_index", "trees/trees_hyperparameters_index", "trees/trees_intuitions_index", "trees/trees_module_intro", "trees/trees_module_take_away", "trees/trees_quiz_m5_01", "trees/trees_quiz_m5_02", "trees/trees_quiz_m5_03", "trees/trees_quiz_m5_04", "trees/trees_regression_index", "trees/trees_wrap_up_quiz", "tuning/parameter_tuning_automated_index", "tuning/parameter_tuning_automated_quiz_m3_02", "tuning/parameter_tuning_manual_index", "tuning/parameter_tuning_manual_quiz_m3_01", "tuning/parameter_tuning_module_intro", "tuning/parameter_tuning_module_take_away", "tuning/parameter_tuning_parallel_plot_video", "tuning/parameter_tuning_wrap_up_quiz"], "filenames": ["appendix/acknowledgement.md", "appendix/adult_census_description.md", "appendix/datasets_intro.md", "appendix/glossary.md", "appendix/notebook_timings.md", "appendix/toc_redirect.md", "concluding_remarks.md", "concluding_remarks_video.md", "ensemble/bagging_slides.md", "ensemble/boosting_slides.md", "ensemble/ensemble_boosting_index.md", "ensemble/ensemble_bootstrap_index.md", "ensemble/ensemble_hyperparameters_index.md", "ensemble/ensemble_module_intro.md", "ensemble/ensemble_module_take_away.md", "ensemble/ensemble_quiz_m6_01.md", "ensemble/ensemble_quiz_m6_02.md", "ensemble/ensemble_quiz_m6_03.md", "ensemble/ensemble_wrap_up_quiz.md", "evaluation/cross_validation_baseline_index.md", "evaluation/cross_validation_choices_index.md", "evaluation/cross_validation_nested_index.md", "evaluation/evaluation_module_intro.md", "evaluation/evaluation_module_take_away.md", "evaluation/evaluation_quiz_m7_01.md", "evaluation/evaluation_quiz_m7_02.md", "evaluation/evaluation_quiz_m7_03.md", "evaluation/evaluation_quiz_m7_04.md", "evaluation/evaluation_quiz_m7_05.md", "evaluation/evaluation_wrap_up_quiz.md", "evaluation/metrics_classification_index.md", "evaluation/metrics_regression_index.md", "feature_selection/feature_selection_limitation_index.md", "feature_selection/feature_selection_module_intro.md", "feature_selection/feature_selection_module_take_away.md", "feature_selection/feature_selection_quiz.md", "index.md", "interpretation/interpretation_quiz.md", "linear_models/linear_models_intuitions_index.md", "linear_models/linear_models_module_intro.md", "linear_models/linear_models_module_take_away.md", "linear_models/linear_models_non_linear_index.md", "linear_models/linear_models_quiz_m4_01.md", "linear_models/linear_models_quiz_m4_02.md", "linear_models/linear_models_quiz_m4_03.md", "linear_models/linear_models_quiz_m4_04.md", "linear_models/linear_models_quiz_m4_05.md", "linear_models/linear_models_regularization_index.md", "linear_models/linear_models_slides.md", "linear_models/linear_models_wrap_up_quiz.md", "linear_models/regularized_linear_models_slides.md", "ml_concepts/quiz_intro_01.md", "ml_concepts/slides.md", "overfit/bias_vs_variance_quiz_m2_03.md", "overfit/bias_vs_variance_slides.md", "overfit/learning_validation_curves_quiz_m2_02.md", "overfit/learning_validation_curves_slides.md", "overfit/overfit_bias_variance_index.md", "overfit/overfit_module_intro.md", "overfit/overfit_overfitting_underfitting_index.md", "overfit/overfit_take_away.md", "overfit/overfit_validation_learning_curves_index.md", "overfit/overfit_wrap_up_quiz.md", "overfit/overfitting_vs_under_fitting_quiz_m2_01.md", "overfit/overfitting_vs_under_fitting_slides.md", "predictive_modeling_pipeline/01_tabular_data_exploration_index.md", "predictive_modeling_pipeline/01_tabular_data_exploration_quiz_m1_01.md", "predictive_modeling_pipeline/02_numerical_pipeline_index.md", "predictive_modeling_pipeline/02_numerical_pipeline_quiz_m1_02.md", "predictive_modeling_pipeline/02_numerical_pipeline_video_cross_validation.md", "predictive_modeling_pipeline/03_categorical_pipeline_index.md", "predictive_modeling_pipeline/03_categorical_pipeline_quiz_m1_03.md", "predictive_modeling_pipeline/03_categorical_pipeline_visualization_video.md", "predictive_modeling_pipeline/predictive_modeling_module_intro.md", "predictive_modeling_pipeline/predictive_modeling_module_take_away.md", "predictive_modeling_pipeline/wrap_up_quiz.md", "python_scripts/01_tabular_data_exploration.py", "python_scripts/01_tabular_data_exploration_ex_01.py", "python_scripts/01_tabular_data_exploration_sol_01.py", "python_scripts/02_numerical_pipeline_cross_validation.py", "python_scripts/02_numerical_pipeline_ex_00.py", "python_scripts/02_numerical_pipeline_ex_01.py", "python_scripts/02_numerical_pipeline_hands_on.py", "python_scripts/02_numerical_pipeline_introduction.py", "python_scripts/02_numerical_pipeline_scaling.py", "python_scripts/02_numerical_pipeline_sol_00.py", "python_scripts/02_numerical_pipeline_sol_01.py", "python_scripts/03_categorical_pipeline.py", "python_scripts/03_categorical_pipeline_column_transformer.py", "python_scripts/03_categorical_pipeline_ex_01.py", "python_scripts/03_categorical_pipeline_ex_02.py", "python_scripts/03_categorical_pipeline_sol_01.py", "python_scripts/03_categorical_pipeline_sol_02.py", "python_scripts/03_categorical_pipeline_visualization.py", "python_scripts/cross_validation_baseline.py", "python_scripts/cross_validation_ex_01.py", "python_scripts/cross_validation_ex_02.py", "python_scripts/cross_validation_grouping.py", "python_scripts/cross_validation_learning_curve.py", "python_scripts/cross_validation_nested.py", "python_scripts/cross_validation_sol_01.py", "python_scripts/cross_validation_sol_02.py", "python_scripts/cross_validation_stratification.py", "python_scripts/cross_validation_time.py", "python_scripts/cross_validation_train_test.py", "python_scripts/cross_validation_validation_curve.py", "python_scripts/datasets_ames_housing.py", "python_scripts/datasets_bike_rides.py", "python_scripts/datasets_blood_transfusion.py", "python_scripts/datasets_california_housing.py", "python_scripts/dev_features_importance.py", "python_scripts/ensemble_adaboost.py", "python_scripts/ensemble_bagging.py", "python_scripts/ensemble_ex_01.py", "python_scripts/ensemble_ex_02.py", "python_scripts/ensemble_ex_03.py", "python_scripts/ensemble_ex_04.py", "python_scripts/ensemble_gradient_boosting.py", "python_scripts/ensemble_hist_gradient_boosting.py", "python_scripts/ensemble_hyperparameters.py", "python_scripts/ensemble_introduction.py", "python_scripts/ensemble_random_forest.py", "python_scripts/ensemble_sol_01.py", "python_scripts/ensemble_sol_02.py", "python_scripts/ensemble_sol_03.py", "python_scripts/ensemble_sol_04.py", "python_scripts/feature_selection_ex_01.py", "python_scripts/feature_selection_introduction.py", "python_scripts/feature_selection_limitation_model.py", "python_scripts/feature_selection_sol_01.py", "python_scripts/linear_models_ex_01.py", "python_scripts/linear_models_ex_02.py", "python_scripts/linear_models_ex_03.py", "python_scripts/linear_models_feature_engineering_classification.py", "python_scripts/linear_models_regularization.py", "python_scripts/linear_models_sol_01.py", "python_scripts/linear_models_sol_02.py", "python_scripts/linear_models_sol_03.py", "python_scripts/linear_regression_in_sklearn.py", "python_scripts/linear_regression_non_linear_link.py", "python_scripts/linear_regression_without_sklearn.py", "python_scripts/logistic_regression.py", "python_scripts/logistic_regression_non_linear.py", "python_scripts/metrics_classification.py", "python_scripts/metrics_ex_01.py", "python_scripts/metrics_ex_02.py", "python_scripts/metrics_regression.py", "python_scripts/metrics_sol_01.py", "python_scripts/metrics_sol_02.py", "python_scripts/parameter_tuning_ex_02.py", "python_scripts/parameter_tuning_ex_03.py", "python_scripts/parameter_tuning_grid_search.py", "python_scripts/parameter_tuning_manual.py", "python_scripts/parameter_tuning_nested.py", "python_scripts/parameter_tuning_parallel_plot.py", "python_scripts/parameter_tuning_randomized_search.py", "python_scripts/parameter_tuning_sol_02.py", "python_scripts/parameter_tuning_sol_03.py", "python_scripts/trees_classification.py", "python_scripts/trees_dataset.py", "python_scripts/trees_ex_01.py", "python_scripts/trees_ex_02.py", "python_scripts/trees_hyperparameters.py", "python_scripts/trees_regression.py", "python_scripts/trees_sol_01.py", "python_scripts/trees_sol_02.py", "toc.md", "trees/slides.md", "trees/trees_classification_index.md", "trees/trees_hyperparameters_index.md", "trees/trees_intuitions_index.md", "trees/trees_module_intro.md", "trees/trees_module_take_away.md", "trees/trees_quiz_m5_01.md", "trees/trees_quiz_m5_02.md", "trees/trees_quiz_m5_03.md", "trees/trees_quiz_m5_04.md", "trees/trees_regression_index.md", "trees/trees_wrap_up_quiz.md", "tuning/parameter_tuning_automated_index.md", "tuning/parameter_tuning_automated_quiz_m3_02.md", "tuning/parameter_tuning_manual_index.md", "tuning/parameter_tuning_manual_quiz_m3_01.md", "tuning/parameter_tuning_module_intro.md", "tuning/parameter_tuning_module_take_away.md", "tuning/parameter_tuning_parallel_plot_video.md", "tuning/parameter_tuning_wrap_up_quiz.md"], "titles": ["Acknowledgement", "The adult census dataset", "Datasets description", "Glossary", "Notebook timings", "Table of contents", "Concluding remarks", "\ud83c\udfa5 Concluding remarks", "\ud83c\udfa5 Intuitions on ensemble models: bagging", "\ud83c\udfa5 Intuitions on ensemble models: boosting", "Ensemble based on boosting", "Ensemble method using bootstrapping", "Hyperparameter tuning with ensemble methods", "Module overview", "Main take-away", "\u2705 Quiz M6.01", "\u2705 Quiz M6.02", "\u2705 Quiz M6.03", "\ud83c\udfc1 Wrap-up quiz 6", "Comparing a model with simple baselines", "Choice of cross-validation", "Nested cross-validation", "Module overview", "Main take-away", "\u2705 Quiz M7.01", "\u2705 Quiz M7.02", "\u2705 Quiz M7.03", "\u2705 Quiz M7.04", "\u2705 Quiz M7.05", "\ud83c\udfc1 Wrap-up quiz 7", "Classification metrics", "Regression metrics", "Caveats of feature selection", "Module overview", "Main take-away", "\u2705 Quiz", "Introduction", "\u2705 Quiz", "Intuitions on linear models", "Module overview", "Main take-away", "Non-linear feature engineering for linear models", "\u2705 Quiz M4.01", "\u2705 Quiz M4.02", "\u2705 Quiz M4.03", "\u2705 Quiz M4.04", "\u2705 Quiz M4.05", "Regularization in linear model", "\ud83c\udfa5 Intuitions on linear models", "\ud83c\udfc1 Wrap-up quiz 4", "\ud83c\udfa5 Intuitions on regularized linear models", "\u2705 Quiz Intro.01", "\ud83c\udfa5 Introducing machine-learning concepts", "\u2705 Quiz M2.03", "\ud83c\udfa5 Bias versus Variance", "\u2705 Quiz M2.02", "\ud83c\udfa5 Comparing train and test errors", "Bias versus variance trade-off", "Module overview", "Overfitting and underfitting", "Main take-away", "Validation and learning curves", "\ud83c\udfc1 Wrap-up quiz 2", "\u2705 Quiz M2.01", "\ud83c\udfa5 Overfitting and Underfitting", "Tabular data exploration", "\u2705 Quiz M1.01", "Fitting a scikit-learn model on numerical data", "\u2705 Quiz M1.02", "\ud83c\udfa5 Validation of a model", "Handling categorical data", "\u2705 Quiz M1.03", "\ud83c\udfa5 Visualizing scikit-learn pipelines in Jupyter", "Module overview", "Main take-away", "\ud83c\udfc1 Wrap-up quiz 1", "First look at our dataset", "\ud83d\udcdd Exercise M1.01", "\ud83d\udcc3 Solution for Exercise M1.01", "Model evaluation using cross-validation", "\ud83d\udcdd Exercise M1.02", "\ud83d\udcdd Exercise M1.03", "Working with numerical data", "First model with scikit-learn", "Preprocessing for numerical features", "\ud83d\udcc3 Solution for Exercise M1.02", "\ud83d\udcc3 Solution for Exercise M1.03", "Encoding of categorical variables", "Using numerical and categorical variables together", "\ud83d\udcdd Exercise M1.04", "\ud83d\udcdd Exercise M1.05", "\ud83d\udcc3 Solution for Exercise M1.04", "\ud83d\udcc3 Solution for Exercise M1.05", "Visualizing scikit-learn pipelines in Jupyter", "Comparing model performance with a simple baseline", "\ud83d\udcdd Exercise M2.01", "\ud83d\udcdd Exercise M7.01", "Sample grouping", "Effect of the sample size in cross-validation", "Nested cross-validation", "\ud83d\udcc3 Solution for Exercise M2.01", "\ud83d\udcc3 Solution for Exercise M7.01", "Stratification", "Non i.i.d. data", "Cross-validation framework", "Overfit-generalization-underfit", "The Ames housing dataset", "The bike rides dataset", "The blood transfusion dataset", "The California housing dataset", "Feature importance", "Adaptive Boosting (AdaBoost)", "Bagging", "\ud83d\udcdd Exercise M6.01", "\ud83d\udcdd Exercise M6.02", "\ud83d\udcdd Exercise M6.03", "\ud83d\udcdd Exercise M6.04", "Gradient-boosting decision tree (GBDT)", "Speeding-up gradient-boosting", "Hyperparameter tuning", "Introductory example to ensemble models", "Random forests", "\ud83d\udcc3 Solution for Exercise M6.01", "\ud83d\udcc3 Solution for Exercise M6.02", "\ud83d\udcc3 Solution for Exercise M6.03", "\ud83d\udcc3 Solution for Exercise M6.04", "\ud83d\udcdd Exercise 01", "Benefits of using feature selection", "Limitation of selecting feature using a model", "\ud83d\udcc3 Solution for Exercise 01", "\ud83d\udcdd Exercise M4.01", "\ud83d\udcdd Exercise M4.02", "\ud83d\udcdd Exercise M4.03", "Non-linear feature engineering for Logistic Regression", "Regularization of linear regression model", "\ud83d\udcc3 Solution for Exercise M4.01", "\ud83d\udcc3 Solution for Exercise M4.02", "\ud83d\udcc3 Solution for Exercise M4.03", "Linear regression using scikit-learn", "Non-linear feature engineering for Linear Regression", "Linear regression without scikit-learn", "Linear models for classification", "Beyond linear separation in classification", "Classification", "\ud83d\udcdd Exercise M7.02", "\ud83d\udcdd Exercise M7.03", "Regression", "\ud83d\udcc3 Solution for Exercise M7.02", "\ud83d\udcc3 Solution for Exercise M7.03", "\ud83d\udcdd Exercise M3.01", "\ud83d\udcdd Exercise M3.02", "Hyperparameter tuning by grid-search", "Set and get hyperparameters in scikit-learn", "Evaluation and hyperparameter tuning", "Analysis of hyperparameter search results", "Hyperparameter tuning by randomized-search", "\ud83d\udcc3 Solution for Exercise M3.01", "\ud83d\udcc3 Solution for Exercise M3.02", "Build a classification decision tree", "The penguins datasets", "\ud83d\udcdd Exercise M5.01", "\ud83d\udcdd Exercise M5.02", "Importance of decision tree hyperparameters on generalization", "Decision tree for regression", "\ud83d\udcc3 Solution for Exercise M5.01", "\ud83d\udcc3 Solution for Exercise M5.02", "Table of contents", "\ud83c\udfa5 Intuitions on tree-based models", "Decision tree in classification", "Hyperparameters of decision tree", "Intuitions on tree-based models", "Module overview", "Main take-away", "\u2705 Quiz M5.01", "\u2705 Quiz M5.02", "\u2705 Quiz M5.03", "\u2705 Quiz M5.04", "Decision tree in regression", "\ud83c\udfc1 Wrap-up quiz 5", "Automated tuning", "\u2705 Quiz M3.02", "Manual tuning", "\u2705 Quiz M3.01", "Module overview", "Main take-away", "\ud83c\udfa5 Analysis of hyperparameter search results", "\ud83c\udfc1 Wrap-up quiz 3"], "terms": {"The": [0, 2, 3, 13, 18, 22, 33, 36, 37, 39, 43, 45, 46, 49, 51, 58, 60, 62, 68, 73, 75, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 110, 111, 112, 113, 114, 115, 116, 118, 119, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 144, 145, 146, 147, 148, 149, 150, 151, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 171, 173, 175, 178, 183, 184, 186], "diagram": [0, 3, 84], "present": [0, 8, 9, 13, 22, 23, 29, 34, 39, 48, 50, 52, 54, 56, 58, 64, 69, 73, 75, 76, 83, 87, 94, 98, 102, 103, 105, 106, 107, 108, 109, 111, 112, 117, 118, 120, 121, 128, 138, 140, 143, 144, 146, 147, 153, 155, 159, 163, 167, 171, 172, 173], "api": [0, 6, 74, 80, 83, 85, 88, 143], "design": [0, 3, 6, 36, 82, 106, 139, 146], "modul": [0, 1, 3, 14, 18, 23, 34, 36, 40, 49, 60, 74, 76, 82, 88, 109, 133, 136, 137, 143, 151, 152, 153, 160, 164, 166, 172, 184], "predict": [0, 1, 13, 16, 18, 22, 23, 24, 25, 29, 33, 36, 39, 40, 42, 43, 44, 49, 51, 53, 58, 60, 62, 63, 68, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 88, 89, 91, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 117, 119, 120, 121, 122, 123, 124, 126, 127, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 142, 146, 148, 150, 152, 154, 157, 158, 159, 161, 162, 163, 165, 171, 175, 178, 182, 183, 186], "model": [0, 1, 10, 11, 13, 14, 15, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 39, 40, 42, 43, 44, 45, 46, 49, 53, 55, 58, 60, 62, 63, 66, 68, 71, 73, 74, 75, 76, 78, 80, 81, 82, 85, 86, 87, 89, 90, 91, 92, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 108, 109, 112, 113, 115, 116, 118, 119, 121, 122, 124, 125, 126, 127, 129, 131, 132, 136, 137, 138, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 150, 152, 154, 156, 157, 158, 161, 162, 163, 164, 165, 171, 172, 178, 180, 182, 183, 184, 186], "pipelin": [0, 1, 3, 13, 22, 33, 34, 36, 39, 44, 49, 52, 58, 62, 68, 70, 73, 74, 75, 79, 84, 88, 89, 91, 95, 96, 97, 99, 100, 101, 102, 106, 109, 110, 118, 121, 126, 127, 128, 129, 131, 132, 133, 134, 136, 137, 139, 141, 142, 149, 150, 151, 152, 153, 155, 156, 157, 171, 180, 182, 183, 186], "us": [0, 14, 17, 18, 22, 23, 24, 26, 27, 28, 29, 32, 33, 34, 35, 36, 37, 38, 39, 40, 43, 44, 45, 49, 51, 58, 62, 66, 67, 68, 70, 71, 73, 74, 75, 76, 77, 78, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 152, 153, 154, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 173, 174, 178, 180, 183, 186], "follow": [0, 3, 13, 14, 17, 18, 22, 23, 27, 29, 33, 34, 40, 43, 45, 49, 51, 58, 60, 62, 68, 71, 73, 74, 75, 76, 80, 83, 84, 85, 87, 88, 95, 96, 97, 99, 100, 101, 103, 110, 112, 116, 117, 119, 121, 125, 132, 133, 134, 137, 138, 139, 140, 141, 142, 143, 146, 149, 150, 151, 152, 153, 155, 156, 157, 159, 163, 171, 172, 178, 180, 183, 184, 186], "paramet": [0, 6, 15, 18, 26, 27, 28, 29, 37, 40, 43, 45, 46, 49, 55, 58, 60, 62, 68, 75, 79, 80, 81, 82, 84, 85, 86, 87, 89, 91, 95, 99, 100, 101, 104, 105, 110, 111, 112, 113, 115, 116, 119, 120, 121, 122, 124, 125, 128, 131, 132, 133, 136, 138, 140, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 164, 171, 178, 180, 182, 183, 186], "free": [0, 6, 36, 87, 116, 119, 125, 134, 186], "icon": [0, 36], "licens": [0, 36], "under": [0, 24, 29, 36, 40, 76, 95, 100, 105, 120, 133, 139, 142, 143, 146, 162, 171], "cc": [0, 36], "BY": [0, 36], "3": [0, 4, 18, 29, 36, 43, 49, 58, 62, 75, 76, 78, 82, 83, 84, 85, 86, 87, 93, 94, 95, 97, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 111, 112, 116, 117, 118, 119, 120, 122, 123, 125, 127, 128, 131, 133, 134, 136, 139, 140, 141, 143, 144, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 161, 162, 163, 164, 165, 166, 171, 178, 183], "0": [0, 3, 4, 18, 29, 37, 43, 46, 49, 68, 75, 76, 78, 79, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 178, 180, 186], "sourc": [0, 119], "set": [0, 6, 18, 26, 29, 35, 37, 39, 40, 42, 45, 49, 53, 55, 58, 60, 62, 63, 66, 68, 75, 76, 79, 81, 82, 83, 84, 86, 87, 88, 89, 91, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 107, 109, 110, 111, 112, 113, 114, 115, 116, 117, 119, 120, 121, 122, 123, 124, 125, 126, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 153, 155, 156, 157, 158, 159, 162, 163, 164, 166, 176, 178, 180, 181, 182, 183, 186], "gear": 0, "svg": 0, "vector": [0, 43, 44, 95, 100, 102, 104, 117, 126, 129, 130, 133, 135, 139, 142, 143], "cc0": 0, "close": [0, 3, 29, 45, 51, 76, 84, 99, 102, 103, 104, 109, 110, 117, 124, 125, 133, 134, 137, 138, 139, 141, 146, 151, 153, 155, 158], "mit": 0, "thi": [1, 13, 14, 18, 22, 23, 27, 29, 33, 34, 36, 39, 40, 44, 49, 51, 52, 58, 60, 62, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 171, 172, 175, 178, 180, 183, 184, 186], "collect": [1, 3, 6, 29, 76, 79, 96, 101, 104, 120, 127, 148], "inform": [1, 6, 24, 29, 49, 75, 76, 79, 83, 87, 88, 94, 97, 98, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 117, 119, 120, 127, 128, 134, 139, 141, 143, 144, 147, 151, 152, 155, 157, 159], "relat": [1, 3, 14, 18, 23, 34, 40, 58, 60, 74, 76, 88, 137, 139, 143, 172, 183, 184], "person": [1, 6, 66, 76, 82, 108, 143, 151], "task": [1, 6, 43, 75, 76, 82, 93, 104, 108, 133, 141, 173], "whether": [1, 3, 25, 66, 75, 76, 79, 84, 88, 90, 92, 93, 95, 100, 104, 105, 108, 110, 143, 148, 151, 153, 157, 161, 162, 165], "earn": [1, 76, 151], "salari": [1, 66, 109], "abov": [1, 3, 6, 18, 29, 49, 75, 76, 80, 84, 85, 93, 99, 102, 104, 105, 109, 110, 112, 117, 118, 130, 134, 135, 136, 140, 141, 142, 143, 144, 146, 147, 151, 153, 157, 159, 161, 163, 164, 165, 178, 180, 186], "below": [1, 3, 18, 49, 62, 79, 86, 87, 93, 109, 110, 118, 124, 130, 135, 140, 143, 146, 155, 159, 161, 164, 165, 178, 180, 182, 186], "50": [1, 18, 29, 33, 62, 76, 80, 82, 84, 85, 94, 101, 102, 104, 105, 106, 107, 108, 109, 115, 117, 118, 119, 120, 121, 124, 131, 134, 136, 146, 151, 152, 154, 155], "k": [1, 3, 25, 62, 79, 82, 83, 84, 94, 98, 104, 105, 111, 113, 115, 116, 117, 118, 119, 120, 122, 124, 125, 127, 128, 129, 146, 148, 150, 151, 153, 154, 157, 164, 183], "we": [1, 3, 13, 14, 18, 22, 23, 25, 28, 29, 33, 34, 37, 39, 40, 43, 49, 51, 55, 58, 60, 62, 66, 68, 71, 73, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 171, 172, 178, 180, 182, 183, 186], "extens": [1, 104], "explor": [1, 6, 49, 77, 78, 82, 84, 87, 100, 114, 116, 123, 125, 133, 134, 139, 150, 151, 153, 154, 155, 157, 166, 186], "first": [1, 8, 9, 29, 48, 50, 52, 54, 56, 58, 64, 65, 66, 67, 69, 73, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 116, 117, 118, 119, 120, 121, 123, 125, 126, 127, 128, 129, 131, 132, 133, 134, 136, 138, 139, 141, 142, 143, 144, 145, 146, 147, 148, 151, 153, 158, 159, 161, 162, 163, 164, 165, 166, 167, 183], "sequenc": [1, 87, 117, 149, 156], "tabular": [1, 6, 66, 73, 76, 83, 88, 166], "data": [1, 18, 20, 22, 23, 24, 25, 28, 29, 36, 39, 40, 44, 45, 46, 49, 60, 62, 68, 71, 73, 74, 75, 77, 78, 80, 81, 85, 86, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 174, 178, 180, 183, 186], "notebook": [1, 18, 23, 36, 49, 66, 75, 78, 80, 81, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 101, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115, 117, 118, 119, 120, 121, 122, 124, 127, 128, 131, 133, 134, 136, 138, 140, 141, 142, 143, 144, 146, 147, 148, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 162, 163, 164, 165, 166, 180], "look": [1, 6, 29, 65, 66, 68, 77, 78, 80, 82, 83, 85, 87, 97, 98, 100, 104, 105, 106, 107, 108, 109, 110, 111, 112, 117, 119, 131, 132, 134, 136, 137, 139, 140, 142, 143, 151, 158, 159, 166, 180, 186], "our": [1, 6, 18, 25, 29, 43, 49, 65, 66, 73, 79, 81, 82, 83, 84, 86, 88, 89, 91, 93, 94, 95, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 110, 111, 112, 115, 116, 117, 119, 124, 125, 126, 127, 129, 130, 132, 133, 134, 135, 137, 138, 139, 140, 141, 143, 144, 146, 147, 152, 154, 158, 159, 163, 165, 166, 186], "To": [1, 3, 8, 9, 29, 37, 48, 49, 50, 52, 54, 56, 64, 69, 75, 76, 82, 83, 84, 88, 89, 91, 95, 97, 98, 99, 100, 102, 103, 104, 105, 110, 111, 112, 115, 118, 119, 124, 127, 131, 133, 134, 136, 137, 138, 139, 142, 143, 146, 155, 157, 160, 163, 167, 178], "avoid": [1, 3, 6, 40, 49, 75, 76, 99, 110, 111, 112, 115, 123, 124, 129, 131, 136, 137, 138, 139, 151, 154, 155, 157], "repeat": [1, 3, 18, 29, 49, 60, 62, 79, 81, 86, 89, 91, 97, 98, 99, 102, 104, 127, 137, 142, 144, 147, 150, 157, 160, 161, 163, 164, 165, 186], "same": [1, 3, 18, 26, 29, 37, 40, 45, 49, 68, 76, 81, 82, 83, 84, 86, 87, 88, 92, 97, 98, 99, 101, 102, 104, 105, 106, 110, 111, 112, 117, 118, 127, 130, 131, 133, 134, 135, 136, 138, 139, 140, 142, 143, 146, 148, 154, 155, 163, 164, 178, 186], "redirect": 1, "reader": [1, 76, 112, 139, 141, 146], "particular": [1, 3, 6, 27, 73, 76, 79, 80, 82, 83, 85, 88, 92, 94, 99, 100, 104, 121, 133, 137, 141, 143, 146, 151, 153, 154, 157, 164], "penguin": [2, 18, 77, 78, 111, 114, 123, 130, 131, 132, 135, 136, 137, 138, 140, 141, 158, 160, 161, 163, 164, 165, 166, 186], "adult": [2, 66, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 96, 101, 121, 149, 151, 152, 153, 155, 156, 166], "censu": [2, 66, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 96, 101, 104, 109, 121, 149, 151, 152, 153, 155, 156, 166], "california": [2, 94, 104, 106, 110, 113, 115, 116, 117, 118, 119, 120, 122, 124, 125, 166], "hous": [2, 3, 51, 75, 93, 94, 98, 104, 105, 110, 113, 115, 116, 117, 118, 119, 120, 122, 124, 125, 134, 145, 146, 148, 166], "am": [2, 134, 145, 146, 148, 166], "blood": [2, 95, 100, 143, 144, 147, 166], "transfus": [2, 95, 100, 143, 144, 147, 166], "bike": [2, 29, 166], "ride": [2, 29, 166], "aim": [3, 36, 82, 95, 100, 103, 104, 111, 113, 114, 115, 116, 120, 122, 123, 124, 125, 126, 127, 129, 130, 131, 135, 136, 140, 143, 144, 147, 160, 161, 164, 165], "describ": [3, 71, 82, 83, 84, 94, 109, 186], "For": [3, 6, 36, 43, 55, 60, 73, 76, 79, 82, 83, 84, 87, 88, 93, 94, 97, 99, 101, 104, 105, 107, 109, 110, 114, 115, 117, 119, 121, 123, 124, 126, 127, 128, 129, 131, 133, 134, 136, 137, 139, 140, 141, 143, 146, 148, 151, 152, 153, 155, 158, 162, 164, 165, 174, 178, 183], "you": [3, 6, 14, 18, 23, 29, 34, 36, 40, 49, 52, 60, 62, 68, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 98, 100, 101, 102, 104, 105, 107, 109, 110, 111, 113, 114, 115, 116, 118, 119, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 154, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 172, 176, 178, 180, 182, 184, 186], "don": [3, 6, 80, 85, 95, 100, 104, 108, 126, 129, 134, 151], "t": [3, 6, 80, 85, 87, 95, 97, 100, 103, 104, 108, 110, 118, 125, 126, 129, 134, 143, 146, 147, 151], "find": [3, 6, 51, 60, 76, 82, 83, 84, 87, 95, 96, 99, 100, 101, 103, 105, 113, 114, 116, 122, 123, 125, 128, 129, 131, 132, 133, 134, 136, 137, 138, 142, 149, 150, 151, 153, 155, 156, 157, 158, 160, 161, 164, 165, 171, 180], "ad": [3, 18, 40, 49, 55, 95, 98, 100, 110, 115, 119, 121, 124, 139, 142, 151, 155], "bottom": [3, 76, 143], "page": [3, 36, 82, 84, 85, 88, 93, 99, 104, 111, 133, 134, 138, 139, 142, 143, 151, 153, 155, 158, 164, 165], "acronym": [3, 103], "stand": [3, 83, 112, 180], "applic": [3, 6, 83, 97, 103, 143, 146, 162], "program": [3, 18, 29, 36, 49, 62, 73, 75, 83, 97, 126, 129, 178, 186], "interfac": [3, 83], "It": [3, 6, 29, 36, 60, 76, 80, 83, 84, 85, 87, 88, 97, 98, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 117, 118, 120, 121, 125, 126, 129, 133, 134, 137, 140, 143, 144, 146, 147, 148, 151, 153, 154, 155, 158, 162, 163, 164], "can": [3, 6, 14, 15, 18, 22, 23, 28, 29, 34, 36, 39, 40, 45, 49, 55, 58, 60, 62, 68, 71, 73, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 150, 151, 152, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 172, 173, 175, 178, 180, 183, 184, 186], "have": [3, 25, 29, 43, 49, 51, 55, 60, 62, 68, 71, 76, 79, 81, 82, 83, 84, 86, 87, 91, 94, 98, 99, 102, 103, 104, 106, 107, 108, 109, 110, 111, 114, 117, 118, 119, 120, 121, 123, 124, 126, 127, 129, 131, 133, 134, 135, 136, 139, 140, 141, 142, 143, 146, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 162, 163, 164, 171, 178, 180, 183, 184, 186], "slightli": [3, 16, 76, 85, 87, 88, 104, 107, 111, 112, 119, 120, 121, 124, 137], "differ": [3, 6, 15, 16, 18, 22, 25, 29, 37, 43, 45, 49, 55, 60, 62, 66, 68, 71, 75, 76, 77, 78, 79, 83, 84, 87, 88, 92, 94, 95, 97, 98, 99, 100, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 117, 118, 119, 121, 129, 130, 133, 134, 135, 136, 137, 138, 139, 144, 146, 147, 148, 150, 152, 153, 154, 155, 157, 158, 159, 162, 163, 178, 186], "mean": [3, 6, 28, 29, 49, 62, 75, 76, 79, 80, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 129, 131, 133, 134, 135, 136, 138, 139, 140, 141, 143, 145, 146, 147, 148, 151, 152, 153, 155, 156, 157, 158, 163, 164, 175, 186], "context": [3, 6, 15, 103, 141, 143], "some": [3, 6, 18, 22, 23, 29, 33, 36, 49, 62, 66, 68, 73, 75, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 89, 91, 93, 97, 99, 101, 102, 103, 104, 105, 106, 107, 109, 110, 111, 112, 114, 116, 117, 118, 119, 120, 121, 123, 125, 126, 128, 129, 133, 134, 137, 139, 140, 141, 142, 146, 148, 151, 153, 154, 155, 157, 158, 162, 163, 165, 178, 186], "case": [3, 29, 33, 51, 76, 79, 82, 84, 87, 88, 90, 92, 93, 94, 96, 97, 99, 100, 101, 102, 103, 104, 105, 110, 117, 119, 121, 126, 129, 131, 133, 134, 136, 137, 140, 141, 142, 143, 144, 146, 147, 148, 150, 152, 153, 155, 157, 158], "an": [3, 16, 22, 23, 26, 28, 35, 36, 40, 43, 44, 49, 51, 53, 55, 58, 60, 71, 73, 74, 75, 76, 79, 83, 84, 86, 88, 89, 90, 91, 92, 93, 95, 97, 98, 99, 100, 102, 103, 104, 107, 108, 109, 110, 112, 115, 117, 118, 119, 120, 121, 124, 126, 127, 129, 131, 132, 133, 134, 135, 136, 137, 138, 139, 141, 142, 143, 144, 146, 147, 148, 149, 151, 152, 153, 156, 157, 158, 162, 163, 164, 171, 174, 178, 180, 182, 183, 184, 186], "onlin": [3, 94, 96, 101], "servic": [3, 36, 88], "access": [3, 15, 29, 36, 49, 60, 80, 85, 95, 100, 104, 110, 112, 114, 123, 134, 137, 141, 186], "remot": 3, "In": [3, 6, 15, 22, 23, 29, 34, 36, 37, 39, 40, 43, 46, 49, 60, 66, 74, 76, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 91, 93, 94, 95, 96, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 116, 117, 118, 119, 120, 121, 125, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 165, 172, 178, 180, 183], "both": [3, 15, 16, 18, 22, 29, 39, 40, 49, 55, 66, 75, 76, 78, 83, 84, 87, 88, 89, 90, 91, 92, 96, 97, 98, 99, 100, 101, 102, 105, 106, 110, 111, 115, 117, 118, 121, 124, 126, 127, 129, 130, 133, 134, 135, 137, 139, 141, 142, 143, 144, 146, 147, 151, 153, 157, 158, 159, 161, 162, 165, 171, 172, 178, 180, 186], "itself": [3, 18, 42, 84, 97, 99, 100, 104, 108, 112, 146, 153, 183], "technic": [3, 13, 22, 33, 36, 39, 58, 73, 83, 171, 183], "specif": [3, 13, 22, 23, 37, 66, 83, 84, 89, 90, 91, 92, 97, 104, 105, 107, 109, 110, 111, 117, 118, 121, 127, 134, 143, 151, 152, 154, 158, 162, 163, 178], "peopl": [3, 6, 76, 97, 104, 109, 110, 143], "who": [3, 6, 88, 143], "write": [3, 36, 77, 80, 81, 89, 90, 92, 95, 96, 97, 113, 114, 115, 116, 126, 130, 131, 132, 139, 144, 145, 149, 150, 156, 160, 161], "client": 3, "connect": 3, "offlin": 3, "librari": [3, 36, 73, 76, 157], "scikit": [3, 13, 14, 22, 23, 24, 27, 28, 33, 34, 37, 38, 39, 40, 43, 46, 58, 60, 62, 66, 68, 70, 73, 74, 79, 80, 82, 84, 85, 87, 88, 89, 91, 96, 101, 102, 104, 109, 111, 114, 116, 118, 121, 123, 125, 126, 129, 132, 133, 134, 139, 141, 143, 144, 146, 147, 148, 151, 153, 164, 166, 171, 172, 174, 175, 181, 183, 184, 186], "list": [3, 29, 36, 49, 62, 87, 90, 92, 102, 110, 112, 113, 115, 122, 124, 134, 144, 145, 147, 148, 152, 186], "all": [3, 15, 16, 17, 18, 24, 26, 27, 28, 29, 37, 43, 44, 45, 46, 49, 51, 53, 55, 62, 63, 66, 68, 71, 75, 79, 80, 82, 83, 84, 85, 87, 90, 92, 94, 96, 97, 98, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 117, 118, 119, 120, 121, 127, 133, 134, 135, 137, 139, 140, 143, 146, 148, 150, 151, 152, 153, 154, 157, 158, 161, 163, 164, 165, 173, 174, 176, 178, 180, 182, 186], "public": 3, "function": [3, 6, 18, 29, 36, 44, 53, 60, 62, 68, 75, 79, 82, 83, 84, 87, 96, 101, 104, 105, 106, 109, 110, 111, 112, 116, 117, 125, 126, 129, 130, 132, 133, 135, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 151, 153, 154, 158, 160, 163, 164, 175, 186], "class": [3, 15, 25, 27, 43, 62, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 100, 101, 102, 106, 107, 108, 109, 110, 111, 112, 118, 121, 132, 133, 134, 137, 139, 140, 141, 142, 144, 147, 148, 149, 151, 152, 153, 155, 156, 158, 160, 162, 174, 186], "method": [3, 4, 6, 14, 43, 62, 75, 76, 77, 78, 82, 83, 84, 88, 97, 103, 110, 113, 117, 120, 121, 122, 128, 131, 133, 134, 136, 139, 141, 142, 143, 146, 152, 153, 155, 166, 186], "along": [3, 76, 79, 87, 89, 91, 106, 130, 135, 146, 158], "document": [3, 4, 6, 15, 62, 80, 82, 83, 84, 85, 87, 89, 91, 94, 96, 97, 101, 139, 143, 144, 145, 147, 148, 152], "via": [3, 29, 36, 79, 87, 99, 105, 109, 116, 117, 118, 120, 121, 125, 127, 141, 151, 152, 162], "docstr": [3, 146], "brows": 3, "http": [3, 6, 36, 76, 83, 97, 104, 109], "org": [3, 76, 82, 83, 84, 85, 88, 93, 99, 104, 111, 133, 134, 138, 139, 142, 143, 151, 153, 155, 158, 164, 165], "stabl": [3, 110, 112, 134, 178, 186], "html": [3, 82, 84, 85, 88, 93, 99, 104, 109, 111, 133, 134, 138, 139, 142, 143, 151, 153, 155, 158, 164, 165], "try": [3, 6, 29, 49, 76, 82, 84, 85, 88, 89, 91, 93, 99, 104, 107, 111, 112, 117, 119, 121, 131, 133, 134, 136, 137, 138, 139, 142, 143, 144, 146, 147, 148, 149, 151, 153, 155, 156, 157, 158, 164, 165, 178, 183], "adopt": [3, 133, 137], "simpl": [3, 6, 49, 76, 81, 86, 95, 100, 106, 111, 112, 120, 121, 134, 137, 139, 140, 141, 152, 158, 164, 166], "convent": [3, 76, 83, 84, 139], "limit": [3, 18, 29, 32, 34, 42, 58, 60, 63, 82, 88, 104, 105, 112, 133, 134, 139, 142, 146, 155, 159, 161, 165, 166], "minimum": [3, 119, 137, 143, 155, 161, 162, 163, 165], "number": [3, 6, 16, 17, 18, 29, 37, 43, 45, 49, 51, 55, 62, 71, 75, 76, 79, 80, 82, 83, 84, 85, 87, 88, 89, 91, 95, 97, 98, 100, 102, 104, 105, 106, 107, 108, 109, 110, 111, 112, 115, 116, 117, 118, 119, 121, 124, 125, 127, 128, 129, 131, 133, 134, 135, 136, 137, 139, 143, 145, 146, 148, 150, 151, 153, 154, 155, 157, 158, 162, 163, 173, 178, 180, 184, 186], "object": [3, 6, 29, 49, 60, 80, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 104, 106, 107, 108, 121, 134, 141, 143, 144, 147, 149, 151, 152, 153, 155, 156, 157, 158, 163, 178], "must": [3, 6, 45, 110, 134, 153, 186], "implement": [3, 92, 102, 111, 112, 118, 138, 141, 144, 147, 151, 154], "furthermor": [3, 49, 104, 133, 134, 136, 141], "tri": [3, 6, 68, 107, 111, 134, 137], "consist": [3, 40, 49, 75, 79, 83, 104, 131, 136, 139, 148], "name": [3, 15, 29, 62, 76, 78, 82, 83, 84, 85, 86, 87, 88, 94, 95, 100, 101, 102, 104, 106, 107, 108, 109, 110, 112, 117, 119, 122, 125, 131, 134, 136, 137, 140, 141, 143, 151, 152, 154, 155, 182, 186], "categori": [3, 71, 75, 76, 82, 88, 89, 91, 106, 108, 121, 134, 151, 159], "e": [3, 6, 18, 29, 49, 62, 66, 68, 71, 73, 74, 75, 76, 82, 83, 84, 86, 87, 88, 91, 97, 98, 99, 102, 103, 104, 110, 117, 118, 119, 120, 127, 131, 134, 136, 137, 138, 141, 143, 146, 148, 149, 151, 155, 156, 157, 158, 178, 180, 182, 186], "g": [3, 6, 18, 29, 75, 76, 87, 88, 97, 99, 103, 110, 114, 119, 120, 123, 127, 130, 131, 134, 135, 136, 137, 138, 140, 141, 149, 151, 155, 156, 157, 159, 161, 162, 163, 165, 178, 186], "expos": [3, 84, 87, 121, 143], "fit_transform": [3, 68, 84, 87, 88, 106, 118, 129, 139], "accept": [3, 87, 104], "similar": [3, 46, 49, 62, 68, 80, 84, 85, 87, 90, 92, 106, 112, 119, 127, 131, 133, 134, 136, 139, 142, 143, 148, 151, 152, 153, 154, 155, 158, 186], "argument": [3, 49, 62, 80, 84, 85, 87, 89, 91, 107, 186], "type": [3, 14, 23, 29, 44, 49, 52, 73, 74, 76, 82, 83, 89, 90, 91, 92, 104, 106, 107, 108, 109, 112, 126, 129, 132, 143, 146, 178], "shape": [3, 43, 44, 76, 82, 83, 87, 106, 107, 109, 110, 111, 112, 133, 139, 141, 146, 158, 163], "those": [3, 15, 28, 58, 82, 96, 101, 105, 112, 118, 134, 139, 146, 151, 153, 157, 164, 175, 182, 186], "problem": [3, 15, 18, 22, 29, 39, 40, 45, 51, 52, 58, 62, 66, 75, 76, 81, 86, 87, 89, 91, 93, 95, 97, 100, 101, 102, 104, 107, 108, 109, 117, 127, 133, 134, 138, 139, 140, 141, 143, 146, 151, 153, 154, 157, 158, 159, 162, 163, 171, 172, 178, 186], "where": [3, 6, 29, 40, 43, 44, 46, 62, 71, 75, 79, 84, 89, 91, 95, 97, 100, 102, 104, 109, 110, 115, 121, 124, 127, 133, 134, 137, 140, 141, 142, 146, 151, 153, 155, 157, 158, 162, 180, 186], "goal": [3, 25, 36, 76, 79, 80, 81, 85, 86, 89, 90, 91, 92, 93, 97, 119, 120, 121, 127, 146, 149, 150, 156, 157, 186], "take": [3, 16, 29, 49, 76, 79, 82, 83, 84, 88, 92, 94, 96, 97, 99, 101, 103, 104, 106, 107, 108, 109, 112, 130, 135, 140, 143, 151, 154, 155, 158, 166, 178, 180], "finit": [3, 66, 71, 76, 87], "valu": [3, 13, 15, 18, 24, 28, 29, 36, 37, 40, 42, 45, 46, 49, 51, 62, 66, 68, 71, 75, 76, 80, 82, 85, 87, 88, 89, 91, 94, 97, 99, 100, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 127, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 161, 162, 163, 164, 165, 174, 175, 178, 180, 182, 183, 186], "exampl": [3, 6, 11, 14, 23, 34, 40, 51, 60, 73, 74, 76, 79, 81, 84, 86, 87, 88, 93, 94, 97, 102, 103, 105, 107, 111, 112, 118, 121, 127, 134, 135, 139, 140, 142, 146, 148, 151, 152, 162, 164, 166, 172, 183, 184], "ar": [3, 13, 14, 15, 16, 17, 18, 22, 23, 25, 27, 28, 29, 33, 34, 36, 37, 39, 40, 44, 46, 49, 51, 55, 58, 60, 62, 68, 71, 73, 74, 75, 76, 77, 78, 79, 80, 82, 83, 84, 85, 87, 88, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 117, 118, 119, 120, 121, 122, 125, 127, 128, 129, 131, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 146, 148, 150, 151, 152, 153, 154, 155, 156, 157, 158, 162, 163, 164, 165, 171, 172, 174, 178, 180, 182, 183, 184, 186], "iri": [3, 102], "setosa": 3, "versicolor": 3, "virginica": 3, "from": [3, 6, 14, 18, 24, 25, 29, 36, 37, 45, 49, 51, 58, 60, 62, 76, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 132, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 173, 175, 178, 180, 182, 183, 186], "petal": 3, "sepal": 3, "measur": [3, 6, 18, 29, 68, 75, 77, 78, 79, 82, 83, 107, 110, 124, 127, 130, 135, 140, 143, 153, 158, 159], "patient": [3, 6, 25, 131, 136], "ha": [3, 25, 37, 44, 45, 49, 66, 73, 75, 76, 82, 83, 84, 86, 87, 88, 92, 97, 101, 104, 105, 106, 109, 110, 111, 112, 118, 119, 124, 131, 133, 134, 136, 137, 138, 140, 143, 144, 146, 147, 150, 152, 155, 157, 158, 164, 178, 180, 186], "diseas": [3, 6, 25, 76, 131, 136], "result": [3, 29, 68, 76, 79, 81, 82, 83, 84, 86, 87, 88, 91, 92, 94, 96, 97, 99, 101, 102, 103, 104, 105, 112, 115, 116, 117, 119, 120, 121, 124, 125, 126, 127, 128, 129, 131, 133, 134, 136, 137, 138, 139, 143, 146, 151, 152, 153, 155, 157, 158, 164, 166, 179, 180, 182, 186], "medic": [3, 6, 25, 76], "email": 3, "spam": 3, "content": [3, 82, 88, 106, 148, 151], "sender": 3, "titl": [3, 94, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 117, 124, 125, 127, 128, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143, 147, 154, 158, 162, 163, 164, 165], "etc": [3, 25, 29, 36, 76, 87, 99, 107, 120, 131, 136], "when": [3, 6, 16, 17, 18, 22, 23, 27, 28, 29, 35, 40, 45, 55, 60, 62, 68, 75, 76, 79, 82, 83, 84, 87, 88, 89, 91, 95, 97, 98, 99, 100, 101, 102, 103, 104, 106, 107, 108, 110, 111, 115, 117, 118, 119, 121, 124, 125, 126, 127, 128, 129, 131, 133, 134, 136, 137, 138, 140, 141, 142, 143, 148, 151, 152, 153, 155, 158, 159, 175, 180, 183, 184], "two": [3, 13, 14, 29, 37, 49, 66, 68, 75, 76, 77, 78, 82, 83, 84, 87, 88, 97, 99, 101, 102, 104, 105, 106, 108, 110, 117, 119, 120, 127, 128, 129, 130, 133, 134, 135, 137, 138, 139, 141, 142, 143, 149, 151, 153, 154, 155, 156, 157, 158, 159, 161, 163, 164, 165, 178, 186], "call": [3, 13, 14, 29, 45, 46, 60, 62, 68, 71, 75, 76, 82, 83, 84, 87, 88, 89, 91, 94, 95, 98, 100, 101, 104, 105, 108, 111, 117, 118, 119, 120, 121, 129, 131, 133, 134, 136, 138, 139, 140, 141, 143, 144, 146, 147, 148, 149, 151, 153, 155, 156, 183], "binari": [3, 6, 42, 43, 62, 76, 93, 101, 141, 143, 173, 186], "least": [3, 102, 119, 137, 162, 186], "three": [3, 79, 88, 101, 102, 105, 109, 110, 111, 114, 123, 133, 158, 159], "multi": [3, 127, 131, 136, 141, 154], "illustr": [3, 33, 60, 79, 83, 84, 87, 96, 99, 101, 102, 104, 110, 121, 133, 139, 142, 143, 153, 158, 159, 162, 163], "provid": [3, 37, 75, 82, 84, 87, 88, 104, 107, 109, 113, 116, 117, 118, 122, 125, 129, 134, 137, 138, 140, 141, 142, 143, 144, 147, 148, 151, 153, 186], "user": [3, 6, 79, 88, 93, 105, 119, 120, 121, 133, 134, 136, 141, 146, 151, 155, 183, 186], "contain": [3, 18, 29, 44, 49, 62, 66, 68, 75, 76, 79, 82, 83, 87, 88, 89, 91, 97, 102, 106, 107, 108, 109, 114, 121, 123, 126, 128, 129, 134, 139, 140, 141, 142, 143, 151, 155, 161, 163, 165, 178, 186], "2": [3, 4, 18, 28, 29, 37, 43, 44, 49, 51, 68, 73, 76, 78, 79, 82, 83, 84, 85, 87, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 115, 117, 118, 119, 120, 121, 122, 124, 125, 127, 128, 129, 131, 133, 134, 135, 136, 139, 140, 141, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 164, 166, 178, 186], "repres": [3, 6, 66, 68, 71, 75, 76, 82, 83, 84, 87, 88, 102, 106, 108, 110, 117, 118, 130, 134, 135, 139, 140, 141, 142, 143, 146, 158, 164], "x": [3, 24, 28, 29, 43, 44, 68, 76, 82, 83, 84, 107, 109, 110, 111, 112, 117, 123, 130, 131, 133, 135, 136, 137, 138, 139, 140, 141, 142, 150, 151, 154, 157, 158, 159, 162, 163, 164, 165, 180], "y": [3, 28, 29, 43, 68, 76, 82, 83, 84, 102, 109, 110, 111, 112, 117, 123, 130, 133, 135, 137, 138, 139, 140, 141, 142, 146, 154, 158, 159, 162, 163, 164, 165, 180], "axi": [3, 18, 29, 78, 94, 101, 102, 106, 109, 110, 112, 125, 127, 128, 133, 134, 137, 139, 140, 142, 143, 146, 151, 154, 155, 157, 158, 162, 180], "becaus": [3, 6, 18, 75, 76, 79, 80, 83, 84, 85, 87, 88, 89, 91, 101, 102, 103, 104, 105, 110, 112, 121, 124, 127, 133, 134, 139, 144, 146, 147, 148, 152, 153, 155, 157, 159, 163], "onli": [3, 6, 18, 29, 37, 43, 49, 51, 66, 68, 71, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 95, 96, 98, 99, 100, 101, 102, 104, 107, 108, 111, 117, 119, 121, 127, 129, 131, 132, 133, 134, 136, 137, 140, 141, 142, 143, 144, 146, 147, 151, 152, 153, 157, 158, 162, 175, 178, 182, 184], "here": [3, 29, 62, 76, 77, 80, 81, 82, 83, 84, 87, 88, 89, 90, 91, 94, 95, 96, 100, 103, 105, 107, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 126, 128, 129, 130, 131, 132, 134, 135, 137, 139, 140, 141, 142, 143, 144, 145, 149, 150, 151, 152, 153, 156, 159, 160, 161, 163], "encod": [3, 6, 29, 49, 70, 71, 82, 88, 89, 91, 106, 107, 109, 118, 121, 133, 134, 141, 166, 178], "color": [3, 76, 99, 109, 110, 111, 112, 117, 123, 125, 127, 128, 133, 134, 135, 137, 138, 139, 140, 141, 143, 147, 154, 157, 158, 162, 163, 164, 165, 180], "blue": [3, 76, 79, 97, 104, 111, 112, 133, 137, 141, 142, 143, 153, 158, 162, 164], "orang": [3, 76, 112, 117, 143, 158, 163, 164], "point": [3, 6, 15, 76, 80, 82, 84, 85, 92, 97, 102, 107, 108, 109, 110, 112, 118, 119, 121, 124, 133, 134, 137, 139, 141, 142, 143, 146, 153, 155, 158, 162, 164], "thu": [3, 6, 29, 37, 63, 82, 84, 88, 95, 97, 99, 100, 103, 104, 105, 107, 108, 109, 110, 111, 115, 118, 119, 120, 121, 124, 126, 129, 133, 134, 140, 141, 142, 146, 151, 152, 153, 154, 157, 158, 162, 163, 178], "each": [3, 6, 18, 25, 29, 36, 40, 49, 51, 68, 71, 76, 77, 78, 79, 82, 83, 84, 87, 88, 96, 97, 99, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 127, 128, 130, 133, 134, 135, 139, 140, 141, 143, 149, 151, 152, 153, 155, 156, 157, 158, 159, 161, 162, 163, 164, 165, 174, 178, 180, 186], "entir": [3, 35, 79, 87, 88, 108, 109, 119, 124, 126, 129, 137, 178], "wa": [3, 76, 83, 84, 92, 93, 97, 99, 100, 102, 104, 106, 109, 111, 112, 117, 121, 127, 130, 134, 135, 137, 139, 143, 153, 158, 160, 163, 164], "linear": [3, 6, 13, 15, 16, 29, 37, 39, 40, 42, 43, 44, 45, 49, 55, 60, 76, 82, 84, 87, 88, 89, 90, 91, 92, 95, 97, 100, 109, 112, 120, 128, 130, 131, 135, 136, 145, 146, 148, 152, 158, 159, 161, 163, 165, 173, 175, 178, 183], "decis": [3, 6, 10, 13, 15, 16, 18, 27, 35, 43, 60, 84, 88, 90, 92, 94, 98, 103, 104, 105, 111, 112, 114, 115, 118, 120, 121, 122, 123, 124, 128, 132, 133, 139, 141, 142, 143, 144, 147, 159, 160, 161, 164, 165, 171, 172, 173, 174, 175, 176, 178], "rule": [3, 82, 83, 120, 133, 134, 137, 141, 158, 174], "black": [3, 76, 82, 87, 94, 97, 99, 101, 104, 105, 106, 107, 108, 109, 111, 112, 117, 123, 125, 127, 128, 134, 135, 138, 139, 140, 147, 151, 155, 162, 163, 165], "dot": 3, "line": [3, 29, 44, 71, 76, 82, 110, 112, 117, 131, 133, 136, 137, 139, 141, 142, 143, 144, 146, 147, 154, 155, 158, 162, 163, 180, 186], "new": [3, 6, 29, 36, 40, 49, 76, 80, 82, 83, 84, 85, 87, 88, 89, 91, 95, 96, 97, 98, 100, 101, 103, 104, 110, 111, 114, 115, 117, 119, 123, 124, 131, 136, 139, 143, 149, 151, 152, 156, 161, 163, 164, 165], "accord": [3, 76, 137], "its": [3, 6, 18, 23, 29, 60, 63, 76, 81, 83, 84, 86, 87, 88, 95, 99, 100, 101, 103, 104, 105, 110, 113, 117, 119, 121, 122, 127, 133, 134, 137, 138, 140, 141, 143, 144, 146, 147, 150, 157, 158, 180], "posit": [3, 6, 27, 28, 29, 45, 49, 68, 105, 110, 112, 120, 134, 137, 140, 141, 143, 144, 146, 147, 155, 186], "respect": [3, 29, 43, 44, 87, 88, 92, 95, 100, 101, 103, 105, 119, 121, 133, 134, 136, 140, 141, 146, 148], "ly": [3, 134], "left": [3, 75, 76, 83, 94, 97, 101, 102, 103, 107, 109, 110, 111, 112, 117, 119, 120, 123, 129, 135, 137, 143, 153, 154, 158, 162, 164], "while": [3, 18, 29, 82, 83, 84, 87, 100, 104, 105, 107, 109, 110, 111, 112, 117, 118, 119, 121, 124, 127, 129, 131, 133, 134, 136, 137, 142, 143, 146, 154, 157, 162, 178], "right": [3, 76, 77, 78, 82, 87, 89, 91, 101, 110, 119, 124, 126, 129, 137, 143, 153, 162], "defin": [3, 18, 29, 36, 49, 58, 68, 75, 79, 84, 87, 88, 89, 91, 93, 96, 97, 101, 102, 103, 110, 111, 116, 125, 130, 131, 133, 134, 135, 136, 137, 139, 140, 142, 143, 149, 150, 151, 154, 155, 156, 157, 158, 160, 178, 180, 182, 183, 186], "higher": [3, 6, 27, 39, 44, 85, 86, 88, 99, 104, 106, 107, 110, 111, 120, 133, 134, 137, 138, 148, 153, 180], "dimens": [3, 44, 76, 133, 157], "would": [3, 18, 29, 51, 76, 79, 81, 82, 83, 86, 87, 89, 91, 99, 100, 101, 102, 103, 104, 106, 108, 109, 110, 112, 117, 118, 119, 121, 124, 127, 131, 133, 134, 136, 137, 138, 139, 140, 141, 143, 144, 146, 147, 150, 153, 157, 158, 162, 163], "hyperplan": 3, "howev": [3, 6, 22, 36, 82, 83, 84, 87, 88, 90, 92, 94, 97, 99, 101, 102, 104, 105, 106, 107, 108, 110, 111, 112, 115, 117, 118, 119, 120, 121, 124, 126, 127, 129, 133, 134, 135, 138, 139, 141, 143, 144, 146, 147, 148, 153, 155, 157, 158, 162, 163, 183], "depend": [3, 18, 22, 27, 28, 29, 37, 40, 79, 84, 87, 88, 99, 101, 103, 109, 110, 112, 119, 127, 131, 133, 134, 136, 137, 141, 143, 148, 151, 155, 158, 159], "A": [3, 6, 29, 36, 45, 55, 63, 66, 68, 76, 84, 88, 97, 99, 103, 104, 109, 118, 119, 134, 138, 139, 143, 146, 157, 163, 173, 174, 178, 184], "These": [3, 6, 23, 76, 79, 83, 87, 106, 121, 143, 152, 163, 183], "handl": [3, 73, 74, 82, 87, 88, 92, 106, 117, 139, 151, 166], "discret": [3, 87, 104, 108, 118, 141, 146], "1": [3, 4, 18, 27, 29, 43, 44, 46, 49, 51, 62, 68, 76, 78, 79, 82, 83, 84, 85, 87, 88, 90, 91, 92, 93, 94, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 135, 136, 137, 139, 140, 141, 142, 143, 144, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 162, 163, 164, 166, 178, 180, 186], "cat": [3, 93], "dog": 3, "logisticregress": [3, 45, 46, 75, 79, 81, 82, 84, 86, 87, 88, 89, 91, 93, 97, 101, 102, 129, 132, 133, 137, 141, 143, 148, 152, 158, 180, 182], "histgradientboostingclassifi": [3, 88, 90, 92, 118, 149, 151, 153, 154, 155, 156], "note": [3, 8, 9, 36, 48, 49, 50, 52, 54, 56, 64, 69, 76, 79, 82, 83, 84, 87, 88, 92, 94, 95, 99, 100, 101, 104, 105, 108, 109, 110, 112, 120, 121, 133, 137, 140, 141, 151, 152, 153, 157, 158, 163, 167, 178], "histor": 3, "reason": [3, 6, 18, 49, 60, 76, 78, 84, 90, 92, 99, 103, 104, 107, 110, 117, 119, 129, 133, 137, 143, 157], "confus": [3, 117, 152, 163, 183], "contrari": [3, 76, 87, 104, 110, 163], "what": [3, 6, 15, 24, 27, 28, 29, 35, 42, 43, 44, 49, 51, 52, 60, 62, 75, 76, 77, 78, 80, 81, 82, 84, 85, 86, 88, 96, 99, 101, 102, 103, 104, 105, 110, 120, 121, 133, 136, 137, 138, 140, 141, 142, 143, 152, 153, 158, 163, 178, 180], "suggest": 3, "procedur": [3, 6, 18, 49, 79, 82, 99, 103, 104, 112, 119, 121, 124, 127, 128, 139, 153, 157, 173, 180, 182], "how": [3, 18, 22, 23, 26, 29, 33, 34, 39, 43, 49, 58, 60, 66, 71, 75, 76, 77, 78, 79, 81, 82, 83, 84, 86, 87, 88, 93, 94, 98, 100, 102, 103, 105, 110, 111, 112, 117, 119, 121, 131, 133, 134, 136, 137, 138, 143, 144, 147, 151, 152, 153, 154, 155, 157, 158, 160, 162, 163, 164, 171, 176, 180, 182, 183], "well": [3, 6, 13, 15, 22, 68, 78, 84, 97, 101, 102, 105, 108, 109, 110, 111, 112, 117, 119, 120, 128, 137, 143, 152, 155, 162], "idea": [3, 76, 93, 100, 110, 117, 153], "behind": [3, 6, 13, 22, 120], "dataset": [3, 16, 18, 25, 29, 35, 37, 39, 40, 42, 44, 49, 55, 58, 62, 65, 66, 68, 71, 73, 75, 77, 78, 79, 80, 81, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 178, 180, 186], "evalu": [3, 18, 22, 23, 26, 29, 37, 45, 49, 58, 62, 67, 68, 76, 81, 82, 83, 86, 89, 90, 91, 92, 93, 94, 95, 97, 99, 100, 102, 103, 104, 108, 110, 112, 113, 115, 117, 118, 122, 124, 128, 129, 134, 138, 144, 145, 146, 147, 148, 149, 150, 151, 152, 155, 156, 157, 163, 178, 179, 183, 186], "separ": [3, 29, 41, 42, 45, 49, 66, 76, 78, 81, 82, 86, 88, 101, 106, 107, 108, 133, 137, 141, 153, 158, 162, 164, 166, 174, 178], "sever": [3, 13, 16, 23, 68, 79, 97, 99, 104, 110, 111, 112, 115, 117, 118, 120, 121, 124, 130, 133, 135, 137, 139, 142, 155], "time": [3, 18, 29, 49, 68, 76, 79, 82, 84, 87, 88, 89, 90, 91, 92, 93, 97, 99, 102, 103, 104, 105, 107, 108, 110, 112, 115, 117, 118, 119, 120, 121, 124, 127, 134, 137, 141, 143, 151, 154, 155, 158, 160, 164, 166, 173, 178], "get": [3, 6, 18, 34, 42, 49, 55, 62, 68, 76, 77, 78, 79, 80, 82, 83, 84, 85, 88, 89, 90, 91, 92, 97, 98, 99, 102, 103, 104, 105, 107, 109, 111, 112, 115, 116, 117, 124, 125, 126, 127, 129, 134, 137, 139, 143, 144, 145, 146, 147, 148, 151, 153, 154, 155, 157, 158, 161, 162, 163, 165, 166, 180, 181, 182], "s": [3, 4, 6, 17, 23, 25, 26, 29, 35, 36, 43, 49, 75, 76, 79, 80, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 117, 119, 120, 122, 123, 127, 128, 131, 132, 133, 134, 135, 136, 137, 138, 139, 141, 142, 143, 146, 148, 151, 152, 153, 154, 155, 158, 159, 162, 163, 183, 186], "uncertainti": [3, 79, 88, 112, 126, 129, 153], "see": [3, 8, 9, 39, 48, 50, 52, 54, 56, 64, 69, 76, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 94, 97, 98, 100, 101, 102, 103, 106, 107, 108, 109, 110, 111, 112, 117, 118, 120, 122, 124, 125, 127, 129, 133, 134, 136, 138, 139, 140, 141, 142, 143, 146, 148, 151, 152, 153, 154, 155, 157, 158, 159, 160, 162, 163, 164, 167], "more": [3, 18, 29, 36, 44, 46, 49, 55, 58, 62, 76, 79, 82, 83, 84, 87, 89, 91, 92, 94, 95, 98, 99, 100, 101, 105, 106, 107, 109, 110, 111, 112, 117, 118, 119, 120, 121, 127, 131, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147, 151, 152, 153, 154, 155, 157, 158, 159, 162, 163, 186], "detail": [3, 13, 18, 29, 39, 63, 76, 79, 80, 82, 83, 85, 87, 88, 89, 91, 95, 97, 100, 107, 109, 110, 117, 119, 120, 133, 139, 141, 143, 144, 147, 148, 151, 159, 171, 172, 186], "n_sampl": [3, 112, 117, 127, 128, 133, 139, 141, 142, 162], "row": [3, 18, 62, 66, 76, 87, 93, 104, 106, 109, 112, 131, 134, 136, 139, 151, 154, 155, 157, 186], "n_featur": [3, 44, 119, 121, 127, 128, 133, 139, 141, 142], "column": [3, 6, 18, 29, 37, 43, 44, 49, 62, 66, 71, 75, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 89, 90, 91, 92, 93, 95, 96, 100, 101, 103, 104, 106, 107, 108, 109, 110, 112, 117, 119, 121, 122, 123, 125, 127, 128, 131, 133, 134, 136, 139, 140, 142, 143, 144, 145, 146, 147, 148, 149, 151, 153, 154, 155, 156, 157, 162, 163, 165, 178, 186], "equal": [3, 6, 29, 43, 45, 46, 62, 84, 102, 117, 134, 151, 152, 163], "flower": 3, "4": [3, 4, 18, 29, 75, 76, 78, 82, 83, 84, 85, 86, 87, 93, 94, 97, 100, 101, 102, 104, 106, 107, 108, 109, 110, 112, 117, 119, 122, 125, 127, 131, 133, 134, 136, 137, 139, 140, 143, 148, 151, 152, 153, 154, 155, 157, 159, 162, 164, 166, 178], "length": [3, 6, 18, 29, 77, 78, 82, 83, 106, 107, 111, 114, 123, 130, 131, 132, 135, 136, 137, 138, 140, 141, 143, 151, 155, 158, 159, 160, 161, 162, 163, 164, 165, 186], "width": [3, 118], "common": [3, 60, 79, 87, 103, 112, 134, 146, 164, 186], "math": [3, 106], "matric": [3, 87], "capit": [3, 76, 79, 81, 82, 83, 84, 86, 87, 88, 151, 152, 155], "letter": [3, 104, 109], "f": [3, 8, 9, 18, 29, 48, 50, 52, 54, 56, 64, 69, 76, 79, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 97, 99, 100, 102, 103, 104, 109, 110, 111, 112, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 134, 135, 136, 137, 138, 139, 140, 141, 143, 146, 147, 148, 151, 152, 153, 155, 156, 158, 162, 164, 167, 180], "iter": [3, 29, 68, 79, 84, 87, 102, 103, 104, 115, 119, 124, 134, 153, 154, 155], "optim": [3, 22, 23, 45, 66, 84, 95, 99, 100, 111, 116, 117, 118, 120, 125, 129, 131, 134, 136, 138, 143, 146, 148, 151, 152, 153, 155, 157, 162, 178, 184, 186], "befor": [3, 45, 49, 76, 80, 82, 84, 85, 87, 102, 104, 106, 110, 118, 121, 126, 129, 134, 140, 143, 146, 160], "converg": [3, 68, 84, 87], "algorithm": [3, 13, 16, 18, 24, 35, 76, 83, 84, 87, 97, 110, 111, 115, 117, 118, 119, 121, 124, 126, 127, 129, 131, 136, 139, 141, 158, 159], "over": [3, 15, 24, 29, 39, 40, 76, 95, 97, 99, 100, 103, 105, 110, 114, 118, 120, 123, 146, 149, 151, 156, 160, 162, 171, 174], "done": [3, 6, 75, 83, 91, 118, 119, 121, 129, 131, 133, 134, 136, 152, 153, 155, 158, 162], "monitor": [3, 6, 29], "score": [3, 18, 27, 28, 29, 37, 49, 60, 62, 68, 75, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 94, 95, 96, 97, 98, 99, 100, 101, 104, 105, 109, 110, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 127, 128, 129, 134, 136, 137, 139, 141, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 164, 176, 178, 180, 186], "jargon": [3, 83, 84], "onc": [3, 6, 18, 29, 82, 84, 92, 97, 102, 104, 112, 119, 121, 141, 143, 145, 148, 149, 150, 151, 154, 155, 156, 157, 160, 180], "quantiti": [3, 6, 87, 88, 107, 110], "size": [3, 51, 58, 60, 61, 87, 94, 95, 100, 107, 109, 111, 112, 119, 129, 133, 158, 166], "weight": [3, 29, 40, 42, 45, 46, 49, 82, 95, 97, 100, 110, 111, 117, 130, 131, 132, 134, 135, 136, 138, 139, 140, 141, 158, 173], "dure": [3, 13, 22, 25, 29, 33, 34, 39, 40, 58, 60, 74, 75, 76, 82, 87, 89, 91, 102, 104, 107, 111, 120, 127, 134, 138, 144, 147, 151, 153, 155, 158, 161, 163, 165, 171, 172, 183, 184], "four": [3, 107, 108, 143], "never": [3, 18, 58, 76, 82, 83, 87, 111, 112, 137, 146, 151, 155, 164, 180], "seen": [3, 25, 79, 81, 83, 84, 86, 87, 104, 137, 140, 143, 151, 152, 153, 161, 165], "aspect": [3, 6, 22, 34, 79, 84, 98, 128, 134, 173], "configur": [3, 84, 116, 125, 139, 151], "learnt": [3, 60, 98, 110, 139, 158], "nearest": [3, 62, 82, 83, 84, 105, 183, 186], "neighbor": [3, 62, 80, 82, 83, 84, 85, 105, 150, 157, 183, 186], "approach": [3, 6, 14, 23, 34, 40, 49, 60, 74, 75, 87, 102, 118, 133, 138, 141, 151, 153, 155, 157, 172, 184], "polynomi": [3, 44, 55, 105, 112, 133, 139], "sai": [3, 62, 110, 137, 158], "degre": [3, 44, 49, 55, 105, 110, 112, 131, 133, 134, 136, 139], "between": [3, 6, 13, 15, 18, 22, 29, 40, 49, 55, 58, 60, 62, 76, 78, 79, 82, 84, 87, 95, 99, 100, 103, 105, 107, 108, 110, 112, 114, 117, 119, 123, 126, 127, 129, 131, 133, 134, 135, 136, 137, 139, 140, 141, 143, 146, 154, 155, 157, 159, 162, 163, 171, 186], "10": [3, 4, 18, 25, 36, 43, 49, 62, 75, 76, 79, 80, 82, 85, 87, 92, 94, 96, 97, 98, 99, 100, 101, 104, 105, 106, 107, 108, 109, 110, 112, 115, 117, 118, 119, 120, 122, 124, 129, 131, 132, 133, 134, 136, 137, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 162, 164, 178, 180, 186], "impact": [3, 18, 45, 49, 58, 87, 89, 90, 91, 92, 98, 99, 105, 115, 119, 124, 132, 134, 146, 154, 157, 162, 180, 182, 183, 184, 186], "comput": [3, 6, 29, 49, 62, 68, 76, 79, 80, 83, 84, 85, 87, 88, 90, 92, 94, 95, 96, 98, 99, 100, 101, 102, 104, 105, 110, 111, 112, 115, 117, 118, 119, 120, 124, 126, 127, 129, 131, 133, 135, 136, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 150, 153, 154, 155, 157, 158, 160, 163, 164, 180], "inde": [3, 18, 29, 76, 82, 83, 84, 88, 92, 95, 97, 99, 100, 103, 104, 106, 107, 108, 109, 110, 111, 112, 117, 118, 119, 120, 126, 127, 128, 129, 134, 136, 137, 138, 139, 141, 142, 143, 144, 146, 147, 148, 152, 153, 155, 158, 159, 162, 163, 164], "usual": [3, 17, 82, 84, 88, 97, 103, 105, 107, 131, 136, 143, 154, 155], "inspect": [3, 6, 29, 62, 66, 84, 93, 104, 111, 116, 119, 125, 128, 132, 133, 137, 139, 141, 142, 151, 154, 155, 158, 160, 162, 164, 186], "regard": [3, 13, 14, 22, 24, 33, 34, 39, 43, 73, 75, 84, 87, 89, 91, 94, 95, 97, 98, 100, 102, 105, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 129, 130, 131, 132, 134, 135, 136, 137, 138, 140, 141, 143, 144, 145, 146, 147, 148, 149, 156, 158, 160, 161, 162, 163, 164, 165], "tune": [3, 13, 17, 26, 35, 40, 44, 45, 49, 95, 99, 100, 105, 113, 120, 121, 122, 127, 129, 133, 137, 150, 154, 156, 157, 172, 178, 183, 186], "maxim": [3, 49, 97, 99, 134, 148, 149, 150, 151, 155, 156, 157, 158, 176, 183], "involv": [3, 6, 76, 101, 104, 152], "grid": [3, 99, 107, 116, 119, 120, 125, 134, 150, 153, 155, 157, 162, 166, 176, 178, 179, 180, 184, 186], "search": [3, 49, 98, 99, 116, 118, 119, 120, 121, 122, 125, 134, 138, 149, 150, 153, 156, 157, 162, 166, 176, 178, 179, 180, 183, 184, 186], "random": [3, 11, 13, 14, 15, 17, 18, 37, 49, 53, 75, 82, 97, 101, 102, 103, 104, 107, 109, 110, 112, 114, 115, 117, 118, 120, 123, 124, 126, 127, 128, 129, 133, 139, 150, 151, 154, 157, 166, 174, 179, 180, 184], "further": [3, 39, 76, 97, 98, 133, 139, 140, 153, 162, 164], "read": [3, 6, 76, 97, 107, 110, 146, 186], "post": [3, 51, 71, 172], "machin": [3, 23, 29, 34, 36, 40, 58, 60, 66, 71, 74, 76, 82, 83, 84, 86, 87, 88, 89, 91, 93, 95, 96, 99, 100, 101, 102, 103, 104, 112, 121, 126, 127, 128, 129, 133, 134, 138, 139, 141, 142, 143, 146, 151, 155], "mooc": [3, 76, 83, 93, 94, 95, 98, 100, 104, 105, 111, 113, 114, 115, 118, 120, 121, 122, 123, 124, 130, 131, 132, 134, 135, 136, 137, 138, 140, 141, 143, 144, 145, 146, 147, 148, 158, 160, 161, 162, 163, 164, 165], "refer": [3, 14, 23, 34, 40, 60, 74, 75, 76, 83, 84, 89, 91, 94, 95, 96, 97, 98, 100, 101, 104, 105, 109, 111, 112, 113, 114, 115, 117, 118, 120, 121, 122, 123, 124, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 152, 158, 160, 161, 162, 163, 164, 165, 172, 184], "process": [3, 6, 36, 60, 68, 74, 75, 76, 88, 103, 112, 118, 126, 127, 129, 134, 148, 152, 153, 160, 183], "make": [3, 6, 24, 25, 29, 45, 46, 49, 53, 58, 62, 63, 73, 75, 76, 79, 80, 82, 84, 85, 87, 88, 89, 91, 92, 93, 94, 95, 97, 99, 100, 101, 103, 104, 105, 106, 107, 109, 110, 111, 114, 115, 116, 117, 118, 119, 120, 121, 123, 124, 125, 126, 127, 128, 129, 131, 133, 134, 136, 137, 138, 139, 140, 141, 142, 143, 145, 146, 148, 149, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 173], "appli": [3, 6, 15, 16, 17, 18, 24, 26, 27, 29, 39, 44, 45, 46, 49, 51, 53, 55, 62, 63, 66, 68, 71, 75, 84, 87, 88, 93, 102, 105, 106, 107, 109, 133, 140, 142, 148, 151, 152, 154, 157, 162, 164, 173, 174, 176, 180, 182, 186], "unlabel": 3, "word": [3, 29, 138, 161, 165, 180], "equival": [3, 18, 29, 49, 75, 76, 83, 95, 100, 104, 119, 132, 137, 139, 141, 143, 157, 178], "unseen": [3, 68, 76, 102, 103, 119, 142, 158], "notion": 3, "out": [3, 6, 25, 75, 76, 79, 82, 83, 87, 96, 98, 101, 103, 104, 110, 112, 115, 116, 119, 120, 124, 125, 129, 132, 134, 137, 143, 151, 153, 160, 161, 164, 165], "ti": 3, "definit": [3, 139, 152], "distribut": [3, 6, 44, 76, 77, 78, 84, 96, 97, 101, 102, 103, 104, 105, 106, 107, 108, 109, 118, 133, 134, 141, 146, 148, 150, 153, 155, 157, 159, 163, 180], "condit": [3, 6, 110, 134, 141], "check": [3, 6, 29, 49, 62, 76, 79, 82, 83, 84, 86, 87, 88, 95, 97, 98, 100, 102, 103, 104, 105, 107, 109, 111, 112, 113, 114, 116, 117, 118, 120, 121, 122, 123, 125, 126, 127, 128, 129, 131, 134, 136, 138, 139, 140, 142, 143, 144, 147, 151, 153, 154, 158, 159, 161, 162, 163, 165, 171, 178], "wikipedia": [3, 60, 112], "articl": [3, 6, 60, 112], "finish": [3, 134], "_": [3, 76, 78, 83, 84, 88, 94, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 117, 122, 123, 124, 125, 127, 128, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147, 152, 154, 158, 159, 162, 163, 164, 165], "end": [3, 84, 87, 94, 95, 97, 98, 100, 101, 102, 104, 105, 107, 111, 113, 114, 115, 118, 120, 121, 122, 123, 124, 130, 131, 132, 134, 135, 136, 137, 138, 140, 141, 143, 144, 145, 146, 147, 148, 156, 158, 160, 161, 162, 163, 164, 165], "thei": [3, 6, 29, 49, 58, 68, 76, 80, 82, 84, 85, 87, 88, 92, 101, 102, 105, 106, 109, 110, 112, 118, 119, 121, 133, 134, 139, 143, 146, 152, 158, 163, 165, 172, 178, 183], "avail": [3, 6, 29, 36, 51, 75, 76, 77, 78, 79, 82, 83, 93, 97, 98, 106, 108, 109, 114, 123, 127, 129, 134, 138, 140, 143, 152, 155, 178], "after": [3, 18, 28, 49, 79, 87, 104, 106, 112, 115, 118, 119, 122, 124, 138, 152, 156, 157], "been": [3, 76, 79, 82, 87, 94, 102, 104, 110, 111, 118, 124, 127, 136, 141, 152, 153, 158], "slope": [3, 29, 107, 140], "intercept": [3, 40, 130, 131, 135, 136, 137, 138, 139, 140, 141, 158], "one": [3, 6, 14, 18, 25, 37, 43, 44, 49, 60, 68, 71, 75, 76, 78, 79, 81, 82, 83, 84, 86, 87, 88, 90, 92, 95, 96, 97, 99, 100, 101, 102, 104, 107, 109, 110, 111, 117, 118, 119, 121, 128, 133, 134, 136, 138, 139, 141, 143, 144, 146, 147, 151, 152, 153, 157, 158, 159, 162, 164, 174, 186], "section": [3, 79, 82, 87, 88, 94, 95, 97, 98, 100, 104, 105, 111, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 130, 131, 132, 134, 135, 136, 137, 138, 140, 141, 142, 143, 144, 145, 146, 147, 148, 155, 158, 160, 161, 162, 163, 164, 165], "about": [3, 13, 17, 22, 24, 29, 33, 36, 39, 58, 62, 66, 73, 74, 76, 79, 83, 84, 87, 96, 98, 101, 104, 105, 106, 108, 110, 117, 120, 133, 137, 141, 142, 146, 151, 159, 163, 171, 180, 183, 186], "also": [3, 13, 22, 25, 27, 29, 33, 36, 46, 60, 62, 76, 82, 83, 84, 87, 88, 89, 90, 91, 92, 95, 98, 99, 100, 103, 104, 105, 106, 107, 110, 111, 112, 115, 116, 118, 119, 121, 124, 125, 127, 133, 134, 137, 139, 140, 141, 142, 143, 146, 152, 153, 154, 155, 157, 158, 164], "python": [3, 6, 29, 36, 68, 73, 76, 79, 89, 91, 104, 112, 118, 134, 144, 147], "pass": [3, 18, 29, 49, 62, 68, 75, 79, 87, 88, 89, 91, 95, 99, 100, 104, 112, 140, 144, 145, 147, 148, 150, 151, 153, 157, 158, 164, 186], "anoth": [3, 6, 18, 60, 75, 76, 79, 99, 101, 103, 112, 121, 127, 128, 130, 134, 135, 139, 142, 143, 146, 162], "includ": [3, 29, 34, 36, 66, 87, 99, 106, 127, 128, 131, 134, 136, 137, 139, 152, 175], "gridsearchcv": [3, 6, 99, 120, 125, 150, 151, 153, 155, 157, 162, 178, 180, 186], "someth": [3, 92, 142, 152], "occur": [3, 87, 134], "your": [3, 6, 34, 39, 62, 75, 76, 77, 80, 81, 85, 87, 88, 89, 90, 91, 92, 95, 96, 100, 102, 113, 114, 115, 116, 119, 126, 129, 130, 131, 132, 136, 144, 145, 149, 150, 156, 160, 161, 165, 178, 180], "stick": 3, "too": [3, 6, 63, 83, 93, 99, 104, 105, 115, 118, 119, 121, 124, 133, 134, 136, 137, 151, 157, 162, 180], "so": [3, 6, 14, 29, 49, 68, 76, 78, 84, 86, 87, 89, 91, 94, 95, 100, 101, 102, 103, 104, 106, 107, 110, 111, 116, 117, 119, 125, 131, 133, 134, 136, 137, 138, 139, 143, 144, 147, 152, 153, 157, 164, 178], "up": [3, 6, 10, 35, 45, 76, 79, 82, 87, 97, 99, 101, 104, 109, 110, 127, 130, 135, 139, 140, 143, 151, 163, 166, 183], "nois": [3, 49, 55, 60, 105, 112, 117, 133, 137, 139, 142], "rather": [3, 29, 34, 79, 82, 107, 108, 141, 143, 148, 155, 157], "than": [3, 6, 18, 27, 28, 29, 34, 36, 44, 49, 55, 62, 75, 76, 79, 82, 83, 84, 85, 86, 87, 88, 91, 92, 94, 96, 97, 99, 100, 101, 103, 104, 105, 106, 107, 110, 111, 112, 118, 119, 120, 121, 124, 126, 128, 129, 130, 131, 133, 134, 135, 136, 137, 141, 142, 143, 146, 148, 150, 151, 153, 154, 155, 157, 158, 161, 162, 165, 175, 178, 180, 186], "relev": [3, 62, 82, 97, 110, 143], "pattern": [3, 23, 76, 97, 126, 129, 144, 147, 153], "tell": [3, 76, 105, 110], "great": [3, 6, 51], "poorli": [3, 91], "real": [3, 51, 76, 82, 83, 87, 88, 102, 104, 130, 135, 143, 146, 163], "world": [3, 163], "fit_predict": 3, "kneighborsclassifi": [3, 62, 80, 83, 85, 186], "decisiontreeregressor": [3, 18, 94, 98, 103, 104, 105, 112, 113, 117, 120, 121, 122, 139, 162, 163, 165, 178], "One": [3, 51, 62, 71, 75, 79, 80, 85, 87, 102, 103, 108, 110, 118, 143, 146, 153], "focu": [3, 18, 76, 82, 104, 106, 109, 111, 117, 134, 143, 146, 151, 152, 158], "were": [3, 29, 68, 79, 82, 88, 97, 104, 105, 108, 117, 126, 129, 130, 133, 135, 143, 155, 157, 162, 165], "If": [3, 6, 28, 29, 37, 43, 55, 68, 76, 79, 83, 87, 94, 95, 97, 98, 99, 100, 103, 104, 105, 109, 110, 111, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 127, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 152, 153, 157, 158, 160, 161, 162, 163, 164, 165, 176, 186], "do": [3, 6, 17, 18, 29, 60, 68, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 91, 92, 93, 96, 99, 101, 103, 104, 105, 106, 109, 115, 118, 119, 121, 124, 126, 127, 129, 131, 133, 134, 136, 138, 139, 143, 144, 147, 151, 152, 153, 154, 163, 180, 182, 186], "1d": [3, 29, 139], "5": [3, 4, 18, 29, 62, 68, 75, 76, 78, 79, 83, 84, 85, 86, 87, 88, 93, 94, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 128, 131, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 146, 148, 151, 153, 154, 155, 157, 158, 159, 162, 163, 164, 165, 166, 182, 183, 186], "someon": [3, 76], "come": [3, 6, 29, 58, 76, 82, 117, 120, 127, 130, 135, 140, 152, 153, 163], "doe": [3, 6, 18, 24, 29, 36, 49, 76, 79, 84, 87, 88, 90, 91, 92, 94, 97, 98, 99, 100, 102, 103, 107, 110, 119, 122, 133, 134, 137, 141, 142, 146, 148, 151, 155, 157, 158, 163, 180, 184], "15": [3, 4, 76, 82, 84, 87, 94, 105, 106, 116, 118, 119, 122, 125, 143, 155, 157, 158, 164, 178], "continu": [3, 6, 37, 42, 44, 66, 76, 82, 104, 106, 110, 140, 141, 143, 146, 148, 159, 162], "price": [3, 51, 75, 93, 94, 104, 106, 109, 110, 145, 146, 148], "descript": [3, 29, 51, 75, 76, 80, 85, 94, 95, 98, 100, 104, 105, 109, 111, 113, 114, 115, 118, 120, 121, 122, 123, 124, 130, 131, 132, 134, 135, 136, 137, 138, 140, 141, 143, 144, 145, 146, 147, 148, 158, 160, 161, 162, 163, 164, 165, 166], "room": [3, 51, 104, 109, 110], "surfac": [3, 29], "locat": [3, 77, 78, 94, 106, 107, 109, 141, 154], "ag": [3, 76, 79, 81, 82, 83, 84, 86, 87, 88, 104, 109, 110, 134, 151, 152, 155], "mri": 3, "scan": [3, 6, 152], "want": [3, 18, 76, 77, 78, 82, 83, 87, 90, 92, 93, 94, 95, 97, 98, 100, 102, 103, 104, 105, 107, 111, 113, 114, 115, 118, 120, 121, 122, 123, 124, 127, 128, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 151, 152, 153, 158, 159, 160, 161, 162, 163, 164, 165, 178, 180, 186], "tree": [3, 6, 10, 13, 15, 16, 17, 18, 60, 76, 84, 87, 88, 90, 92, 94, 98, 103, 104, 105, 110, 111, 112, 114, 115, 116, 118, 120, 121, 122, 123, 124, 125, 128, 133, 139, 144, 147, 149, 151, 155, 156, 159, 160, 161, 164, 165, 171, 172, 173, 174, 175, 176, 178], "piecewis": [3, 133, 163, 175], "constant": [3, 24, 86, 110, 131, 133, 136, 137, 139, 163, 175], "given": [3, 6, 18, 29, 43, 51, 60, 68, 82, 84, 87, 96, 99, 101, 102, 104, 106, 108, 109, 110, 112, 117, 121, 128, 132, 133, 134, 136, 137, 138, 140, 141, 143, 148, 153, 155, 164, 173, 180, 182, 183], "output": [3, 18, 42, 76, 79, 84, 87, 88, 103, 104, 107, 110, 112, 130, 131, 133, 135, 136, 141, 143, 148, 164], "correspond": [3, 18, 29, 49, 76, 79, 82, 87, 88, 89, 91, 97, 99, 104, 105, 106, 107, 108, 109, 110, 112, 114, 123, 136, 140, 141, 143, 151, 152, 154, 155, 163, 175, 178], "ridg": [3, 40, 45, 46, 49, 109, 110, 112, 134, 137], "order": [3, 6, 18, 29, 40, 49, 71, 76, 84, 88, 91, 92, 93, 97, 102, 104, 106, 116, 121, 125, 134, 140, 151, 154, 155, 186], "shrink": [3, 45, 46, 134, 137], "constrain": [3, 40, 45, 63, 105, 133], "toward": [3, 45, 46, 110, 127, 134, 137, 141], "zero": [3, 28, 29, 42, 44, 45, 46, 55, 58, 76, 87, 105, 110, 134, 137, 139, 141], "2d": [3, 133, 139], "singl": [3, 15, 16, 18, 24, 25, 27, 28, 29, 35, 42, 43, 44, 45, 46, 49, 51, 55, 62, 66, 68, 71, 75, 76, 79, 82, 84, 87, 88, 93, 96, 99, 101, 102, 103, 104, 110, 112, 117, 120, 121, 122, 127, 128, 130, 131, 133, 135, 136, 139, 143, 144, 146, 147, 151, 152, 153, 158, 162, 164, 173, 174, 175, 176, 178, 180, 182, 186], "orient": [3, 110, 137, 164], "clf": 3, "give": [3, 6, 14, 22, 24, 29, 33, 55, 58, 60, 73, 76, 79, 84, 86, 87, 88, 97, 98, 99, 102, 104, 107, 108, 110, 111, 112, 117, 118, 119, 120, 121, 127, 134, 137, 138, 139, 141, 143, 146, 153, 157, 158, 164], "concret": [3, 29, 60], "graphic": [3, 68, 88, 102, 109, 140], "plot": [3, 18, 29, 49, 62, 68, 76, 77, 78, 84, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 116, 117, 123, 125, 127, 128, 130, 132, 133, 134, 135, 137, 138, 139, 140, 141, 142, 143, 144, 146, 147, 153, 154, 155, 157, 158, 159, 160, 161, 162, 163, 164, 165, 180], "compos": [3, 75, 76, 83, 87, 88, 89, 90, 91, 92, 93, 96, 101, 106, 121, 146, 149, 151, 153, 155, 156, 162], "sinc": [3, 76, 79, 84, 95, 99, 100, 101, 102, 104, 107, 108, 109, 110, 111, 112, 117, 118, 119, 121, 127, 134, 138, 141, 142, 143, 146, 151, 158, 159, 163, 164], "potenti": [3, 46, 51, 76, 84, 88, 98, 104, 105, 118, 138, 142, 143, 153, 182], "choic": [3, 29, 36, 45, 55, 58, 60, 87, 100, 101, 104, 107, 109, 110, 112, 134, 138, 148, 151, 155, 157, 166, 186], "circl": [3, 76, 109, 112, 133, 142], "vs": [3, 84, 87, 137, 143, 164], "squar": [3, 28, 60, 107, 134, 135, 138, 139, 146, 148], "boil": 3, "down": [3, 6, 119], "fact": [3, 18, 84, 86, 92, 107, 117, 134, 155, 165, 178], "exactli": [3, 45, 58, 62, 82, 92, 97, 142, 186], "know": [3, 6, 88, 95, 100, 104, 105, 106, 109, 112, 117, 129, 134, 139, 143, 151], "frame": [3, 106, 107, 108, 109], "scienc": [3, 6, 36, 97, 107], "solv": [3, 6, 29, 45, 62, 76, 82, 88, 97, 100, 102, 104, 107, 108, 134, 138, 139, 140, 141, 146, 163, 186], "might": [3, 6, 29, 37, 51, 75, 86, 87, 88, 90, 92, 97, 98, 102, 103, 104, 105, 107, 110, 119, 135, 143, 146, 151, 155, 164], "speci": [3, 18, 77, 78, 111, 132, 137, 141, 158, 159, 160, 162, 164, 186], "commonli": [3, 76, 82, 83], "denot": 3, "eventu": 3, "ideal": [3, 104, 143, 146], "let": [3, 6, 18, 25, 44, 49, 75, 76, 79, 80, 82, 83, 84, 85, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 117, 119, 127, 128, 131, 132, 133, 134, 135, 136, 137, 138, 139, 142, 143, 146, 148, 151, 152, 155, 158, 159, 162, 163, 186], "On": [3, 6, 29, 82, 84, 85, 88, 93, 99, 104, 110, 111, 112, 119, 124, 126, 129, 133, 134, 136, 137, 138, 139, 142, 143, 146, 151, 153, 155, 158, 163, 164, 165], "figur": [3, 27, 79, 82, 102, 104, 110, 111, 112, 117, 141, 153, 154, 155, 158, 164, 180], "mathemat": [3, 60, 95, 100, 133, 139, 140, 141, 146], "b": [3, 15, 16, 17, 18, 24, 25, 26, 27, 28, 29, 35, 37, 42, 43, 44, 45, 46, 49, 51, 53, 55, 62, 63, 66, 68, 71, 75, 130, 135, 140, 155, 157, 173, 174, 175, 176, 178, 180, 182, 186], "creat": [3, 29, 45, 49, 62, 71, 73, 74, 75, 79, 80, 82, 84, 85, 87, 88, 95, 96, 98, 100, 101, 102, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 120, 122, 123, 124, 125, 126, 127, 129, 130, 131, 132, 134, 135, 136, 137, 139, 141, 142, 143, 144, 145, 147, 148, 151, 152, 153, 155, 158, 160, 161, 163, 164, 165, 174, 178, 183], "infin": 3, "vari": [3, 18, 82, 95, 98, 100, 102, 105, 107, 110, 125, 127, 134, 138, 140, 143, 152, 157, 178], "fulfil": 3, "requir": [3, 6, 13, 18, 22, 29, 33, 36, 39, 40, 44, 49, 58, 62, 73, 75, 76, 79, 82, 84, 88, 95, 100, 101, 107, 111, 118, 119, 134, 148, 153, 155, 157, 162, 171, 178, 183, 186], "minim": [3, 6, 40, 60, 66, 94, 99, 104, 105, 137, 138, 146, 148, 158, 174], "sum": [3, 40, 42, 43, 60, 76, 83, 85, 117, 135, 141, 143], "error": [3, 6, 16, 28, 29, 40, 42, 53, 55, 58, 60, 61, 63, 76, 79, 83, 89, 91, 94, 97, 98, 99, 105, 111, 113, 114, 115, 117, 118, 119, 121, 122, 123, 124, 130, 131, 134, 135, 136, 138, 139, 142, 143, 145, 146, 148, 149, 156, 166, 174], "red": [3, 27, 79, 104, 111, 112, 117, 133, 137, 141, 142, 153, 162], "best": [3, 13, 18, 22, 33, 39, 55, 60, 62, 76, 93, 99, 100, 102, 105, 113, 115, 116, 118, 119, 121, 122, 124, 125, 130, 134, 135, 137, 138, 139, 143, 146, 149, 150, 151, 152, 153, 155, 156, 157, 158, 171, 180, 183, 184, 186], "possibl": [3, 6, 15, 29, 36, 42, 44, 60, 62, 66, 71, 76, 84, 87, 94, 98, 99, 102, 104, 105, 110, 112, 118, 119, 121, 129, 130, 131, 133, 134, 135, 136, 137, 139, 141, 142, 146, 148, 150, 151, 153, 154, 157, 161, 163, 164, 165, 180, 186], "abstract": [3, 107], "manner": [3, 14, 29, 87, 97, 134, 148], "state": [3, 6, 14, 62, 76, 82, 83, 84, 87, 88, 109, 151, 155], "jockei": 3, "wheel": 3, "i": [3, 13, 18, 20, 22, 29, 49, 73, 74, 75, 76, 79, 82, 83, 84, 86, 87, 88, 91, 92, 98, 99, 102, 104, 110, 112, 117, 118, 119, 120, 130, 131, 133, 134, 135, 136, 138, 141, 143, 146, 148, 151, 157, 158, 166, 180, 186], "support": [3, 6, 84, 90, 92, 95, 100, 133, 139, 142, 144, 147, 164], "standardscal": [3, 29, 49, 62, 68, 75, 79, 84, 88, 90, 92, 93, 95, 100, 101, 102, 109, 110, 132, 133, 137, 141, 142, 150, 152, 157, 178, 180, 182, 186], "columntransform": [3, 74, 88, 90, 92, 93, 133, 149, 151, 153, 155, 156], "enough": [3, 6, 91, 92, 101, 104, 105, 117, 119, 137, 142, 146, 152, 158, 162, 164, 178], "flexibl": [3, 6, 55, 58, 60, 63, 95, 100, 105, 121, 142, 158], "opposit": 3, "cluster": [3, 104, 173], "whose": [3, 83, 118, 152], "group": [3, 6, 20, 25, 29, 76, 102, 103, 104, 109, 166], "subset": [3, 17, 42, 45, 49, 73, 76, 79, 82, 83, 88, 93, 104, 107, 109, 119, 121, 124, 126, 127, 128, 129, 149, 156, 158, 159, 162, 178], "them": [3, 6, 13, 62, 76, 78, 79, 84, 87, 88, 96, 99, 101, 104, 110, 112, 114, 118, 119, 120, 123, 131, 133, 134, 136, 139, 141, 143, 146, 151, 152, 153, 157, 161, 164, 165, 178, 186], "broad": 3, "topic": [3, 104, 109], "custom": [3, 139], "commerc": 3, "websit": [3, 36, 51, 80, 85], "although": 3, "mention": [3, 51, 79, 95, 100, 103, 106, 111, 118, 120, 133, 134, 137, 138, 141, 143, 144, 146, 147, 152, 155, 165], "cover": [3, 52, 76, 79, 82, 87, 88, 137], "impli": [3, 162], "fix": [3, 29, 49, 55, 60, 87, 95, 100, 119, 134, 150, 151, 157, 162, 164, 178, 180, 184], "like": [3, 6, 18, 25, 29, 46, 55, 76, 82, 83, 87, 88, 89, 91, 99, 101, 104, 106, 108, 110, 111, 112, 119, 127, 134, 135, 139, 140, 141, 143, 144, 147, 148, 152], "necessari": [3, 6, 45, 76, 119, 133, 153], "subdivid": [3, 158], "select": [3, 6, 13, 15, 16, 17, 18, 22, 23, 24, 25, 26, 27, 28, 29, 33, 34, 35, 39, 42, 43, 44, 45, 46, 49, 51, 53, 55, 62, 63, 66, 68, 71, 75, 77, 78, 79, 81, 82, 84, 86, 89, 90, 91, 92, 99, 102, 104, 110, 112, 117, 119, 121, 125, 126, 129, 130, 135, 138, 139, 141, 151, 152, 153, 154, 157, 159, 171, 173, 174, 175, 176, 178, 180, 182, 186], "final": [3, 13, 23, 39, 45, 58, 62, 73, 83, 84, 87, 88, 99, 103, 104, 107, 109, 112, 116, 117, 119, 124, 125, 126, 128, 129, 134, 137, 144, 145, 147, 148, 151, 152, 153, 161, 165, 183], "sometim": [3, 6, 60, 88, 101, 143, 146, 153, 155], "clear": [3, 76, 100, 105, 162], "mani": [3, 6, 29, 43, 62, 75, 76, 77, 78, 83, 84, 87, 88, 99, 101, 102, 104, 105, 106, 109, 112, 119, 121, 131, 133, 134, 136, 143, 152, 157, 186], "need": [3, 6, 22, 24, 29, 37, 40, 62, 68, 76, 80, 82, 84, 85, 87, 88, 93, 95, 99, 100, 104, 105, 107, 110, 111, 112, 117, 119, 120, 121, 122, 133, 134, 137, 138, 139, 142, 144, 145, 147, 148, 149, 151, 152, 153, 155, 156, 162, 176, 178], "criteria": [3, 119], "ml": [3, 6, 97], "cheatsheet": 3, "readthedoc": 3, "io": [3, 36], "en": 3, "latest": [3, 28], "googl": 3, "develop": [3, 6, 36, 73, 76, 89, 91, 107, 131, 136, 139], "com": [3, 6, 36], "advanc": [3, 6, 36, 73, 90, 92], "terminolog": 3, "modifi": [4, 6, 118, 120, 139], "run": [4, 6, 18, 45, 68, 80, 85, 94, 98, 99, 110, 116, 125, 134, 154, 155, 178, 180, 186], "statu": [4, 25, 76, 82, 87, 88, 151, 153, 155], "python_script": 4, "01_tabular_data_explor": 4, "2023": 4, "20": [4, 18, 29, 62, 76, 78, 87, 93, 94, 99, 104, 105, 106, 107, 108, 109, 115, 119, 120, 122, 124, 131, 134, 136, 143, 148, 149, 150, 156, 157, 159], "13": [4, 76, 82, 84, 94, 97, 106, 107, 108, 119, 120, 122, 133, 142, 146, 155, 157], "57": [4, 106, 107, 122], "cach": 4, "12": [4, 76, 84, 93, 94, 106, 107, 108, 109, 119, 122, 143, 151, 157, 164], "36": [4, 75, 78, 104, 106, 119, 122, 131, 136, 159, 163], "01_tabular_data_exploration_ex_01": 4, "31": [4, 106, 116, 119, 125, 136, 143, 151, 155], "01_tabular_data_exploration_sol_01": 4, "76": [4, 86, 100, 106, 108, 143], "02_numerical_pipeline_cross_valid": 4, "02_numerical_pipeline_ex_00": 4, "45": [4, 76, 83, 84, 87, 94, 104, 106, 108, 118, 122, 135, 140, 141, 158], "02_numerical_pipeline_ex_01": 4, "02_numerical_pipeline_hands_on": 4, "49": [4, 87, 106, 118, 119, 127, 138, 155], "02_numerical_pipeline_introduct": 4, "7": [4, 18, 49, 75, 76, 78, 84, 85, 87, 94, 97, 100, 101, 102, 104, 106, 107, 109, 110, 118, 119, 120, 122, 131, 134, 136, 143, 148, 151, 154, 155, 157, 159, 162, 164, 166, 178, 186], "21": [4, 87, 92, 94, 104, 106, 107, 109, 110, 122, 148, 155, 157], "02_numerical_pipeline_sc": 4, "32": [4, 88, 106, 117, 119, 151], "02_numerical_pipeline_sol_00": 4, "84": [4, 93, 106, 136], "02_numerical_pipeline_sol_01": 4, "51": [4, 106, 122, 186], "03_categorical_pipelin": 4, "08": [4, 29, 107, 134, 155], "03_categorical_pipeline_column_transform": 4, "9": [4, 29, 75, 76, 85, 93, 94, 97, 100, 101, 102, 104, 106, 109, 110, 118, 119, 122, 134, 136, 144, 146, 147, 148, 151, 155, 157, 159, 186], "95": [4, 109, 155], "03_categorical_pipeline_ex_01": 4, "58": [4, 106, 107, 136, 155], "44": [4, 76, 82, 94, 104, 106, 136, 151, 152, 155], "03_categorical_pipeline_ex_02": 4, "8": [4, 62, 76, 78, 82, 85, 87, 93, 94, 97, 100, 101, 102, 103, 104, 106, 109, 110, 112, 116, 117, 118, 119, 120, 122, 123, 125, 133, 134, 137, 139, 143, 148, 149, 151, 154, 155, 156, 157, 158, 163, 164, 178, 180, 186], "03_categorical_pipeline_sol_01": 4, "03_categorical_pipeline_sol_02": 4, "17": [4, 29, 76, 78, 82, 84, 94, 104, 106, 118, 119, 122, 131, 136, 141, 146, 148, 154, 157, 158, 159], "03_categorical_pipeline_visu": 4, "61": [4, 106, 119, 134, 155], "cross_validation_baselin": 4, "59": [4, 84, 87, 106, 107], "16": [4, 76, 84, 87, 94, 97, 103, 105, 106, 108, 118, 119, 122, 148, 154, 157, 158, 164], "cross_validation_ex_01": 4, "03": [4, 10, 12, 21, 29, 31, 41, 47, 57, 67, 70, 166, 177], "cross_validation_ex_02": 4, "53": [4, 106, 107, 118, 127, 155], "cross_validation_group": 4, "24": [4, 88, 94, 104, 106, 107, 108, 109, 110, 122, 143, 148, 151, 155], "cross_validation_learning_curv": 4, "18": [4, 29, 36, 76, 78, 82, 94, 106, 107, 118, 119, 122, 131, 134, 136, 139, 144, 147, 151, 152, 154, 155, 157, 159], "cross_validation_nest": 4, "14": [4, 76, 94, 97, 106, 107, 118, 119, 122, 133, 143, 146, 157], "00": [4, 29, 84, 104, 107, 135, 138, 151], "25": [4, 62, 76, 82, 83, 84, 88, 94, 104, 105, 106, 107, 109, 110, 122, 135, 140, 151, 152, 155], "39": [4, 78, 87, 88, 106, 118, 122, 131, 136, 159], "cross_validation_sol_01": 4, "65": [4, 87, 93, 106], "cross_validation_sol_02": 4, "cross_validation_stratif": 4, "52": [4, 104, 106, 107, 109, 110, 127, 158], "cross_validation_tim": 4, "63": [4, 106, 112, 122], "cross_validation_train_test": 4, "01": [4, 11, 19, 32, 38, 59, 61, 65, 84, 99, 107, 119, 120, 132, 137, 151, 152, 154, 166, 168, 170, 181], "07": [4, 103, 110, 134], "cross_validation_validation_curv": 4, "27": [4, 76, 87, 94, 106, 107, 122], "38": [4, 76, 82, 84, 87, 106, 122, 151, 152, 155], "datasets_ames_h": 4, "datasets_bike_rid": 4, "89": [4, 84, 94, 127], "datasets_blood_transfus": 4, "02": [4, 10, 11, 20, 30, 38, 41, 61, 67, 84, 166, 168, 177, 179], "46": [4, 87, 94, 104, 106, 117, 118, 122, 155, 157], "datasets_california_h": 4, "dev_features_import": 4, "80": [4, 29, 75, 93, 94, 106, 149, 156], "09": [4, 107, 134], "ensemble_adaboost": 4, "ensemble_bag": 4, "04": [4, 12, 30, 47, 70, 84, 111, 119, 134, 164, 166, 169], "6": [4, 13, 22, 39, 49, 73, 75, 76, 78, 84, 85, 90, 92, 93, 94, 97, 100, 101, 102, 104, 106, 107, 109, 110, 118, 119, 122, 131, 134, 136, 137, 143, 146, 148, 151, 154, 155, 157, 158, 159, 162, 163, 166, 178], "99": [4, 84], "ensemble_ex_01": 4, "ensemble_ex_02": 4, "ensemble_ex_03": 4, "22": [4, 94, 104, 106, 107, 109, 110, 120, 146, 148, 154], "ensemble_ex_04": 4, "ensemble_gradient_boost": 4, "06": 4, "127": [4, 87], "87": [4, 87, 103, 119, 151], "ensemble_hist_gradient_boost": 4, "54": [4, 106, 107, 119, 120], "88": [4, 87, 103, 104, 109, 110, 119, 151, 155], "ensemble_hyperparamet": 4, "123": [4, 78], "ensemble_introduct": 4, "ensemble_random_forest": 4, "28": [4, 76, 82, 84, 87, 94, 104, 106, 107, 108, 118, 151, 152, 155], "ensemble_sol_01": 4, "35": [4, 76, 106, 108, 119], "83": [4, 76, 118], "ensemble_sol_02": 4, "11": [4, 76, 87, 94, 106, 119, 122, 134, 151, 155, 157, 162, 178], "ensemble_sol_03": 4, "104": 4, "ensemble_sol_04": 4, "60": [4, 29, 76, 83, 93, 106, 107, 110, 112, 122, 154, 162, 164], "feature_selection_ex_01": 4, "feature_selection_introduct": 4, "feature_selection_limitation_model": 4, "78": [4, 106, 143, 155, 158], "43": [4, 88, 94, 97, 104, 106, 107, 118], "feature_selection_sol_01": 4, "05": [4, 29, 31, 47, 70, 94, 97, 101, 102, 103, 107, 109, 112, 117, 120, 123, 134, 137, 143, 153, 158, 162, 164, 166], "linear_models_ex_01": 4, "linear_models_ex_02": 4, "linear_models_ex_03": 4, "linear_models_feature_engineering_classif": 4, "linear_models_regular": 4, "linear_models_sol_01": 4, "linear_models_sol_02": 4, "linear_models_sol_03": 4, "33": [4, 104, 106, 109, 119, 154, 155], "linear_regression_in_sklearn": 4, "linear_regression_non_linear_link": 4, "linear_regression_without_sklearn": 4, "79": [4, 75, 106, 122], "logistic_regress": [4, 132, 133, 137, 141], "logistic_regression_non_linear": 4, "77": [4, 106, 108, 118, 143], "metrics_classif": 4, "metrics_ex_01": 4, "34": [4, 106, 109, 124, 154], "metrics_ex_02": 4, "metrics_regress": 4, "55": [4, 98, 106, 107], "metrics_sol_01": 4, "19": [4, 78, 79, 87, 94, 106, 107, 118, 119, 122, 131, 134, 136, 138, 154, 157, 159], "metrics_sol_02": 4, "parameter_tuning_ex_02": 4, "71": [4, 106, 151, 155, 163], "parameter_tuning_ex_03": 4, "parameter_tuning_grid_search": 4, "42": [4, 75, 82, 84, 86, 87, 88, 106, 119, 129, 133, 142, 149, 150, 151, 153, 155, 156, 157], "parameter_tuning_manu": 4, "parameter_tuning_nest": 4, "parameter_tuning_parallel_plot": 4, "parameter_tuning_randomized_search": 4, "parameter_tuning_sol_02": 4, "73": [4, 83, 106], "parameter_tuning_sol_03": 4, "26": [4, 94, 106, 107, 155], "trees_classif": 4, "23": [4, 87, 94, 104, 106, 107, 108, 109, 110, 118, 120, 122, 164], "93": [4, 118], "trees_dataset": 4, "trees_ex_01": 4, "trees_ex_02": 4, "trees_hyperparamet": 4, "trees_regress": 4, "trees_sol_01": 4, "trees_sol_02": 4, "lot": [6, 76, 109, 110, 129, 134, 143], "materi": 6, "far": [6, 49, 94, 105, 117, 124, 128, 134], "congratul": 6, "And": [6, 103], "thank": [6, 133, 153], "everyon": 6, "instructor": 6, "staff": 6, "help": [6, 62, 68, 84, 86, 90, 92, 95, 96, 100, 101, 105, 106, 107, 108, 109, 110, 119, 126, 129, 133, 134, 137, 141, 143, 146, 186], "forum": [6, 36], "student": [6, 36], "hard": [6, 75, 76, 77, 78, 126, 129, 141, 143, 148], "work": [6, 40, 62, 67, 76, 84, 87, 88, 102, 103, 107, 112, 119, 121, 128, 129, 134, 149, 152, 154, 156, 158, 160, 163, 164, 166, 171, 186], "summar": [6, 104, 111, 119, 121], "train": [6, 15, 16, 17, 18, 25, 26, 29, 34, 35, 37, 40, 42, 43, 45, 46, 49, 53, 55, 58, 60, 61, 62, 63, 68, 71, 73, 74, 76, 79, 80, 81, 84, 85, 86, 87, 88, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 107, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 131, 132, 133, 134, 136, 137, 138, 139, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 175, 176, 178, 183, 186], "test": [6, 18, 26, 29, 34, 35, 37, 45, 49, 55, 58, 60, 61, 62, 68, 74, 75, 79, 80, 81, 84, 85, 86, 87, 88, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 105, 110, 112, 113, 114, 115, 116, 117, 119, 120, 122, 123, 124, 125, 126, 127, 128, 129, 134, 136, 137, 141, 142, 143, 144, 146, 147, 149, 151, 152, 153, 155, 156, 157, 160, 163, 164, 166, 176, 178, 180, 186], "built": [6, 37, 96, 101, 110, 112, 139, 143, 162, 164, 174], "matrix": [6, 29, 84, 87, 97, 121, 126, 129, 134, 139], "featur": [6, 15, 16, 17, 18, 24, 29, 33, 34, 35, 37, 40, 42, 43, 44, 49, 51, 60, 62, 66, 67, 68, 71, 73, 74, 75, 76, 77, 78, 79, 82, 83, 88, 89, 91, 93, 94, 96, 100, 101, 104, 106, 107, 108, 109, 111, 112, 117, 118, 119, 121, 126, 129, 131, 136, 140, 141, 142, 146, 151, 152, 153, 157, 158, 159, 160, 161, 162, 163, 164, 165, 173, 174, 178, 186], "observ": [6, 28, 45, 49, 53, 55, 76, 78, 84, 86, 87, 88, 90, 92, 94, 96, 97, 98, 99, 100, 101, 102, 104, 105, 107, 108, 111, 112, 115, 117, 119, 121, 124, 125, 127, 133, 134, 136, 137, 139, 141, 142, 143, 146, 151, 154, 157, 158, 159, 162, 163, 165, 175], "transform": [6, 29, 40, 44, 68, 71, 83, 84, 87, 88, 93, 96, 99, 101, 104, 105, 107, 112, 118, 121, 126, 129, 131, 133, 134, 136, 137, 139, 146, 151, 152, 153, 154, 155, 180], "often": [6, 40, 43, 45, 60, 63, 76, 87, 88, 99, 101, 112, 137, 139, 146, 148, 153, 178, 183, 186], "typic": [6, 13, 51, 73, 76, 87, 104, 109, 119, 126, 129, 133, 141, 146, 148, 153, 155, 173], "categor": [6, 37, 49, 66, 71, 73, 74, 75, 76, 77, 78, 89, 91, 106, 121, 133, 134, 141, 143, 151, 159, 166, 178], "variabl": [6, 24, 29, 36, 40, 49, 51, 60, 62, 66, 68, 70, 71, 75, 79, 80, 83, 84, 85, 89, 91, 94, 97, 98, 103, 104, 105, 106, 108, 109, 112, 119, 121, 134, 140, 141, 146, 151, 153, 155, 157, 159, 166, 178, 180, 186], "seek": [6, 34, 119, 120, 143], "suffic": [6, 119], "But": [6, 93, 100, 103, 104, 109, 133, 134, 153, 154], "larg": [6, 18, 49, 71, 88, 99, 104, 107, 109, 115, 116, 118, 119, 124, 125, 128, 129, 132, 134, 136, 137, 146, 150, 153, 154, 155, 157, 180], "detect": 6, "underfit": [6, 13, 22, 29, 33, 39, 44, 45, 46, 53, 55, 58, 60, 61, 62, 63, 98, 117, 119, 120, 121, 133, 136, 137, 139, 142, 158, 166, 171, 173], "multipl": [6, 87, 97, 110, 112, 117, 131, 136, 139, 144, 145, 147, 148, 154, 173, 174], "hyper": [6, 18, 37, 99, 101, 153, 157, 180], "control": [6, 46, 80, 84, 85, 95, 99, 100, 105, 119, 121, 127, 132, 133, 137, 139, 149, 150, 152, 154, 156, 157, 158, 162, 173, 183], "import": [6, 13, 18, 22, 29, 36, 37, 49, 60, 62, 74, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 163, 164, 165, 166, 169, 171, 178, 180, 182, 186], "randomsearchcv": 6, "understand": [6, 13, 22, 33, 39, 58, 80, 82, 85, 87, 97, 98, 102, 105, 130, 135, 143, 162, 163, 171, 172, 183], "suit": [6, 133, 146, 172], "intuit": [6, 10, 11, 13, 14, 22, 39, 47, 58, 73, 82, 83, 87, 107, 109, 111, 112, 117, 125, 133, 137, 138, 139, 141, 142, 158, 159, 163, 164, 166], "debug": 6, "build": [6, 18, 29, 49, 73, 75, 76, 83, 93, 95, 100, 112, 118, 128, 131, 133, 136, 151, 162, 166, 168], "combin": [6, 13, 14, 16, 42, 43, 44, 68, 76, 82, 84, 88, 97, 99, 108, 109, 110, 111, 112, 116, 117, 118, 119, 120, 121, 125, 128, 133, 134, 136, 138, 139, 148, 149, 150, 151, 153, 155, 156, 157, 158, 173, 174, 180, 183, 184], "particularli": [6, 75, 89, 91, 119], "few": [6, 76, 77, 78, 81, 82, 86, 104, 106, 108, 109, 119, 121, 131, 133, 136, 137, 153, 159], "benefit": [6, 17, 24, 33, 84, 87, 98, 117, 120, 121, 134, 146, 160, 166], "non": [6, 20, 29, 39, 42, 44, 45, 49, 68, 71, 76, 84, 92, 95, 99, 100, 101, 106, 107, 108, 109, 110, 112, 127, 131, 134, 136, 141, 157, 158, 163, 165, 166, 172, 173, 184], "engin": [6, 40, 44, 49, 97, 107, 131, 134, 136, 166], "base": [6, 13, 14, 15, 16, 18, 29, 34, 36, 42, 51, 62, 76, 77, 78, 84, 90, 92, 97, 104, 107, 112, 117, 120, 121, 127, 128, 131, 136, 137, 139, 141, 142, 143, 148, 151, 153, 158, 159, 166, 186], "seri": [6, 94, 96, 97, 101, 103, 110, 112, 117, 137, 141, 158], "threshold": [6, 15, 27, 76, 93, 109, 158, 163, 164, 174], "variou": [6, 58, 93], "attribut": [6, 37, 76, 84, 87, 97, 99, 104, 109, 110, 112, 114, 123, 137, 138, 139, 141, 150, 151, 155, 157, 180, 186], "natur": [6, 22, 36, 83, 87, 88, 104, 107, 112, 133, 134, 155], "miss": [6, 76, 87, 97, 104, 106, 108, 109, 131, 136, 155, 186], "histgradientboostingregressor": [6, 18, 29, 118, 119, 125, 148], "classifi": [6, 15, 24, 27, 42, 71, 77, 78, 81, 82, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 97, 100, 101, 102, 108, 111, 112, 121, 127, 132, 133, 137, 141, 142, 144, 147, 148, 149, 151, 152, 153, 155, 156, 158, 160, 162, 164, 172, 173, 180, 182, 186], "goto": 6, "strongli": [6, 110], "advis": [6, 110], "pointer": 6, "doc": 6, "rich": 6, "didact": [6, 36, 87, 88, 106], "improv": [6, 36, 68, 92, 93, 97, 98, 100, 101, 105, 113, 115, 119, 122, 124, 139, 146, 154, 180, 183], "compris": [6, 143], "guid": [6, 133, 141, 146, 186], "everi": [6, 76, 79, 104, 107, 110, 138, 153], "explain": [6, 18, 29, 39, 60, 88, 110, 117, 118, 124, 128, 137, 146, 151, 171], "demonstr": [6, 88, 94, 111, 117, 118, 134, 139, 162], "good": [6, 22, 25, 49, 76, 79, 81, 82, 83, 86, 87, 88, 90, 92, 102, 103, 104, 105, 108, 110, 119, 120, 121, 128, 130, 131, 134, 135, 136, 137, 138, 141, 142, 143, 151, 153, 154, 155, 157, 158, 180], "softwar": [6, 36, 83], "ask": [6, 126, 129, 130, 132, 135, 137, 143], "question": [6, 82, 90, 92, 106, 130, 131, 135, 136, 137, 143, 157], "stackoverflow": 6, "github": [6, 36, 82, 84, 85, 88, 93, 99, 104, 111, 133, 134, 138, 139, 142, 143, 151, 153, 155, 158, 164, 165], "discuss": [6, 14, 18, 36, 49, 76, 79, 83, 111, 117, 119, 120, 134, 137, 158], "driven": [6, 137], "inclus": 6, "contribut": [6, 62, 84, 97, 134, 157, 180], "other": [6, 14, 27, 29, 36, 45, 62, 75, 76, 79, 83, 84, 87, 88, 89, 91, 94, 95, 96, 100, 101, 102, 103, 107, 110, 112, 119, 127, 131, 134, 136, 138, 139, 141, 142, 146, 151, 153, 154, 155, 161, 164, 165, 180, 183, 186], "advocaci": 6, "curat": 6, "overflow": 6, "code": [6, 29, 36, 51, 71, 77, 80, 81, 89, 95, 96, 112, 113, 114, 115, 116, 118, 126, 129, 130, 131, 132, 134, 135, 139, 141, 144, 145, 149, 150, 151, 153, 154, 156, 157, 160, 161, 180], "start": [6, 36, 49, 76, 80, 81, 82, 84, 85, 86, 87, 88, 90, 92, 94, 97, 98, 101, 102, 103, 104, 107, 108, 117, 119, 120, 126, 127, 129, 131, 132, 133, 134, 136, 137, 140, 141, 143, 146, 148, 150, 152, 157, 158, 159, 160], "carpentri": 6, "resourc": [6, 36, 73, 76, 107, 119, 153], "git": 6, "lab": [6, 36], "unsupervis": [6, 51], "structur": [6, 60, 73, 76, 84, 87, 88, 97, 119, 146, 157, 158, 163, 172], "instanc": [6, 49, 66, 76, 82, 83, 84, 87, 97, 104, 106, 107, 109, 110, 113, 116, 122, 125, 126, 127, 128, 129, 131, 133, 134, 136, 138, 140, 143, 145, 146, 148, 152, 155, 176, 182, 183], "sampl": [6, 14, 15, 16, 18, 20, 29, 43, 45, 51, 61, 63, 66, 76, 77, 78, 79, 82, 83, 84, 87, 88, 95, 96, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 115, 117, 118, 119, 121, 124, 126, 129, 130, 133, 134, 135, 137, 139, 140, 141, 142, 143, 148, 150, 151, 153, 155, 157, 158, 159, 161, 162, 163, 165, 166, 175, 184], "supervis": [6, 51, 104, 173], "recov": [6, 18, 97, 134], "link": [6, 15, 81, 82, 86, 97, 106, 107, 108, 109, 110, 119, 126, 129, 143, 146], "drive": 6, "system": [6, 76, 97], "hand": [6, 29, 93, 97, 111, 124, 134, 136, 139, 151, 153], "nuanc": 6, "deep": [6, 92, 119, 120, 162], "better": [6, 17, 18, 28, 49, 75, 79, 83, 86, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 104, 105, 112, 119, 120, 121, 126, 129, 130, 134, 135, 137, 138, 148, 152, 153, 155, 157, 162, 178, 186], "gradient": [6, 10, 13, 14, 16, 17, 18, 29, 84, 88, 111, 115, 116, 120, 124, 125, 148, 151, 155, 166], "boost": [6, 13, 14, 16, 17, 18, 29, 88, 115, 116, 120, 124, 125, 151, 155, 166], "classif": [6, 15, 22, 38, 39, 41, 43, 51, 62, 66, 75, 76, 82, 83, 89, 91, 93, 95, 96, 97, 100, 101, 102, 104, 108, 111, 131, 133, 136, 140, 144, 145, 146, 147, 148, 160, 162, 163, 164, 166, 171, 172, 173, 186], "regress": [6, 18, 22, 27, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 51, 55, 60, 62, 68, 75, 82, 84, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 100, 101, 102, 104, 109, 112, 114, 117, 123, 126, 129, 131, 132, 136, 137, 141, 142, 143, 145, 148, 150, 152, 157, 158, 161, 162, 165, 166, 171, 172, 173, 178, 186], "nativ": [6, 76, 82, 87, 88, 104, 127, 139, 151, 153, 155], "input": [6, 24, 40, 42, 43, 60, 75, 76, 81, 83, 84, 86, 87, 90, 91, 92, 94, 97, 100, 101, 110, 112, 130, 135, 139, 140, 141, 153, 158, 159, 173, 186], "speech": 6, "text": [6, 36, 51, 107, 133, 140], "imag": [6, 97], "voic": 6, "pretrain": 6, "human": [6, 76, 107, 133], "cost": [6, 83, 104, 107, 120, 137, 154, 155], "mainten": 6, "Not": [6, 88, 89, 91, 99], "pytorch": 6, "tensorflow": 6, "introduct": [6, 58, 73, 166], "andrea": 6, "c": [6, 15, 16, 17, 18, 24, 25, 26, 27, 28, 29, 35, 37, 42, 43, 44, 45, 46, 49, 51, 53, 55, 62, 63, 66, 68, 71, 75, 97, 99, 108, 132, 133, 141, 143, 152, 164, 173, 174, 175, 176, 178, 180, 182, 186], "m\u00fcller": 6, "sarah": 6, "guido": 6, "handbook": 6, "jake": 6, "van": 6, "der": 6, "pla": 6, "broader": [6, 161, 165], "statist": [6, 18, 58, 76, 78, 83, 84, 87, 90, 92, 104, 109, 111, 112, 126, 129, 143, 186], "jame": 6, "witten": 6, "hasti": 6, "tibshirani": 6, "theori": [6, 111], "concept": [6, 13, 14, 22, 23, 33, 34, 39, 40, 58, 60, 74, 97, 102, 104, 148, 171, 172, 184], "kera": 6, "aur\u00e9lien": 6, "g\u00e9ron": 6, "kaggl": 6, "particip": 6, "challeng": [6, 36, 108, 139], "team": 6, "solut": [6, 10, 11, 12, 18, 19, 30, 31, 32, 36, 38, 41, 47, 61, 65, 67, 70, 87, 103, 126, 127, 138, 142, 151, 166, 168, 177, 179, 181], "share": [6, 112], "winner": 6, "wai": [6, 73, 75, 76, 79, 82, 86, 87, 99, 100, 101, 103, 111, 112, 117, 118, 119, 126, 127, 129, 139, 143, 146, 163, 178, 186], "now": [6, 18, 29, 49, 62, 75, 79, 80, 82, 83, 84, 85, 86, 87, 88, 89, 91, 94, 95, 96, 97, 98, 100, 101, 102, 103, 104, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 129, 130, 131, 133, 134, 135, 136, 137, 139, 140, 141, 143, 144, 147, 149, 151, 153, 154, 155, 156, 158, 161, 162, 164, 165, 178, 186], "touch": 6, "briefli": 6, "fit": [6, 14, 24, 26, 29, 39, 40, 42, 43, 44, 45, 49, 53, 66, 68, 79, 80, 82, 85, 86, 87, 90, 92, 93, 95, 99, 100, 101, 103, 104, 105, 110, 111, 112, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 130, 133, 134, 135, 136, 137, 138, 139, 141, 142, 143, 146, 148, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 162, 163, 164, 165, 166, 171, 175, 180], "wider": [6, 36, 55], "mai": [6, 25, 44, 45, 49, 51, 76, 104, 109, 119, 131, 134, 136, 137, 138, 141, 143, 148, 155, 157, 164], "fail": [6, 103, 133, 144, 147], "weak": [6, 16, 119, 137, 155], "analysi": [6, 73, 82, 95, 100, 108, 109, 134, 146, 155, 157, 158, 166, 179], "kei": [6, 8, 9, 48, 50, 52, 54, 56, 64, 68, 69, 95, 100, 102, 105, 119, 122, 125, 127, 128, 137, 151, 152, 155, 162, 167], "achiev": [6, 18, 76, 81, 84, 86, 98, 100, 108, 133, 134, 162], "reliabl": [6, 97, 141], "even": [6, 36, 39, 63, 78, 79, 83, 87, 88, 90, 91, 92, 97, 101, 103, 104, 111, 118, 119, 124, 127, 133, 134, 137, 139, 141, 142, 143, 144, 145, 147, 148, 151, 157, 183, 184], "cross": [6, 13, 18, 22, 23, 24, 25, 26, 29, 33, 34, 39, 40, 45, 49, 58, 59, 61, 62, 67, 68, 75, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 100, 101, 102, 103, 105, 109, 110, 116, 117, 118, 119, 120, 121, 124, 125, 126, 127, 128, 129, 131, 134, 136, 142, 143, 144, 145, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 162, 166, 171, 176, 178, 180, 183, 184, 186], "accuraci": [6, 18, 27, 62, 68, 75, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 95, 97, 99, 100, 101, 102, 108, 111, 117, 127, 128, 129, 130, 135, 137, 141, 144, 147, 148, 151, 152, 153, 154, 155, 156, 157, 158, 160, 164, 186], "imperfect": [6, 110], "estim": [6, 13, 17, 22, 29, 33, 39, 45, 49, 58, 62, 68, 73, 79, 83, 84, 87, 88, 93, 99, 101, 103, 109, 110, 111, 112, 113, 115, 116, 118, 119, 120, 121, 122, 124, 125, 126, 127, 129, 131, 134, 136, 139, 145, 146, 148, 151, 152, 153, 155, 171, 178, 180, 183, 186], "actual": [6, 76, 80, 83, 85, 94, 103, 104, 105, 119, 133, 143, 146, 153], "gener": [6, 17, 18, 22, 23, 28, 29, 49, 52, 58, 60, 61, 62, 68, 79, 81, 82, 83, 84, 86, 87, 88, 89, 91, 92, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 106, 108, 109, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 131, 134, 136, 137, 139, 141, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 155, 156, 157, 163, 166, 169, 178, 180, 186], "As": [6, 29, 49, 76, 79, 82, 83, 84, 87, 88, 90, 92, 95, 97, 99, 100, 101, 106, 108, 109, 110, 112, 117, 118, 133, 134, 137, 141, 142, 143, 145, 146, 148, 152, 153, 154, 157, 158, 162, 165], "narrow": 6, "spend": [6, 107, 119], "increasingli": 6, "effort": [6, 107], "split": [6, 15, 18, 23, 29, 37, 43, 45, 68, 76, 79, 81, 86, 87, 88, 94, 97, 99, 102, 103, 104, 106, 110, 113, 117, 118, 119, 121, 122, 124, 126, 129, 142, 143, 146, 151, 153, 155, 158, 160, 162, 163, 164, 173, 174], "afford": 6, "trust": [6, 82, 83, 84, 85, 88, 93, 99, 104, 111, 133, 134, 137, 138, 139, 142, 143, 151, 152, 153, 155, 158, 164, 165], "think": [6, 77, 78, 103, 107, 131, 136, 137], "carefulli": [6, 97], "complet": [6, 15, 29, 36, 49, 99, 101, 126, 129, 133, 134, 150, 153, 157, 180], "futur": [6, 76, 79, 88, 93, 103, 104, 151, 164], "upon": [6, 93, 100, 101], "affect": [6, 103, 134, 137, 141, 151, 158, 163, 164], "live": [6, 134], "sure": [6, 18, 62, 82, 84, 87, 92, 116, 125], "divers": [6, 158], "demograph": [6, 120], "increas": [6, 16, 18, 28, 29, 44, 45, 46, 49, 53, 55, 60, 78, 84, 87, 100, 104, 105, 110, 115, 118, 119, 124, 134, 137, 140, 141, 142, 151, 155, 157, 158, 160, 162, 163, 164, 176, 184], "coverag": 6, "phrase": 6, "recommend": [6, 36, 73, 76, 87], "identifi": [6, 13, 73, 88, 97, 100, 105, 143, 180], "ani": [6, 15, 18, 29, 36, 44, 75, 76, 79, 82, 84, 86, 88, 91, 92, 94, 97, 100, 102, 103, 104, 105, 107, 108, 109, 110, 112, 119, 120, 121, 125, 126, 127, 128, 129, 133, 134, 138, 141, 146, 151, 153, 154, 157, 162, 175, 186], "bia": [6, 37, 53, 58, 60, 110, 131, 133, 136, 146, 166], "acquisit": 6, "full": [6, 8, 9, 18, 36, 48, 50, 51, 52, 54, 56, 64, 68, 69, 79, 80, 84, 85, 87, 99, 104, 119, 124, 126, 128, 129, 140, 149, 153, 156, 167, 180, 183], "chain": [6, 79, 84, 88], "acquir": [6, 13, 22, 33, 39, 58, 105, 107, 171, 183], "fanci": 6, "put": [6, 33, 37, 84, 105, 110, 134, 158], "product": [6, 99, 102, 104, 131, 134, 136, 151], "routin": [6, 18, 97, 186], "debt": 6, "simpler": [6, 14, 49, 88, 137], "easier": [6, 84, 87, 94, 139, 146], "maintain": 6, "less": [6, 29, 46, 88, 97, 103, 109, 110, 111, 112, 119, 120, 128, 133, 134, 136, 137, 139, 151, 157], "power": [6, 29, 36, 107, 119, 120, 131, 134, 136, 139, 158], "drift": 6, "gave": [6, 143], "methodolog": [6, 36, 58, 104, 163], "element": [6, 22, 83, 87, 97, 104, 134, 135, 140, 143], "alwai": [6, 15, 18, 22, 24, 43, 45, 55, 81, 82, 83, 86, 88, 92, 94, 97, 99, 100, 101, 102, 104, 105, 108, 109, 121, 127, 142, 143, 152, 153, 154, 165, 178, 180, 186], "solid": 6, "conclus": [6, 76, 96, 97, 99, 101, 102, 103, 105, 108, 119, 127], "standpoint": 6, "biggest": 6, "shortcom": 6, "cannot": [6, 18, 29, 60, 76, 102, 103, 105, 110, 119, 126, 129, 133, 139, 142, 143, 146, 148, 151, 154, 165, 183], "autom": [6, 76, 166, 184], "domain": 6, "knowledg": [6, 36, 73, 99, 105, 112, 129, 139, 142, 153], "critic": [6, 36, 106], "thing": [6, 76, 87, 88, 93, 103, 139, 151], "oper": [6, 84, 112, 133, 143, 153], "risk": [6, 131, 136, 142], "advertis": 6, "individu": [6, 17, 29, 76, 84, 88, 108, 112, 114, 121, 123, 134, 141, 142, 158, 186], "caus": [6, 18, 53, 60, 76, 87, 91, 92, 119, 134, 151, 153, 180], "wast": [6, 119], "bit": [6, 29, 86, 104, 105, 110, 134, 139, 144, 147, 153], "monei": 6, "annoi": 6, "otherwis": [6, 18, 82, 91, 97, 99, 121, 133, 139, 140, 162], "mostli": [6, 137, 157], "harmless": 6, "medicin": 6, "kill": 6, "logic": [6, 151, 164], "fals": [6, 16, 55, 83, 87, 90, 92, 97, 99, 103, 107, 109, 125, 127, 128, 133, 134, 136, 139, 143, 147, 150, 151, 155, 157, 158, 164, 176], "brain": 6, "tumor": 6, "sent": 6, "surgeri": 6, "veri": [6, 18, 58, 62, 76, 82, 88, 90, 92, 99, 100, 102, 105, 108, 109, 110, 112, 117, 119, 121, 125, 133, 134, 137, 139, 143, 151, 152, 153, 154, 155, 162, 180], "danger": [6, 134, 155], "mr": 6, "confirm": [6, 94, 102, 107, 109, 112, 126, 129, 133, 137, 141, 146, 153, 154], "should": [6, 18, 23, 29, 34, 35, 45, 49, 71, 75, 76, 83, 84, 88, 92, 97, 99, 101, 102, 103, 104, 105, 106, 107, 108, 110, 111, 116, 117, 119, 120, 125, 126, 127, 129, 130, 134, 135, 137, 139, 142, 143, 144, 147, 148, 149, 151, 152, 153, 156, 158, 160, 162, 163, 176, 178, 180, 183, 184], "delai": 6, "life": [6, 76, 126, 129, 146], "save": [6, 186], "treatment": [6, 60], "hospit": [6, 25], "stai": [6, 40, 45, 112, 134], "overcrowd": 6, "unit": [6, 76, 82, 84, 87, 88, 104, 107, 109, 110, 111, 134, 138, 140, 146, 151, 155], "chang": [6, 28, 29, 37, 49, 84, 96, 101, 110, 111, 115, 124, 127, 134, 146, 149, 152, 156, 158, 183, 186], "inpati": 6, "chose": [6, 55, 76, 117, 134], "load": [6, 18, 66, 77, 78, 79, 80, 84, 85, 87, 88, 89, 91, 95, 98, 99, 100, 102, 103, 104, 105, 108, 109, 111, 113, 118, 119, 120, 122, 131, 132, 133, 134, 136, 137, 138, 139, 142, 143, 151, 152, 154, 155, 158, 159, 160, 161, 162, 163, 164, 165, 180, 186], "interest": [6, 51, 76, 77, 78, 94, 96, 101, 102, 104, 105, 107, 109, 112, 117, 131, 133, 136, 138, 139, 141, 143, 146, 148, 151, 152, 153, 154, 155, 157, 164, 186], "focus": [6, 14, 63, 109, 111, 134, 143, 153], "easi": [6, 75, 88, 103, 104, 107, 133, 162], "accumul": 6, "target": [6, 18, 29, 39, 40, 44, 49, 51, 60, 62, 66, 68, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 159, 160, 164, 178, 186], "proxi": [6, 143], "reflect": [6, 104, 112, 121], "ground": [6, 117, 143], "truth": [6, 117, 143], "polici": [6, 25], "uneven": 6, "across": [6, 43, 49, 79, 84, 94, 110, 134, 141, 155, 186], "popul": [6, 76, 104, 109, 110, 143, 157], "eg": 6, "qualiti": [6, 110, 141, 146, 153], "affair": 6, "desir": [6, 81, 86, 121, 134], "qualif": 6, "respons": 6, "women": 6, "pai": [6, 87, 111], "men": 6, "pick": [6, 29, 93, 99, 106, 107, 110, 118, 152, 183], "amplifi": 6, "inequ": 6, "mechan": [6, 29, 83, 84, 153], "die": 6, "naiv": [6, 18, 29, 76, 99, 108, 118, 121], "bad": [6, 91, 100, 129, 134, 142, 143, 180], "health": [6, 36], "fallaci": 6, "compar": [6, 13, 17, 18, 22, 29, 37, 49, 51, 61, 62, 75, 76, 79, 81, 83, 84, 86, 87, 88, 89, 91, 99, 100, 101, 105, 109, 110, 112, 115, 117, 118, 122, 124, 127, 128, 129, 131, 134, 136, 143, 146, 155, 157, 158, 166, 178, 186], "wors": [6, 18, 28, 49, 75, 100, 101, 103, 138, 178], "baselin": [6, 22, 24, 81, 86, 88, 89, 91, 96, 97, 100, 101, 120, 166], "heart": [6, 29, 107, 131, 136], "pressur": 6, "greater": [6, 29, 75, 133], "trigger": 6, "care": [6, 34, 49, 87, 99, 102, 108, 109, 126, 129, 134], "which": [6, 14, 16, 17, 18, 23, 25, 27, 29, 33, 34, 40, 43, 45, 49, 60, 68, 71, 74, 75, 76, 79, 82, 83, 84, 86, 87, 88, 92, 93, 94, 95, 98, 99, 100, 101, 103, 104, 105, 107, 108, 109, 110, 111, 112, 117, 118, 119, 121, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 143, 144, 146, 147, 148, 150, 151, 152, 154, 155, 157, 158, 162, 163, 164, 171, 172, 173, 178, 180, 182, 184, 186], "learner": [6, 14, 111, 112, 117, 119, 120], "predictor": [6, 14, 15, 16, 17, 68, 83, 84, 88, 101, 105, 122, 134, 151, 158], "pure": [6, 129, 164], "benefici": [6, 33, 84, 119, 127, 153, 155, 162], "intervent": [6, 76], "brittl": 6, "interpret": [6, 17, 36, 107, 109, 110, 136, 137, 138, 139, 146, 154, 158, 164], "subject": [6, 76, 143], "caution": [6, 92, 110], "feedback": 6, "loop": [6, 99, 110, 149, 151, 153, 156, 186], "todai": 6, "ai": 6, "alloc": 6, "loan": 6, "screen": [6, 8, 9, 48, 50, 52, 54, 56, 64, 69, 167], "job": [6, 84], "prioritis": 6, "treatement": 6, "law": [6, 29], "enforc": [6, 103, 107, 119, 134, 137], "court": 6, "fairlearn": [6, 76], "assess": [6, 25, 49, 79, 83, 96, 98, 99, 101, 105, 115, 124, 130, 134, 135, 142, 143, 146, 153, 157], "shift": [6, 84, 137], "technolog": [6, 97], "induc": [6, 110, 112, 137], "societi": 6, "though": [6, 101, 118, 145, 148], "difficult": [6, 107, 119, 138, 146], "intersect": [6, 154, 157], "No": [6, 24], "found": [6, 62, 99, 108, 109, 116, 119, 125, 134, 138, 149, 151, 153, 156, 157, 158, 162, 163, 180, 186], "short": [6, 34, 82, 109, 120, 159], "move": [6, 88, 107, 137, 154, 157], "choos": [6, 18, 36, 76, 89, 91, 104, 110, 126, 127, 129, 133, 134, 139, 141, 153, 176, 186], "revolut": 6, "fantast": [6, 129], "opportun": 6, "With": [6, 37, 91, 104, 107, 119, 127, 128, 143, 151, 155, 162], "lift": 6, "roadblock": 6, "hope": [6, 93, 133, 146], "empow": 6, "varieti": [6, 36, 79], "mindset": 6, "dream": 6, "being": [6, 43, 94, 141, 157], "adventur": 6, "navig": [8, 9, 48, 50, 52, 54, 56, 64, 69, 167], "slide": [8, 9, 48, 50, 52, 54, 56, 64, 69, 133, 137, 141, 154, 157, 167], "click": [8, 9, 15, 48, 50, 52, 54, 56, 64, 69, 154, 157, 167, 180], "press": [8, 9, 48, 50, 52, 54, 56, 64, 69, 167], "arrow": [8, 9, 48, 50, 52, 54, 56, 64, 69, 167], "go": [8, 9, 13, 22, 29, 33, 36, 39, 48, 50, 52, 54, 56, 58, 64, 69, 73, 79, 80, 85, 87, 95, 97, 99, 100, 103, 104, 105, 107, 109, 110, 117, 120, 127, 141, 143, 148, 151, 158, 167, 171, 183], "next": [8, 9, 48, 50, 52, 54, 56, 60, 64, 69, 82, 83, 87, 93, 95, 96, 100, 101, 102, 103, 111, 117, 119, 120, 131, 133, 134, 136, 137, 139, 152, 158, 167], "previou": [8, 9, 16, 18, 22, 29, 48, 49, 50, 52, 54, 56, 62, 64, 66, 68, 69, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 96, 97, 98, 99, 101, 102, 103, 104, 105, 112, 113, 116, 117, 118, 119, 121, 122, 125, 126, 129, 130, 131, 133, 134, 135, 136, 137, 138, 139, 142, 144, 147, 149, 151, 152, 153, 154, 155, 156, 157, 158, 160, 161, 164, 165, 167, 178, 180, 183, 186], "p": [8, 9, 48, 50, 52, 54, 56, 64, 69, 97, 136, 144, 147, 167], "toggl": [8, 9, 48, 50, 52, 54, 56, 64, 69, 167], "mode": [8, 9, 36, 48, 50, 52, 54, 56, 64, 69, 167], "adapt": [10, 102, 120, 139, 142, 146, 155, 166], "adaboost": [10, 13, 117, 166], "gbdt": [10, 111, 124, 166], "exercis": [10, 11, 12, 19, 29, 30, 31, 32, 36, 38, 41, 47, 49, 61, 65, 67, 70, 82, 87, 119, 133, 138, 139, 151, 153, 158, 166, 168, 177, 178, 179, 181], "m6": [10, 11, 12, 119, 166], "speed": [10, 29, 34, 35, 45, 107, 110, 127, 153, 155, 166], "quiz": [10, 11, 12, 19, 20, 21, 30, 31, 38, 41, 47, 57, 59, 61, 65, 67, 70, 157, 166, 168, 169, 170, 177, 179, 181], "bag": [11, 13, 15, 16, 111, 113, 119, 120, 121, 122, 166], "introductori": [11, 141, 166], "forest": [11, 13, 14, 15, 17, 18, 37, 110, 114, 115, 117, 118, 120, 123, 124, 127, 128, 166], "togeth": [13, 14, 70, 75, 83, 84, 91, 96, 97, 99, 101, 111, 117, 142, 162, 166], "ensembl": [13, 14, 17, 18, 29, 60, 88, 90, 92, 110, 111, 112, 115, 117, 118, 119, 121, 122, 123, 124, 125, 127, 128, 148, 149, 151, 153, 155, 156], "famili": [13, 14, 39, 58, 60, 76, 82, 84, 88, 120, 152], "techniqu": [13, 33, 76, 110, 133], "bootstrap": [13, 14, 18, 119, 120, 121, 122, 166], "ii": [13, 22, 79, 83, 138], "belong": [13, 18, 49, 82, 86, 87, 97, 100, 108, 141, 148, 158, 164, 178], "former": [13, 76, 84, 127, 143], "strategi": [13, 14, 18, 22, 23, 24, 25, 29, 62, 79, 81, 83, 86, 89, 91, 93, 94, 96, 97, 99, 101, 102, 103, 104, 106, 111, 112, 115, 118, 121, 124, 131, 135, 136, 138, 143, 146, 153, 183, 186], "later": [13, 18, 76, 82, 83, 93, 100, 104, 118, 136, 137, 139, 142, 143, 150, 151, 153, 157], "hyperparamet": [13, 17, 26, 40, 44, 49, 62, 95, 98, 99, 100, 105, 113, 117, 120, 122, 129, 132, 133, 134, 137, 148, 150, 157, 158, 171, 172, 179, 180, 181, 182, 183, 184], "allow": [13, 14, 29, 45, 68, 76, 79, 82, 84, 87, 95, 100, 104, 106, 109, 110, 119, 126, 129, 130, 134, 135, 139, 140, 141, 144, 147, 153, 155, 158, 162, 163, 164, 171, 180, 183, 184], "skill": [13, 22, 33, 39, 58, 73, 171, 183], "carri": [13, 22, 33, 39, 49, 58, 73, 87, 98, 109, 128, 171, 183], "basic": [13, 22, 33, 36, 39, 52, 58, 73, 102, 104, 110, 122, 146, 171, 183], "usag": [13, 22, 33, 39, 58, 82, 106, 107, 108, 109, 121, 139, 153, 171, 183], "mainli": [13, 14, 22, 33, 39, 76, 106, 158, 171], "around": [13, 22, 33, 39, 76, 82, 93, 97, 100, 103, 104, 105, 107, 110, 136, 137, 142, 143, 146, 171], "overfit": [13, 16, 18, 22, 29, 33, 39, 45, 46, 49, 53, 55, 58, 60, 61, 62, 63, 98, 99, 103, 110, 111, 112, 115, 119, 120, 121, 124, 128, 133, 134, 136, 137, 142, 153, 157, 162, 166, 171, 173, 176], "valid": [13, 18, 22, 23, 24, 25, 26, 29, 33, 34, 39, 40, 45, 49, 58, 59, 60, 62, 67, 68, 75, 87, 89, 90, 91, 92, 93, 94, 95, 96, 97, 100, 101, 102, 103, 109, 110, 115, 116, 117, 118, 119, 120, 121, 124, 125, 126, 127, 128, 129, 131, 134, 136, 142, 143, 144, 145, 147, 148, 149, 151, 152, 153, 154, 155, 156, 162, 163, 166, 171, 176, 178, 180, 183, 184, 186], "principl": [13, 22, 34, 143], "through": [13, 22, 29, 33, 36, 39, 58, 73, 95, 100, 105, 110, 116, 125, 134, 140, 141, 144, 147, 151, 171, 180, 183], "hour": [13, 22, 39, 58, 73, 76, 79, 81, 82, 83, 84, 86, 87, 88, 151, 152, 155, 171, 183], "saw": [14, 29, 40, 49, 82, 84, 87, 88, 104, 105, 117, 119, 134, 138, 141, 142, 144, 147, 151, 153, 154, 155, 158, 162, 163, 164, 172], "parallel": [14, 16, 117, 153, 154, 157, 180], "sequenti": [14, 16, 55, 84, 118, 119, 154, 180], "intern": [14, 45, 68, 84, 88, 99, 104, 111, 112, 115, 116, 124, 125, 134, 146, 148, 151, 153, 180], "machineri": [14, 111, 117], "art": 14, "learn": [14, 16, 17, 23, 24, 27, 28, 29, 34, 37, 38, 40, 43, 46, 53, 60, 62, 66, 68, 70, 71, 74, 76, 79, 80, 82, 84, 85, 86, 87, 88, 89, 91, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 108, 109, 111, 114, 116, 118, 119, 121, 123, 125, 126, 127, 128, 129, 132, 133, 134, 136, 139, 141, 142, 143, 144, 146, 147, 148, 151, 153, 154, 156, 159, 163, 164, 172, 173, 174, 175, 181, 182, 184, 186], "earli": [14, 29, 115, 116, 124, 125], "stop": [14, 29, 89, 91, 94, 101, 107, 115, 116, 119, 124, 125], "stack": 14, "By": [15, 18, 29, 46, 49, 76, 84, 87, 99, 102, 105, 107, 121, 129, 134, 143, 146, 148, 161, 165, 178], "default": [15, 18, 27, 28, 46, 49, 62, 68, 79, 80, 84, 85, 87, 95, 100, 102, 107, 113, 119, 120, 122, 132, 134, 143, 144, 145, 146, 147, 148, 152, 153, 178, 183], "baggingclassifi": [15, 121], "baggingregressor": [15, 112, 113, 120, 121, 122], "draw": [15, 29, 76, 96, 101, 112, 119, 127, 155, 158, 180], "replac": [15, 29, 49, 87, 106, 107, 109, 112], "without": [15, 36, 38, 49, 62, 76, 80, 83, 85, 94, 97, 99, 100, 103, 104, 106, 107, 108, 119, 120, 127, 128, 131, 134, 136, 137, 138, 142, 143, 144, 146, 147, 164, 166, 186], "d": [15, 16, 17, 18, 20, 25, 27, 29, 37, 43, 44, 45, 49, 51, 53, 55, 62, 63, 66, 68, 71, 75, 76, 83, 97, 166, 173, 178, 180, 182, 186], "answer": [15, 16, 17, 18, 24, 25, 26, 27, 28, 29, 35, 42, 43, 44, 45, 46, 49, 51, 53, 55, 62, 63, 66, 68, 71, 75, 87, 106, 131, 136, 137, 157, 173, 174, 175, 176, 178, 180, 182, 186], "hint": [15, 28, 29, 49, 62, 75, 77, 78, 80, 81, 85, 86, 90, 92, 131, 134, 136, 137, 164, 186], "base_estim": [15, 122], "decid": [15, 22, 76, 82, 104, 109, 126, 129, 131, 136, 153], "resampl": [15, 53, 75, 99, 107, 111, 134], "perform": [15, 17, 18, 19, 22, 23, 24, 26, 29, 34, 35, 49, 62, 66, 68, 75, 78, 79, 81, 82, 83, 84, 86, 87, 88, 89, 91, 93, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 108, 110, 111, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 126, 127, 128, 129, 131, 134, 136, 139, 142, 143, 145, 146, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 162, 171, 178, 180, 183, 184, 186], "correct": [16, 17, 18, 29, 62, 83, 85, 111, 117, 119, 131, 136, 143, 149, 155, 156, 162, 186], "statement": [16, 18, 27, 29, 43, 75, 180, 186], "simultan": 16, "histogram": [16, 29, 68, 76, 77, 78, 84, 96, 101, 106, 109, 116, 118, 125, 141, 151, 155], "acceler": [16, 29, 107, 118], "subsampl": [16, 109, 121, 126, 129], "origin": [16, 68, 79, 82, 83, 87, 88, 102, 103, 106, 111, 112, 117, 118, 121, 131, 133, 136, 137, 139, 140, 146, 158, 159, 163, 164], "bin": [16, 76, 84, 94, 97, 101, 104, 105, 106, 107, 108, 109, 118, 133, 139, 154, 155], "numer": [16, 49, 66, 70, 71, 73, 74, 75, 76, 77, 78, 79, 80, 81, 83, 85, 86, 87, 96, 101, 104, 106, 107, 109, 131, 133, 134, 136, 139, 150, 151, 152, 157, 166, 178, 186], "tend": [16, 29, 97, 119, 120, 133, 134, 137, 146, 153], "true": [16, 18, 27, 29, 43, 49, 55, 60, 62, 68, 75, 83, 94, 97, 98, 99, 102, 103, 104, 105, 106, 107, 108, 109, 110, 112, 113, 115, 116, 117, 118, 119, 120, 122, 124, 125, 127, 130, 131, 133, 134, 135, 136, 141, 143, 146, 148, 150, 151, 153, 157, 158, 164, 176, 180, 186], "shallow": [17, 111, 117, 119, 162], "deeper": [17, 94, 95, 98, 100, 104, 105, 111, 113, 114, 115, 118, 119, 120, 121, 122, 123, 124, 130, 131, 132, 134, 135, 136, 137, 138, 140, 141, 143, 144, 145, 146, 147, 148, 158, 160, 161, 162, 163, 164, 165], "exist": [17, 76, 79, 97], "maximum": [17, 29, 84, 87, 99, 105, 139, 143, 151, 155, 158, 160, 161, 163, 164, 165, 173, 176], "depth": [17, 18, 36, 77, 78, 105, 109, 111, 117, 118, 119, 120, 131, 132, 136, 137, 141, 149, 156, 158, 159, 160, 161, 162, 163, 164, 165, 173, 176, 178], "rate": [17, 29, 83, 94, 98, 104, 107, 119, 143, 151, 154, 156], "option": [17, 84, 87, 94, 102, 104, 107, 115, 124, 183, 186], "reduc": [17, 18, 40, 45, 49, 93, 97, 98, 118, 119, 120, 121, 127, 134, 135], "sensit": [17, 53, 137, 142, 143, 154, 157, 172], "notic": [18, 83, 84, 100, 104, 109, 110, 134, 136, 137, 139, 141, 143, 148, 150, 157, 164], "tradit": 18, "panda": [18, 29, 36, 49, 62, 66, 73, 75, 76, 77, 78, 79, 80, 81, 82, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 117, 119, 121, 122, 123, 125, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 178, 180, 186], "pd": [18, 29, 49, 62, 66, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 114, 117, 119, 121, 122, 123, 125, 127, 128, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 178, 180, 186], "read_csv": [18, 29, 49, 62, 66, 75, 76, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 100, 101, 103, 106, 107, 108, 111, 114, 121, 123, 130, 131, 132, 134, 135, 136, 137, 138, 140, 141, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 165, 178, 180, 186], "csv": [18, 29, 49, 62, 66, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 100, 101, 103, 106, 107, 108, 111, 114, 121, 123, 130, 131, 132, 134, 135, 136, 137, 138, 140, 141, 143, 144, 145, 146, 147, 148, 149, 151, 152, 153, 154, 155, 156, 158, 159, 160, 161, 162, 163, 164, 165, 178, 180, 186], "feature_nam": [18, 106, 109, 114, 123, 130, 133, 134, 135, 138, 140, 141, 142, 158, 159, 161, 162, 163, 164, 165], "culmen": [18, 77, 78, 111, 131, 132, 136, 137, 141, 158, 159, 160, 162, 164, 186], "mm": [18, 78, 111, 114, 123, 130, 131, 132, 135, 136, 137, 138, 140, 141, 158, 159, 160, 161, 162, 163, 164, 165, 186], "flipper": [18, 114, 123, 130, 131, 135, 136, 138, 140, 159, 161, 162, 163, 165, 186], "target_nam": [18, 29, 49, 62, 75, 79, 81, 83, 84, 86, 87, 88, 89, 90, 91, 92, 93, 106, 107, 114, 121, 123, 130, 131, 133, 134, 135, 136, 138, 140, 142, 149, 151, 152, 153, 155, 156, 161, 162, 163, 165, 178, 186], "bodi": [18, 77, 78, 107, 114, 123, 130, 131, 135, 136, 138, 140, 159, 161, 162, 163, 165, 186], "mass": [18, 29, 114, 123, 130, 131, 135, 136, 138, 140, 159, 161, 162, 163, 165, 186], "dropna": [18, 131, 136, 186], "frac": [18, 29], "random_st": [18, 37, 82, 84, 86, 88, 94, 95, 99, 100, 101, 102, 103, 104, 105, 110, 111, 112, 113, 114, 115, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 128, 129, 132, 133, 134, 136, 137, 139, 141, 142, 143, 146, 149, 150, 151, 153, 155, 156, 157, 158, 160, 162, 164, 178], "reset_index": [18, 132, 137, 141], "drop": [18, 29, 37, 49, 62, 75, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 95, 96, 100, 101, 103, 106, 107, 108, 109, 110, 121, 143, 144, 145, 146, 147, 148, 149, 151, 153, 155, 156, 178], "therefor": [18, 29, 75, 76, 79, 84, 86, 88, 94, 97, 98, 99, 101, 104, 105, 109, 111, 117, 118, 119, 121, 127, 128, 129, 134, 135, 136, 139, 141, 142, 143, 146, 148, 153, 157, 162], "randomli": [18, 29, 99, 101, 104, 110, 112, 121, 155], "shuffl": [18, 37, 82, 97, 99, 102, 103, 104, 110, 116, 125, 143, 146], "break": [18, 97, 134], "spuriou": 18, "troubl": [18, 102], "outsid": [18, 151, 158, 161, 165], "scope": [18, 76, 139, 141, 146, 148], "regressor": [18, 24, 28, 29, 40, 46, 49, 83, 84, 94, 98, 103, 104, 105, 112, 113, 116, 117, 118, 119, 120, 121, 122, 124, 125, 134, 139, 146, 172, 175, 178], "sklearn": [18, 29, 45, 49, 62, 75, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 132, 133, 134, 136, 137, 138, 139, 141, 142, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 160, 162, 163, 164, 165, 178, 180, 182, 186], "randomforestregressor": [18, 110, 117, 119, 121, 123, 124], "except": [18, 89, 91, 144, 147, 158, 164], "exact": [18, 29, 117], "fold": [18, 25, 29, 49, 62, 75, 79, 97, 102, 104, 110, 116, 125, 127, 128, 129, 130, 131, 134, 135, 136, 145, 148, 153, 155, 157, 178, 186], "model_select": [18, 29, 49, 62, 79, 81, 82, 84, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 109, 110, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 132, 134, 136, 137, 141, 143, 144, 146, 147, 148, 149, 150, 151, 152, 153, 155, 156, 157, 158, 160, 162, 164, 178, 180, 186], "cross_valid": [18, 29, 49, 62, 68, 75, 79, 87, 88, 89, 90, 91, 92, 93, 94, 95, 100, 101, 102, 105, 109, 110, 116, 117, 118, 120, 125, 127, 128, 134, 136, 144, 145, 147, 148, 151, 152, 153, 178, 186], "cv": [18, 29, 49, 68, 75, 79, 88, 93, 94, 95, 97, 98, 99, 100, 101, 102, 103, 104, 105, 110, 116, 120, 125, 128, 134, 136, 144, 147, 148, 151, 153, 155, 156, 162, 178, 180, 186], "store": [18, 29, 76, 82, 84, 94, 96, 101, 102, 104, 106, 107, 108, 112, 120, 127, 128, 133, 134, 138, 142, 150, 151, 157, 186], "return_train_scor": [18, 29, 62, 105, 134], "count": [18, 49, 62, 75, 76, 78, 82, 84, 86, 87, 94, 97, 102, 106, 107, 108, 109, 158, 178, 186], "rang": [18, 40, 49, 62, 68, 75, 82, 84, 97, 99, 102, 104, 107, 108, 109, 110, 112, 133, 134, 140, 153, 154, 155, 157, 159, 161, 164, 165, 175, 178, 180, 186], "substanti": [18, 178, 186], "almost": [18, 49, 75, 83, 92, 104, 110, 137, 140, 146, 153, 164, 178], "100": [18, 49, 62, 82, 83, 94, 98, 101, 104, 105, 109, 110, 112, 113, 115, 116, 117, 118, 119, 120, 122, 124, 125, 126, 127, 128, 129, 131, 133, 134, 136, 137, 139, 142, 143, 146, 150, 155, 156, 157, 164, 186], "again": [18, 95, 100, 110, 112, 115, 124, 137, 139, 143, 154], "curv": [18, 43, 60, 62, 95, 100, 115, 124, 136, 140, 141, 143, 166], "n_estim": [18, 111, 112, 115, 117, 118, 119, 120, 121, 122, 123, 124], "numpi": [18, 29, 36, 62, 66, 68, 73, 84, 94, 97, 98, 100, 101, 102, 105, 107, 109, 110, 111, 112, 117, 118, 123, 124, 126, 127, 129, 130, 133, 134, 135, 136, 138, 139, 140, 142, 143, 145, 146, 148, 154, 157, 162, 163, 164, 165, 180], "np": [18, 29, 49, 62, 94, 95, 97, 98, 100, 101, 102, 105, 107, 109, 110, 111, 112, 115, 117, 118, 121, 123, 124, 126, 127, 129, 130, 131, 133, 134, 135, 136, 138, 139, 140, 142, 143, 145, 146, 148, 150, 154, 157, 162, 163, 164, 165, 175, 180], "arrai": [18, 29, 43, 44, 62, 68, 79, 82, 83, 84, 85, 87, 88, 97, 98, 104, 105, 110, 111, 112, 115, 118, 123, 124, 131, 134, 136, 141, 143, 147, 151, 158], "200": [18, 62, 75, 97, 107, 117, 118, 133, 134, 155], "500": [18, 62, 87, 88, 91, 104, 107, 109, 146, 154, 155], "1_000": [18, 29, 97, 115, 124], "decreas": [18, 29, 46, 49, 55, 60, 84, 110, 118, 127, 134, 146, 151, 157], "becom": [18, 95, 98, 100, 105, 110, 118, 119, 151, 155, 164, 180], "reach": [18, 98, 105, 115, 124, 151, 154, 162, 180], "plateau": [18, 98, 115, 124], "experi": [18, 36, 49, 62, 73, 81, 86, 95, 97, 98, 99, 100, 104, 105, 109, 115, 116, 118, 124, 125, 137, 142, 144, 147, 157, 160, 163, 164], "instead": [18, 29, 49, 62, 75, 79, 83, 84, 87, 89, 90, 91, 92, 94, 95, 97, 98, 100, 101, 104, 112, 117, 119, 120, 121, 131, 134, 136, 139, 143, 144, 145, 146, 147, 148, 149, 150, 153, 154, 155, 156, 157, 158, 159, 163, 164, 178], "max_depth": [18, 105, 111, 112, 115, 116, 117, 119, 120, 124, 125, 139, 158, 163, 164, 165, 178], "gap": [18, 105, 134], "begin": [18, 83, 115, 124, 133, 134, 153], "consid": [18, 44, 62, 71, 75, 87, 103, 105, 106, 109, 110, 111, 117, 118, 119, 121, 133, 134, 139, 144, 147, 158, 164, 173, 182, 186], "none": [18, 49, 95, 97, 100, 104, 106, 107, 108, 109, 112, 115, 119, 120, 124, 132, 133, 139, 154, 186], "rf_1_tree": 18, "cv_results_tre": 18, "train_scor": [18, 29, 105, 134], "return": [18, 28, 29, 43, 46, 68, 79, 82, 83, 87, 89, 91, 110, 112, 117, 130, 134, 135, 140, 141, 143, 144, 147, 151, 152, 154, 155, 180], "83120264": 18, "83309064": 18, "83195043": 18, "84834224": 18, "85790323": 18, "86235297": 18, "84791111": 18, "85183089": 18, "82241954": 18, "85045978": 18, "perfect": [18, 42, 58, 94, 104, 110, 117, 126, 128, 129, 142, 143, 162], "r2": [18, 28, 103, 109, 120, 125, 146, 148], "surpris": [18, 86, 97, 102, 103, 126, 129, 158, 164], "memor": [18, 83, 103, 104, 105], "expect": [18, 29, 68, 76, 78, 82, 87, 88, 99, 102, 103, 104, 109, 112, 119, 129, 131, 134, 136, 142, 146, 148, 153, 157, 162], "automat": [18, 68, 76, 82, 84, 87, 89, 91, 104, 152, 153, 178, 183], "prevent": [18, 44, 87, 91, 112, 119, 180], "max_it": [18, 29, 84, 87, 88, 91, 97, 118, 119, 125, 137], "recal": [18, 27, 62, 87, 99, 104, 118, 120, 137, 143, 152, 153, 155, 157, 186], "averag": [18, 29, 62, 83, 94, 97, 101, 102, 104, 107, 109, 110, 112, 117, 118, 119, 120, 121, 124, 127, 134, 137, 138, 143, 144, 146, 147, 148, 186], "small": [18, 40, 75, 78, 79, 88, 97, 100, 102, 104, 105, 110, 112, 117, 118, 119, 131, 134, 136, 137, 139, 149, 151, 156, 180], "behav": [18, 95, 100, 101, 134, 137, 178], "high": [18, 29, 37, 53, 55, 60, 66, 76, 78, 82, 86, 87, 100, 105, 106, 107, 108, 109, 110, 133, 137, 141, 151, 152, 155], "optimum": 18, "m7": [19, 20, 21, 30, 31, 166], "stratif": [20, 166], "framework": [22, 23, 34, 58, 59, 98, 102, 105, 116, 125, 145, 148, 153, 166, 183], "keep": [22, 29, 76, 93, 97, 104, 106, 107, 109, 110, 127, 128, 129, 131, 132, 136, 137, 139, 141, 142, 153, 155], "mind": [22, 76, 104, 110, 119, 126, 127, 128, 129, 142, 155], "metric": [22, 27, 29, 68, 79, 83, 98, 103, 104, 108, 112, 113, 115, 122, 123, 124, 127, 131, 134, 135, 136, 138, 139, 144, 145, 146, 147, 148, 154, 163, 166, 186], "besid": [22, 23, 33, 39, 82, 88, 90, 92, 94, 97, 98, 116, 125, 127, 158, 171, 184], "insight": [22, 33, 36, 49, 66, 76, 103, 105, 112, 126, 129, 140, 141, 146, 155], "addit": [22, 29, 44, 71, 79, 83, 87, 104, 107, 109, 115, 116, 120, 121, 124, 125, 134, 136, 139, 140, 143, 146, 151, 152, 153, 155, 157, 178], "necess": [22, 104], "appropri": [22, 76], "nest": [22, 23, 26, 119, 134, 149, 151, 153, 156, 166, 178, 184, 186], "wise": [23, 133, 153, 154, 184], "encount": [23, 75, 87, 89, 91, 102], "show": [23, 39, 76, 77, 78, 79, 81, 82, 83, 84, 85, 86, 87, 88, 93, 98, 99, 102, 104, 105, 106, 109, 111, 112, 117, 119, 120, 121, 128, 130, 131, 133, 134, 135, 136, 138, 139, 140, 141, 142, 143, 144, 147, 151, 152, 153, 154, 155, 157, 158, 160, 163, 164, 165, 171, 180, 183], "comparison": [23, 40, 99, 120, 143], "remov": [24, 35, 49, 76, 110, 118, 129, 131, 136, 151, 154, 186], "dummi": [24, 62, 81, 86, 91, 94, 96, 101, 143, 146], "reli": [24, 76, 82, 84, 110, 111, 128, 143], "ye": [24, 42, 44], "whatev": [24, 154], "chosen": [24, 87, 91, 108, 115, 124, 146, 184], "record": [25, 29, 51, 76, 83, 87, 104, 107, 108, 110], "suppos": [25, 87, 97], "imbalanc": [25, 62, 76, 101, 134, 143, 186], "addition": [25, 84, 134], "suspect": 25, "systemat": [25, 53, 60, 75, 100, 146, 152], "bias": [25, 133], "due": [25, 29, 86, 88, 102, 117, 121, 148, 158], "factor": [25, 29, 94, 137, 146], "devic": [25, 29], "socioeconom": 25, "most": [25, 29, 49, 62, 76, 82, 83, 86, 87, 91, 92, 95, 96, 97, 100, 101, 104, 106, 110, 111, 112, 118, 127, 134, 137, 138, 141, 143, 144, 147, 151, 154, 158, 164, 173, 175, 178, 180], "suitabl": 25, "abil": [25, 105, 143, 149, 156], "stratifi": [25, 96, 101, 102, 186], "leav": [25, 83, 95, 100, 119, 155, 162, 164], "inner": [26, 99, 116, 125, 134, 153, 178], "outer": [26, 99, 116, 124, 125, 133, 134, 153, 178, 186], "balanc": [27, 62, 105, 119, 134, 143, 144, 146, 147, 186], "roc": [27, 143], "auc": [27, 143], "precis": [27, 29, 60, 88, 119, 140, 143, 144, 147, 151], "regular": [27, 37, 39, 40, 45, 46, 49, 110, 112, 132, 133, 155, 163, 166, 184], "assum": [27, 29, 44, 45, 55, 71, 91, 102, 103, 110, 134, 139, 141, 178], "logist": [27, 41, 43, 45, 46, 68, 82, 84, 87, 88, 89, 90, 91, 92, 95, 96, 97, 100, 101, 102, 126, 129, 132, 137, 141, 143, 152, 158, 166], "stronger": [27, 107, 112, 137, 157], "lead": [27, 60, 76, 87, 88, 91, 97, 103, 117, 119, 120, 121, 134, 136, 137, 143, 150, 153, 154, 155, 157], "lower": [27, 28, 29, 49, 55, 91, 97, 98, 101, 104, 107, 110, 119, 124, 134, 136, 137, 143, 146, 148, 153, 157, 164], "r": [28, 100, 103, 104, 109, 110, 145, 146, 148], "absolut": [28, 29, 49, 94, 98, 104, 105, 113, 114, 115, 117, 118, 122, 123, 124, 131, 135, 136, 138, 139, 145, 146, 148], "median": [28, 93, 94, 99, 104, 109, 110, 120, 125, 127, 128, 134, 146, 147, 174, 175], "cross_val_scor": [28, 62, 97, 99, 103, 104, 121, 129, 144, 145, 147, 148, 149, 156], "model_a": 28, "neg_mean_squared_error": [28, 134, 148], "strictli": 28, "model_b": 28, "rememb": [28, 49, 76, 112, 131, 136, 137, 182, 186], "alia": 28, "neg": [28, 29, 49, 68, 104, 105, 110, 134, 135, 140, 143], "guarante": [28, 110, 162], "either": [28, 71, 83, 97, 100, 102, 126, 127, 129, 135, 141, 143, 146], "open": [29, 49, 62, 75, 80, 82, 85, 103, 106, 107, 178], "bike_rid": [29, 107], "command": [29, 49, 62, 75, 178, 186], "cycl": [29, 107], "index_col": [29, 103, 107, 154, 155, 180], "parse_d": [29, 103, 107], "index": [29, 49, 76, 83, 97, 102, 103, 107, 110, 112, 118, 127, 131, 134, 136, 137, 141, 147, 151, 153, 158], "appendix": [29, 94, 95, 98, 100, 104, 105, 111, 113, 114, 115, 118, 120, 121, 122, 123, 124, 130, 131, 132, 134, 135, 136, 137, 138, 140, 141, 143, 144, 145, 146, 147, 148, 158, 160, 161, 162, 163, 164, 165], "remind": 29, "cheap": [29, 51, 88], "sensor": [29, 76, 107], "gp": [29, 107], "cyclist": [29, 107], "meter": [29, 107], "expens": [29, 75, 118, 151, 184], "blindli": 29, "introduc": [29, 36, 83, 84, 104, 110, 112, 127, 131, 134, 136, 139, 140, 146, 148, 166], "flavor": 29, "classic": 29, "newton": 29, "second": [29, 37, 75, 84, 87, 90, 92, 96, 101, 102, 107, 111, 117, 118, 133, 142, 146, 155, 162, 164], "p_": 29, "meca": 29, "rho": 29, "sc_x": 29, "v_": 29, "c_r": 29, "mg": 29, "co": 29, "alpha": [29, 45, 46, 49, 76, 97, 100, 109, 110, 111, 112, 117, 123, 133, 134, 135, 137, 138, 139, 140, 141, 142, 146, 158, 162, 163, 164, 165], "sin": 29, "ma": 29, "v_d": 29, "air": 29, "densiti": [29, 133], "kg": [29, 159], "m": [29, 87, 97], "frontal": 29, "c_x": 29, "drag": 29, "coeffici": [29, 37, 40, 44, 49, 109, 134, 136, 137, 139, 140, 141, 146, 173], "v_a": 29, "roll": 29, "rider": 29, "bicycl": 29, "standard": [29, 49, 76, 79, 84, 88, 89, 91, 96, 97, 99, 101, 104, 105, 110, 116, 125, 134, 142, 143, 153], "graviti": 29, "81": [29, 75, 81, 86, 118, 119], "radian": 29, "equat": [29, 138, 141], "complex": [29, 46, 63, 82, 88, 89, 91, 93, 98, 106, 117, 137, 144, 147, 162, 163], "term": [29, 76, 83, 84, 103, 104, 112, 114, 117, 118, 121, 123, 127, 140, 158, 163], "within": [29, 34, 79, 97, 99, 102, 104, 109, 110, 112, 116, 118, 125, 127, 133, 134, 145, 148, 153, 154, 158, 165], "parenthesi": 29, "produc": [29, 164], "fight": [29, 39], "wind": 29, "resist": 29, "tire": 29, "floor": 29, "third": [29, 117, 133, 136], "hill": 29, "forward": [29, 107], "fourth": 29, "last": [29, 36, 49, 71, 87, 102, 106, 108, 133, 134, 139, 141, 143, 144, 147], "hi": [29, 108], "simplifi": [29, 49, 103, 104, 127, 141, 157, 159, 178], "beta_": 29, "closer": [29, 46, 102, 107, 134, 137, 141], "previous": [29, 49, 75, 87, 88, 95, 100, 103, 106, 111, 117, 118, 119, 120, 131, 133, 136, 137, 139, 141, 146, 149, 151, 153, 155, 156, 162, 163], "part": [29, 76, 87, 88, 99, 105, 110, 118, 129, 130, 134, 135, 137, 143, 158, 160, 164], "cube": 29, "multipli": [29, 148], "sine": 29, "angl": 29, "arc": 29, "tangent": 29, "arctan": 29, "ourself": [29, 143], "clip": 29, "brake": 29, "preprocess": [29, 36, 49, 62, 67, 68, 75, 76, 79, 87, 88, 89, 90, 91, 92, 93, 95, 97, 100, 101, 102, 109, 110, 112, 118, 121, 132, 133, 134, 136, 137, 139, 141, 142, 146, 149, 151, 152, 153, 155, 156, 157, 166, 178, 180, 182, 186], "linear_model": [29, 45, 49, 75, 79, 82, 84, 87, 88, 89, 91, 93, 97, 101, 102, 109, 110, 112, 129, 132, 133, 134, 136, 137, 138, 139, 141, 142, 143, 146, 148, 152, 158, 163, 165, 178, 180, 182], "ridgecv": [29, 49, 109, 110, 134], "shufflesplit": [29, 94, 95, 96, 98, 100, 101, 102, 103, 104, 105, 134], "n_split": [29, 94, 98, 99, 101, 102, 103, 104, 105, 110, 125, 134, 147, 153], "mae": [29, 124, 131, 135, 136, 148], "return_estim": [29, 49, 104, 109, 110, 116, 120, 125, 127, 134, 153, 186], "subsequ": [29, 73, 97, 105, 116, 119, 125, 126, 129, 131, 133, 134, 136, 182, 183], "Be": [29, 76, 87, 88, 89, 91, 105, 119, 142, 151, 152, 178], "awar": [29, 33, 34, 76, 83, 87, 88, 89, 91, 93, 105, 106, 119, 142, 151, 152, 178], "investig": [29, 84, 103, 110, 113, 116, 120, 122, 125, 127, 158], "consequ": [29, 102, 112, 118, 121], "003": [29, 79, 88, 92, 152, 153], "obtain": [29, 49, 62, 75, 79, 83, 87, 88, 89, 91, 93, 97, 99, 101, 103, 104, 107, 109, 110, 113, 119, 120, 122, 129, 133, 134, 137, 138, 142, 143, 146, 153, 154, 155, 156, 180], "closest": [29, 83, 133], "watt": [29, 107], "70": [29, 76, 93, 106, 120], "90": [29, 76, 82, 84, 94, 97, 102, 135], "neg_mean_absolute_error": [29, 94, 98, 104, 105, 117, 118, 119, 122, 124, 131, 136, 148], "request": [29, 87, 118, 134], "h": [29, 110], "beta": 29, "cadenc": [29, 107], "turn": [29, 75, 107, 131, 136], "pedal": [29, 107], "rotat": [29, 76, 97, 107], "per": [29, 76, 79, 81, 82, 83, 84, 86, 87, 88, 99, 104, 107, 109, 118, 121, 139, 143, 151, 152, 153, 155], "minut": [29, 33, 88, 107, 155], "beat": [29, 107], "1000": [29, 49, 88, 107, 119, 124, 125, 137, 143, 145, 146, 148, 157], "activ": [29, 71, 154, 180], "early_stop": [29, 119, 125], "40": [29, 76, 78, 82, 83, 84, 88, 103, 104, 106, 119, 122, 131, 135, 136, 140, 150, 151, 152, 155, 157, 159], "consider": [29, 119, 140], "test_scor": [29, 79, 87, 88, 90, 91, 92, 93, 94, 97, 99, 100, 101, 102, 103, 104, 105, 109, 117, 118, 120, 125, 127, 128, 129, 134, 136, 152, 153, 156, 158, 164], "dictionari": [29, 68, 79, 104], "made": [29, 35, 43, 76, 95, 97, 100, 103, 104, 108, 117, 143, 148, 152], "ignor": [29, 75, 87, 88, 90, 91, 92, 93, 94, 110, 157], "datafram": [29, 49, 62, 75, 76, 77, 78, 82, 83, 84, 87, 88, 93, 94, 96, 97, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 112, 117, 119, 120, 122, 123, 125, 127, 128, 133, 134, 139, 140, 141, 142, 143, 147, 148, 151, 153, 154, 155, 157, 158, 162, 163, 164, 165, 178, 186], "account": [29, 83, 94, 97, 106, 110, 143, 178], "date": [29, 88, 97, 106, 107], "hesit": 29, "uniqu": [29, 62, 82, 87, 97, 102, 112, 118, 151, 155, 164], "dai": 29, "datetimeindex": [29, 107], "went": 29, "df": [29, 75, 154], "capac": [29, 98], "leaveonegroupout": [29, 103], "had": [29, 104, 110, 136, 139, 141], "indic": [29, 76, 88, 97, 104, 107, 109, 110, 112, 127, 130, 134, 135, 157], "differenti": [29, 73, 76, 153, 159], "integ": [29, 71, 79, 82, 87, 89, 91, 97, 106, 108, 110, 112, 155, 157, 186], "align": [29, 108, 133, 137, 139, 155], "pessimist": 29, "optimist": [29, 83, 97, 99, 104], "deviat": [29, 49, 79, 84, 97, 99, 104, 105, 110, 116, 125, 134, 153], "analys": [29, 82, 110], "reus": [29, 130, 135, 144, 147, 153], "train_indic": 29, "test_indic": 29, "data_linear_model_train": 29, "data_linear_model": 29, "iloc": [29, 85, 102, 107, 109, 110, 111, 112, 117, 151, 162], "data_linear_model_test": 29, "data_train": [29, 82, 84, 88, 103, 104, 112, 113, 114, 115, 117, 119, 122, 123, 124, 129, 132, 137, 141, 143, 146, 149, 150, 151, 153, 155, 156, 157, 158, 160, 161, 163, 164, 165], "data_test": [29, 82, 83, 84, 85, 88, 103, 104, 112, 113, 114, 115, 117, 119, 122, 123, 124, 129, 132, 137, 141, 143, 146, 149, 150, 151, 153, 155, 156, 157, 158, 160, 162, 163, 164, 165], "target_train": [29, 82, 84, 86, 88, 102, 103, 104, 112, 113, 114, 115, 117, 119, 122, 123, 124, 129, 132, 137, 141, 143, 146, 149, 150, 151, 153, 155, 156, 157, 158, 160, 161, 163, 164, 165], "target_test": [29, 82, 83, 84, 85, 86, 88, 102, 103, 104, 113, 114, 115, 119, 122, 123, 124, 129, 132, 137, 141, 143, 146, 149, 150, 151, 153, 155, 156, 157, 158, 160, 164], "scatter": [29, 78, 109, 112, 114, 117, 123, 133, 142, 159, 161, 163, 164, 165], "catastroph": [29, 84], "portion": 29, "time_slic": 29, "slice": 29, "2020": [29, 107], "data_test_linear_model_subset": 29, "data_test_subset": [29, 129], "target_test_subset": 29, "pm": 29, "until": [29, 119, 143], "accur": [29, 44, 111, 134, 143], "motiv": [33, 120], "known": [33, 76, 108, 109, 134, 135, 141, 143, 146, 151, 158], "caveat": [33, 126, 129, 153, 166], "practic": [33, 60, 76, 79, 82, 83, 86, 93, 99, 101, 102, 104, 119, 121, 134, 142, 143, 144, 146, 147, 153, 154, 155], "magic": [34, 103], "tool": [34, 36, 79, 88, 112, 141, 153, 155], "margin": [34, 97, 110], "gain": [34, 36, 66, 76, 79, 81, 82, 83, 84, 86, 87, 88, 98, 113, 122, 126, 127, 129, 141, 146, 151, 152, 155], "tackl": [34, 60, 128], "selector": [34, 87, 88, 89, 90, 91, 92, 126, 129, 149, 151, 153, 155, 156], "recurs": 34, "main": [35, 49, 79, 84, 90, 92, 119, 127, 136, 139, 157, 166], "advantag": [35, 79, 127, 133], "fine": [35, 40, 88, 92, 153, 157, 183], "noisi": [35, 63, 105, 110, 112, 137, 142, 157, 162], "teach": [36, 52], "beginn": 36, "strong": [36, 110, 137, 157], "background": 36, "bring": 36, "vast": 36, "busi": 36, "intellig": 36, "industri": 36, "scientif": [36, 121], "discoveri": 36, "pillar": 36, "modern": 36, "field": [36, 76, 186], "central": 36, "easili": [36, 75, 76, 83, 84, 87, 133, 136, 162], "yet": [36, 75, 88, 90, 92, 134, 139], "dovetail": 36, "ecosystem": 36, "languag": 36, "step": [36, 49, 62, 76, 82, 83, 84, 88, 93, 119, 121, 127, 128, 131, 134, 136, 137, 139, 141, 142, 145, 148, 151, 152, 153, 155, 186], "lesson": [36, 152], "fundament": [36, 58, 100, 146], "stone": 36, "artifici": 36, "mine": 36, "cookbook": 36, "failur": [36, 58], "session": [36, 153, 155], "octob": 36, "2022": 36, "month": [36, 108, 143], "enrol": 36, "quizz": 36, "execut": [36, 131, 136, 149, 155, 156, 180], "platform": 36, "purpos": [36, 87, 88, 99, 101, 103, 104, 105, 114, 123, 126, 127, 129, 134, 137, 143, 152, 178], "educ": [36, 76, 82, 87, 88, 89, 90, 91, 92, 121, 141, 149, 151, 153, 155, 156], "prior": [36, 73], "matplotlib": [36, 73, 76, 84, 94, 97, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 117, 123, 125, 127, 128, 133, 134, 135, 137, 138, 140, 141, 142, 143, 146, 147, 158, 162, 163, 164, 165], "quick": [36, 73, 76, 106, 109, 118, 159], "publicli": 36, "cite": 36, "project": [36, 154], "zenodo": 36, "archiv": [36, 93, 97], "doi": 36, "5281": 36, "7220306": 36, "repositori": [36, 104, 109], "inria": 36, "publish": [36, 104, 109], "static": 36, "rocket": 36, "top": [36, 76, 143, 154, 155, 161, 162, 165], "interact": [36, 49, 76, 107, 131, 134, 136, 139, 154, 155, 157, 180], "cell": [36, 76, 80, 82, 84, 85, 88, 93, 99, 104, 111, 117, 118, 133, 134, 138, 139, 142, 143, 151, 153, 155, 158, 164, 165], "binder": 36, "video": [36, 93, 173], "youtub": 36, "playlist": 36, "channel": 36, "www": [36, 76, 83, 104, 109], "pl2oka_2qdj": 36, "m44koooi7x8tu85wr4ez4f": 36, "version": [36, 84, 106, 118, 120, 133, 155, 164], "host": [36, 155], "fun": 36, "infer": [37, 107, 127, 140, 183], "importance_permut": 37, "correl": [37, 49, 76, 108, 110, 121, 127, 134, 139], "divid": [37, 84, 94, 97, 105, 135, 143, 153, 155], "receiv": [37, 143], "cardin": [37, 87, 110], "independ": [37, 87, 97, 99, 103, 112, 118, 119, 133, 134, 143, 146, 152, 155], "could": [37, 62, 75, 76, 82, 83, 84, 86, 87, 88, 94, 95, 97, 99, 100, 101, 103, 104, 105, 106, 107, 108, 109, 110, 111, 118, 120, 121, 125, 127, 129, 130, 133, 134, 135, 138, 139, 140, 141, 142, 143, 144, 146, 147, 152, 153, 154, 157, 162], "m4": [38, 41, 47, 166], "parametr": [39, 130, 135, 138, 140, 155, 158, 163, 165, 172], "implic": 39, "dimension": [39, 68, 73, 76, 97, 126, 129, 131, 133, 136, 137, 141, 151, 154, 158], "effect": [39, 45, 49, 61, 62, 84, 95, 99, 100, 109, 110, 112, 119, 120, 121, 132, 137, 163, 164, 166], "relationship": [39, 76, 82, 87, 88, 103, 110, 112, 133, 134, 139, 140, 143, 151, 153, 155, 159], "adjust": [40, 49, 60, 87, 131, 136, 151, 154, 158], "successfulli": [40, 101, 117, 133], "scale": [40, 45, 49, 62, 74, 75, 84, 87, 88, 95, 97, 100, 104, 112, 118, 146, 151, 152, 155, 157, 178, 184, 186], "approxim": [40, 62, 79, 83, 84, 92, 94, 97, 101, 112, 124, 133, 134, 136, 137, 157, 186], "dynam": 40, "linearli": [40, 42, 45, 82, 133, 139, 142], "extra": [40, 75, 107, 137, 144, 147, 153], "beyond": [41, 76, 139, 141, 146, 148, 166], "Is": [42, 44, 81, 86, 106], "linearregress": [43, 45, 134, 136, 138, 139, 146, 148, 163, 165, 178], "coef_": [43, 44, 49, 109, 110, 128, 134, 137, 138, 139, 141, 152, 183], "intercept_": [43, 44, 138, 139], "boundari": [43, 132, 133, 141, 142, 158, 160, 162, 163, 164], "predict_proba": [43, 46, 84, 133, 137, 141, 143, 148, 151, 158, 164], "probabl": [43, 93, 104, 109, 110, 111, 133, 136, 137, 148, 158, 180], "extract": [44, 79, 97, 107, 110, 112, 134, 151, 155, 186], "straight": [44, 88, 133, 137, 139, 141, 142, 163], "float": [44, 107, 109, 118, 155], "express": [44, 49, 63, 75, 92, 95, 100, 104, 109, 110, 117, 131, 133, 136, 137, 139, 142, 154, 157, 162, 180], "ensur": [44, 46, 97, 99, 102, 119, 133, 137], "extrapol": [44, 133, 161, 165, 172], "regardless": [44, 133, 134, 158], "inher": [44, 110], "robust": [45, 92, 104, 110, 120, 134], "outlier": [45, 94, 109, 134, 148, 162], "wide": [45, 82], "forc": [45, 84, 90, 92, 111, 118, 121, 134, 138], "penal": [45, 134], "scientist": [45, 99], "prepar": 45, "plan": [45, 164], "strength": [45, 46, 49, 132, 134, 137, 155], "penalti": [46, 49, 110, 132, 137], "magnitud": [46, 110, 132, 134, 137, 173], "l2": [46, 132, 137], "confid": [46, 133, 137, 141, 143], "ames_housing_no_miss": [49, 75, 106, 134, 178], "ames_h": [49, 75, 93, 106, 134, 145, 146, 148, 178], "salepric": [49, 75, 93, 106, 134, 145, 146, 148, 178], "numerical_featur": [49, 75, 106, 178], "lotfrontag": [49, 75, 93, 106, 134, 178], "lotarea": [49, 75, 93, 106, 134, 178], "masvnrarea": [49, 75, 106, 178], "bsmtfinsf1": [49, 75, 106, 178], "bsmtfinsf2": [49, 75, 106, 178], "bsmtunfsf": [49, 75, 106, 178], "totalbsmtsf": [49, 75, 106, 178], "1stflrsf": [49, 75, 106, 178], "2ndflrsf": [49, 75, 106, 178], "lowqualfinsf": [49, 75, 106, 178], "grlivarea": [49, 75, 106, 178], "bedroomabvgr": [49, 75, 106, 178], "kitchenabvgr": [49, 75, 106, 178], "totrmsabvgrd": [49, 75, 106, 178], "fireplac": [49, 75, 106, 178], "garagecar": [49, 75, 106, 178], "garagearea": [49, 75, 106, 178], "wooddecksf": [49, 75, 106, 178], "openporchsf": [49, 75, 106, 178], "enclosedporch": [49, 75, 106, 178], "3ssnporch": [49, 75, 106, 178], "screenporch": [49, 75, 93, 106, 178], "poolarea": [49, 75, 93, 106, 134, 178], "miscval": [49, 75, 93, 106, 178], "data_numer": [49, 79, 81, 82, 84, 86, 178], "largest": [49, 109], "1e0": 49, "000": [49, 51, 75, 91, 94, 102, 104, 109, 117, 118, 126, 129, 141, 146, 156, 157], "1e5": 49, "larger": [49, 84, 87, 105, 119, 124, 136, 137, 139, 140, 149, 150, 153, 156, 157, 158, 175], "notat": 49, "box": [49, 99, 109, 116, 125, 127, 128, 134, 144, 147, 186], "garag": 49, "just": [49, 91, 103, 104, 105, 107, 110, 111, 112, 115, 119, 121, 124, 134, 139, 141, 143], "logspac": [49, 95, 100, 109, 134, 150, 157], "num": [49, 76, 82, 87, 88, 89, 90, 91, 92, 93, 94, 95, 98, 100, 101, 109, 112, 117, 121, 123, 130, 134, 135, 138, 140, 149, 150, 151, 153, 155, 156, 157], "101": [49, 186], "alpha_": [49, 134], "fall": [49, 104, 146, 155], "preprocessor": [49, 88, 89, 90, 91, 92, 93, 97, 106, 121, 149, 151, 152, 153, 155, 156, 178, 186], "deal": [49, 83, 87, 88, 92, 102, 103, 108, 126, 129, 133, 136, 139, 141, 148, 159, 178], "onehotencod": [49, 74, 75, 87, 88, 89, 90, 91, 92, 93, 134], "categorical_featur": [49, 93, 106], "yield": [49, 92, 119, 138], "long": [49, 92, 106, 107, 109, 131, 136, 152], "splinetransform": [49, 133, 139], "influenc": [49, 98, 105, 110, 134, 139, 146, 155, 171], "nystroem": [49, 131, 133, 136, 137, 139], "kernel": [49, 95, 100, 131, 133, 136, 137, 139, 142], "poli": [49, 131, 133, 136, 139], "n_compon": [49, 131, 133, 136, 137, 139], "300": [49, 84, 107, 112, 117, 119, 123, 130, 135, 138, 140, 162], "studi": [51, 62, 76, 95, 97, 100, 104, 142, 186], "apart": [51, 110], "estat": [51, 104], "thousand": [51, 104, 109, 110], "entertain": 51, "spaciou": 51, "updat": [51, 93, 186], "bedroom": [51, 104, 109, 110], "bathroom": 51, "lakeview": 51, "97630": 51, "1st": [51, 76, 87, 136], "nightlif": 51, "privat": [51, 76, 82, 87, 88, 151, 155], "backyard": 51, "buyer": 51, "market": 51, "kind": [51, 76, 88, 92, 110, 124, 139, 146, 173, 186], "sub": [52, 99, 100, 158], "vocabulari": 52, "varianc": [53, 58, 60, 97, 105, 110, 146, 166], "low": [55, 66, 76, 78, 82, 86, 97, 107, 109, 110, 112, 119, 133, 137, 143, 158, 162, 180], "littl": [55, 82, 97, 102, 154], "reduct": [55, 110], "steadi": 55, "label": [55, 60, 71, 78, 82, 87, 88, 91, 101, 102, 103, 111, 112, 117, 123, 135, 140, 141, 143, 144, 147, 163, 165], "slow": [55, 92, 119], "tradeoff": [55, 60, 105], "m2": [57, 59, 61, 166], "trade": [58, 60, 79, 133, 137, 162, 166, 171, 173], "off": [58, 60, 76, 79, 94, 106, 133, 137, 143, 162, 166, 171, 173], "character": [58, 110, 143], "why": [58, 62, 68, 76, 88, 96, 101, 107, 110, 137, 148, 180], "aris": [58, 76], "Then": [58, 73, 79, 84, 88, 94, 104, 112, 116, 120, 125, 126, 127, 128, 129, 133, 137, 139, 141, 144, 145, 146, 147, 148, 153, 155, 158], "quantifi": [58, 76, 105, 110, 130, 135, 186], "contrast": [58, 76, 87, 104, 117, 140, 163], "importantli": 58, "emphas": [58, 120], "happen": [60, 68, 76, 89, 91, 121, 132, 136, 158], "suffer": [60, 84, 108], "lack": 60, "captur": [60, 76, 105, 110, 133, 134], "neither": [60, 102], "nor": 60, "still": [60, 79, 84, 87, 88, 92, 105, 109, 110, 111, 113, 122, 133, 134, 137, 139, 146, 154, 155, 158, 162], "variat": [60, 79, 104, 105, 110, 112, 134, 146], "fulli": [60, 87, 104, 115, 119, 124], "determin": [60, 87, 95, 100, 143, 146], "irreduc": 60, "decompos": 60, "chapter": [60, 186], "diagnos": 60, "blood_transfus": [62, 95, 100, 108, 143, 144, 147], "propos": [62, 186], "multiclass": [62, 158, 164, 186], "proport": [62, 98, 101, 108, 137, 143, 146, 186], "twice": [62, 143, 186], "value_count": [62, 76, 77, 78, 86, 87, 102, 106, 108, 143, 186], "dummyclassifi": [62, 81, 86, 91, 96, 101, 143], "most_frequ": [62, 86, 91, 101, 106, 143], "75": [62, 82, 84, 87, 93, 94, 101, 103, 106, 109], "balanced_accuraci": [62, 143, 144, 147, 186], "remaind": [62, 87, 88, 90, 92, 121, 149, 151, 153, 155, 156], "add": [62, 107, 110, 117, 118, 127, 131, 134, 136, 139, 140, 143, 144, 147, 161, 165], "faster": [62, 68, 76, 84, 119, 149, 156], "distanc": [62, 84, 137, 157], "normal": [62, 84, 93, 97, 106, 107, 108, 109, 110, 118, 141, 143, 146, 150, 151, 157, 158, 164], "irrelev": 62, "make_pipelin": [62, 68, 79, 84, 87, 88, 89, 90, 91, 92, 97, 100, 101, 102, 106, 109, 110, 112, 118, 121, 126, 127, 128, 129, 131, 132, 133, 134, 136, 137, 139, 141, 142, 157], "get_param": [62, 95, 100, 113, 122, 152, 182, 186], "n_neighbor": [62, 80, 85, 150, 157, 183, 186], "clearli": [62, 86, 98, 100], "param_rang": [62, 100, 105, 115, 124, 131, 136], "affirm": 62, "highli": [63, 76, 133], "much": [63, 76, 91, 92, 94, 101, 104, 105, 110, 118, 119, 121, 122, 127, 133, 136, 180], "m1": [65, 67, 70, 166], "adult_censu": [66, 76, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 96, 101, 121, 149, 151, 152, 153, 154, 155, 156], "comma": [66, 76, 106, 107, 108], "file": [66, 76, 82, 83, 106, 107, 108, 144, 147, 186], "alreadi": [66, 76, 82, 83, 84, 100, 110, 119, 121, 133, 134, 150, 155, 157], "packag": [66, 118, 134, 144, 147], "survei": 66, "incom": [66, 76, 82, 86, 94, 104, 109, 110], "seaborn": [66, 76, 77, 78, 84, 107, 108, 109, 110, 111, 112, 117, 123, 135, 137, 138, 139, 140, 141, 142, 151, 154, 158, 159, 162, 163, 164, 165], "visual": [66, 70, 75, 84, 87, 98, 100, 103, 104, 107, 112, 117, 130, 133, 134, 135, 141, 143, 146, 151, 154, 158, 159, 163, 164, 166, 183], "scipi": [66, 119, 122, 155], "organ": [66, 164], "five": [68, 83, 88, 104], "overlap": [68, 78, 79, 112, 148, 155], "lie": 68, "fewer": [68, 146], "jupyt": [70, 82, 84, 85, 88, 99, 104, 111, 133, 134, 138, 139, 142, 143, 151, 153, 155, 158, 164, 165, 166], "ordin": [71, 75, 88, 91, 118], "string": [71, 82, 87, 88, 89, 91, 104, 106, 144, 147, 148, 153, 186], "meaning": [71, 87, 92, 126, 128, 129, 140, 146, 151], "hot": [71, 87, 88, 133], "represent": [71, 82, 84, 85, 87, 88, 90, 92, 93, 98, 99, 104, 108, 109, 111, 118, 121, 133, 134, 138, 139, 142, 143, 151, 153, 155, 158, 162, 164, 165], "compani": [71, 103], "sector": 71, "construct": [71, 112, 121, 155], "retail": 71, "energi": [71, 103, 107], "insur": 71, "phone": 71, "sale": [71, 75, 88], "depart": 71, "employe": 71, "profit": 71, "quarter": [71, 103], "head": [71, 75, 76, 78, 82, 83, 87, 88, 104, 106, 107, 108, 109, 110, 131, 136, 140, 151, 152, 155, 159], "tabl": [73, 76, 119, 121, 151], "progress": [73, 150, 157], "attent": [73, 111], "extend": [73, 82], "mix": [73, 74, 76, 88, 97, 162], "unknown": [73, 87, 89, 91, 121, 146], "notabl": [74, 143], "ordinalencod": [74, 87, 88, 89, 90, 91, 92, 121, 149, 151, 153, 155, 156, 178], "200_000": [75, 93], "astyp": [75, 93, 106, 133, 150, 155, 157, 162], "int": [75, 79, 93, 111, 155], "did": [75, 76, 84, 87, 96, 101, 103, 104, 106, 107, 119, 127, 129, 133, 137, 139, 143, 144, 147, 151, 152, 153, 155, 157, 160, 164, 183], "convert": [75, 104, 111, 112, 123, 157], "info": [75, 83, 97, 106, 107, 108, 109], "examin": [75, 134], "select_dtyp": [75, 106, 145, 146, 148], "make_column_selector": [75, 87, 88, 89, 90, 91, 92, 121, 149, 151, 153, 155, 156], "shown": [75, 76, 104, 117, 133, 137, 141, 146, 153, 160, 164], "among": [75, 87, 88, 102, 127, 157], "quantit": [75, 82, 117, 130, 135, 138], "exclud": [75, 76, 127], "overallqu": [75, 106], "overallcond": [75, 106], "yearbuilt": [75, 106, 134], "sole": [75, 129, 146], "treat": [75, 88, 93, 134], "issu": [75, 76, 87, 88, 102, 103, 104, 107, 108, 118, 133, 134, 139], "rare": [75, 76, 87, 88, 106, 121, 134], "handle_unknown": [75, 87, 88, 89, 90, 91, 92, 93, 121, 149, 151, 153, 155, 156], "mere": 75, "chanc": [75, 101, 104, 112, 126, 129, 143, 164], "partit": [75, 79, 144, 147, 158, 160, 162, 163, 164], "classifact": 75, "li": [75, 87, 112], "place": [76, 129, 134, 139], "workflow": 76, "1994": [76, 97], "download": [76, 104, 109], "openml": [76, 83], "webpag": 76, "1590": [76, 83], "manipul": [76, 80, 85, 95, 100, 104], "tutori": 76, "50k": [76, 81, 82, 83, 84, 85, 86, 88, 151, 155], "year": [76, 82, 106, 134, 151], "heterogen": [76, 82, 88, 106, 134], "employ": 76, "covari": 76, "workclass": [76, 82, 87, 88, 151, 153, 155], "marit": [76, 82, 87, 88, 151, 153, 155], "occup": [76, 82, 87, 88, 109, 110, 151, 153, 155], "race": [76, 82, 87, 88, 107, 151, 153, 155], "sex": [76, 82, 87, 88, 151, 153, 155], "loss": [76, 79, 81, 82, 83, 84, 86, 87, 88, 146, 148, 151, 152, 155], "week": [76, 79, 81, 82, 83, 84, 86, 87, 88, 151, 152, 155], "countri": [76, 82, 87, 88, 151, 153, 155], "11th": [76, 82, 87, 151, 155], "marri": [76, 82, 87, 88, 151, 155], "op": [76, 82, 87, 151, 155], "inspct": [76, 82, 87, 151, 155], "own": [76, 82, 87, 88, 119, 139, 151, 155], "child": [76, 82, 87, 88, 151, 155], "male": [76, 82, 87, 88, 151, 155], "lt": [76, 82, 83, 155], "hs": [76, 82, 87, 88, 151, 155], "grad": [76, 82, 87, 88, 151, 155], "civ": [76, 82, 87, 88, 151, 155], "spous": [76, 82, 87, 88, 151, 155], "farm": [76, 82, 87, 151, 155], "fish": [76, 82, 87, 151, 155], "husband": [76, 82, 87, 88, 151, 155], "white": [76, 82, 87, 88, 133, 137, 141, 151, 155, 164], "local": [76, 82, 87, 93, 108, 139, 151, 155], "gov": [76, 82, 87, 151, 155], "assoc": [76, 82, 87, 151, 155], "acdm": [76, 82, 87, 151, 155], "protect": [76, 82, 87, 151, 155], "serv": [76, 82, 87, 90, 92, 107, 143, 151, 155], "gt": [76, 82, 155], "colleg": [76, 82, 87, 151, 155], "7688": [76, 82, 151, 152, 155], "femal": [76, 82, 87, 88, 151, 155], "30": [76, 82, 87, 88, 94, 95, 97, 98, 100, 105, 106, 108, 109, 112, 118, 119, 120, 122, 136, 149, 151, 152, 153, 155, 156, 162, 164, 165], "revenu": [76, 86, 87, 134], "target_column": [76, 111, 132, 137, 141, 158, 159, 160, 164], "37155": [76, 86], "11687": [76, 86], "dtype": [76, 78, 82, 83, 84, 85, 86, 87, 88, 89, 91, 94, 101, 104, 106, 107, 108, 109, 111, 134, 141, 143, 151, 155, 157, 158], "int64": [76, 78, 82, 86, 87, 106, 108, 157], "imbal": [76, 108, 137], "special": [76, 107], "healthi": 76, "ill": [76, 134], "numerical_column": [76, 79, 81, 82, 84, 86, 88, 90, 92, 152], "categorical_column": [76, 87, 88, 89, 90, 91, 92, 151, 153, 155], "all_column": 76, "print": [76, 79, 82, 83, 84, 85, 86, 87, 88, 90, 91, 92, 93, 97, 99, 100, 102, 103, 104, 109, 110, 111, 112, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 127, 129, 130, 134, 135, 136, 138, 139, 140, 141, 143, 144, 146, 147, 148, 150, 151, 152, 153, 155, 156, 157, 158, 164], "48842": [76, 82, 87, 151, 155], "subtract": [76, 84], "mayb": [76, 97, 105, 109], "peculiar": [76, 106], "malfunct": 76, "afterward": [76, 83, 110], "cap": [76, 99, 109, 125, 127, 128, 134, 147], "hist": [76, 78, 94, 97, 101, 104, 105, 106, 107, 108, 109, 141], "figsiz": [76, 78, 106, 107, 108, 109, 110, 133, 134, 143, 146, 158, 162, 163, 164], "func": [76, 104, 109, 144, 147], "assign": [76, 84, 101, 106, 111, 117, 133, 139, 141, 145, 148], "underscor": [76, 84, 152], "garbag": 76, "comment": 76, "retir": 76, "filter": [76, 87, 107, 151], "peak": 76, "ll": 76, "32650": 76, "16192": 76, "disproport": 76, "fair": [76, 99, 120], "deploi": [76, 88, 104, 153, 163], "mitig": [76, 119], "deploy": [76, 153], "compon": [76, 131, 136, 139, 158, 182], "unexpect": [76, 102], "gender": 76, "15784": 76, "10878": 76, "bachelor": [76, 87, 88], "8025": 76, "master": [76, 87], "2657": 76, "voc": [76, 87], "2061": 76, "1812": 76, "1601": 76, "10th": [76, 87], "1389": 76, "7th": [76, 87], "8th": [76, 87], "955": 76, "prof": [76, 87, 88], "school": [76, 87, 97], "834": 76, "9th": [76, 87], "756": 76, "12th": [76, 87], "657": 76, "doctor": [76, 87], "594": 76, "5th": [76, 87, 136], "6th": [76, 87], "509": 76, "4th": [76, 87], "247": 76, "preschool": [76, 87], "crosstab": 76, "entri": [76, 79, 104, 106, 107, 108, 109, 116, 125, 130, 135, 141], "lose": 76, "redund": [76, 104, 127, 131, 136, 139], "upcom": [76, 143, 152], "latter": [76, 84, 99, 127, 143], "pairplot": [76, 77, 78, 107, 108, 109, 110, 159], "diagon": [76, 108, 133, 143, 146, 151, 159], "reveal": [76, 104], "sn": [76, 84, 107, 108, 109, 110, 111, 112, 117, 123, 135, 137, 138, 139, 140, 141, 142, 151, 154, 158, 159, 162, 163, 164, 165], "readabl": [76, 151, 154, 180], "n_samples_to_plot": 76, "5000": [76, 108, 127, 128, 135, 140], "var": 76, "hue": [76, 78, 107, 108, 109, 111, 137, 141, 142, 154, 158, 159, 162, 164], "plot_kw": [76, 110], "height": [76, 78, 131, 136], "diag_kind": [76, 110], "diag_kw": 76, "written": [76, 97, 109], "scatterplot": [76, 84, 109, 111, 112, 117, 123, 135, 137, 138, 139, 140, 141, 142, 154, 158, 159, 162, 163, 164, 165], "region": [76, 104, 105, 133, 137, 141, 151, 155], "pyplot": [76, 84, 94, 97, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 117, 123, 125, 127, 128, 133, 134, 135, 137, 138, 141, 142, 143, 146, 147, 158, 162, 163, 164, 165], "plt": [76, 84, 94, 97, 99, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 117, 123, 125, 127, 128, 133, 134, 135, 137, 138, 141, 142, 143, 146, 147, 158, 162, 163, 164, 165], "ax": [76, 84, 106, 107, 110, 111, 121, 133, 134, 135, 137, 139, 140, 142, 143, 146, 151, 154, 158, 162, 163, 164], "age_limit": 76, "axvlin": [76, 109, 110], "ymin": [76, 109], "ymax": [76, 109], "linestyl": [76, 109, 112, 123, 133, 137, 143, 163], "hours_per_week_limit": 76, "axhlin": 76, "xmin": 76, "xmax": 76, "annot": [76, 151], "fontsiz": 76, "AND": 76, "seem": [76, 79, 82, 85, 86, 90, 92, 100, 103, 109, 110, 119, 121, 124, 134, 135, 146, 152, 158], "complic": [76, 109, 127], "similarli": [76, 95, 96, 98, 100, 101, 103, 114, 119, 121, 123, 134, 141, 143, 155, 165], "somewhat": [76, 112], "arbitrari": [76, 87, 88, 89, 91, 92, 93, 110, 140], "straightforward": [76, 112], "obviou": [76, 97, 107, 142], "highlight": [76, 83, 87, 97, 99, 103, 111, 117, 126, 127, 129, 134, 143, 151, 153, 158, 163], "imagin": [77, 78, 110, 142], "feel": [77, 78, 87, 116, 119, 125, 134, 148, 186], "penguins_classif": [77, 78, 111, 132, 137, 141, 158, 159, 160, 162, 164], "There": [78, 84, 104, 108], "adeli": [78, 132, 137, 141, 158, 159, 164], "151": [78, 87, 154, 155], "gentoo": [78, 158, 159, 164], "chinstrap": [78, 132, 137, 141, 158, 159], "68": [78, 93, 106, 120, 155, 157], "pairplot_figur": [78, 159], "prioriti": 78, "tweak": 78, "subfigur": 78, "perfectli": [78, 92, 108, 117, 119, 139, 146, 162], "downsid": [79, 136], "amount": [79, 97, 104, 108, 121, 134], "smaller": [79, 104, 118, 119, 124, 136, 137, 148, 175], "repetit": [79, 97, 151], "aggreg": [79, 109, 116, 125, 134, 143], "clone": [79, 112], "earlier": [79, 88, 109, 120, 143, 158], "computation": [79, 118, 139, 151, 180], "intens": [79, 101, 180], "cv_result": [79, 87, 88, 90, 91, 92, 93, 100, 104, 105, 109, 119, 120, 122, 127, 128, 134, 136, 148, 151, 152, 153, 154, 155, 157, 180], "cpu": [79, 88, 105, 117, 120, 151, 155], "894": 79, "ms": [79, 88, 105, 120, 151], "sy": [79, 88, 105, 120, 151, 155], "299": [79, 136], "total": [79, 88, 97, 103, 104, 105, 106, 107, 108, 109, 110, 120, 136, 143, 151, 155, 157], "wall": [79, 88, 105, 120, 151, 155], "680": 79, "fit_tim": [79, 87, 88, 100, 104, 117, 118, 127, 147, 153], "10083437": 79, "09485173": 79, "09516358": 79, "09389663": 79, "09959269": 79, "score_tim": [79, 87, 88, 100, 104, 117, 118, 127, 147, 153], "02249742": 79, "02220821": 79, "02236342": 79, "02161741": 79, "02207828": 79, "79557785": 79, "80049135": 79, "79965192": 79, "79873055": 79, "80436118": 79, "iii": 79, "distinct": [79, 82, 99, 102], "match": [79, 80, 85, 99, 141], "stabil": [79, 110], "discard": [79, 104, 109, 111, 158], "round": [79, 96, 101, 111], "themselv": 79, "3f": [79, 82, 83, 84, 86, 87, 88, 90, 91, 92, 93, 97, 99, 100, 102, 109, 117, 118, 120, 121, 123, 125, 129, 130, 135, 136, 141, 143, 146, 147, 148, 152, 153, 156, 158], "std": [79, 82, 84, 87, 88, 90, 91, 92, 93, 94, 97, 99, 100, 102, 103, 104, 109, 110, 112, 117, 118, 120, 121, 125, 131, 134, 136, 147, 148, 152, 153], "800": [79, 152], "crucial": [79, 110, 119], "bar": [79, 102, 106, 110, 134, 141, 158], "decim": 79, "trustworthi": [79, 99], "compat": [79, 153], "familiar": [80, 85, 109, 116, 125, 145, 148], "conveni": [80, 85, 134], "directli": [80, 83, 85, 88, 110, 117, 139, 148, 158], "insid": [80, 85, 87, 106, 144, 147, 178], "pager": [80, 85], "roughli": [81, 86, 112, 124, 140], "simplest": [81, 86], "irrespect": [81, 86, 101, 133, 180, 186], "82": [81, 83, 86, 103, 118, 119], "train_test_split": [81, 82, 84, 86, 88, 103, 104, 110, 113, 114, 115, 119, 122, 123, 124, 126, 129, 132, 137, 141, 143, 146, 149, 150, 151, 153, 155, 156, 157, 158, 160, 164], "behavior": [81, 86, 134, 137, 142, 163], "oversimplifi": 82, "exclus": [82, 133], "helper": [82, 84, 87, 88, 130, 135, 139, 144, 147], "duplic": [82, 87, 88, 112, 151, 155], "48837": [82, 87, 151, 155], "48838": [82, 87, 151, 155], "48839": [82, 87, 151, 155], "48840": [82, 87, 151, 155], "48841": [82, 87, 151, 155], "explicit": [82, 83, 104, 139, 145, 148], "At": [82, 99, 102, 104, 112, 143, 164], "moreov": 82, "o": [82, 164], "self": [82, 83, 87, 99, 144, 147, 155], "explanatori": [82, 103], "000000": [82, 84, 94, 107, 109], "643585": 82, "710510": 82, "min": [82, 84, 94, 107, 109, 112, 130, 134, 135, 138, 140, 162, 163, 165, 175], "37": [82, 83, 84, 87, 104, 106, 109, 110, 119, 154], "48": [82, 83, 84, 106, 119, 120, 122, 154], "max": [82, 84, 94, 107, 109, 112, 130, 134, 135, 138, 139, 140, 156, 162, 163, 165, 175, 180], "float64": [82, 94, 101, 104, 106, 107, 108, 109, 141], "unusu": 82, "memori": [82, 103, 106, 107, 108, 109, 136, 139, 152, 153], "test_siz": [82, 94, 98, 101, 104, 105, 113, 115, 122, 124, 137, 143, 153], "determinist": [82, 101, 139], "specifi": [82, 87, 88, 106, 107, 121, 140, 153, 155, 183], "remain": [82, 83, 102, 103, 110, 127, 134, 142, 155], "quickli": [82, 106, 109, 110, 119, 139, 141, 143, 154, 155, 164], "got": [82, 116, 125, 142, 165], "1f": [82, 112, 148], "12211": 82, "36631": [82, 84], "cours": [82, 87, 106, 127, 130, 135, 139, 144, 147, 160, 164], "environ": [82, 84, 85, 88, 93, 99, 104, 111, 133, 134, 138, 139, 142, 143, 151, 153, 155, 158, 164, 165], "pleas": [82, 84, 85, 88, 93, 96, 99, 101, 104, 111, 133, 134, 138, 139, 142, 143, 151, 153, 155, 158, 164, 165, 178, 186], "rerun": [82, 84, 85, 88, 93, 99, 104, 111, 133, 134, 138, 139, 142, 143, 151, 153, 155, 158, 164, 165], "unabl": [82, 84, 85, 88, 93, 99, 102, 104, 111, 133, 134, 138, 139, 142, 143, 151, 153, 155, 158, 164, 165], "render": [82, 84, 85, 88, 93, 99, 104, 111, 133, 134, 138, 139, 142, 143, 151, 153, 155, 158, 164, 165], "nbviewer": [82, 84, 85, 88, 93, 99, 104, 111, 133, 134, 138, 139, 142, 143, 151, 153, 155, 158, 164, 165], "logisticregressionlogisticregress": [82, 84, 88, 93, 133, 143, 158], "807": [82, 84], "fraction": [82, 105, 119, 143, 146], "correctli": [82, 92, 93, 102, 111, 143], "visit": 83, "glossari": [83, 166], "fed": 83, "41": [83, 104, 106, 109, 110, 122], "92": [83, 87, 94, 146, 154, 186], "3273": 83, "side": [83, 94, 121, 124, 153, 163], "39068": 83, "39069": 83, "39070": 83, "39071": 83, "39072": 83, "39073": 83, "linger": [83, 87, 97, 104], "denomin": 83, "major": [83, 86, 101, 137], "seldom": 83, "target_predict": [83, 103, 104, 111, 122, 123, 130, 135, 139, 143, 146, 162, 163], "sake": [83, 93, 96, 101, 119, 139, 142, 153, 158, 178], "simplic": [83, 93, 96, 101, 139, 142, 158, 178], "agre": [83, 124, 141], "bool": [83, 106, 143], "mistak": [83, 111, 129, 137, 143, 162], "success": [83, 84, 117, 164], "8242776341719346": 83, "harder": [83, 127], "conclud": [83, 89, 91, 101, 112, 137, 158], "ones": [83, 87, 137, 151, 152, 155], "adult_census_test": [83, 85], "9769": 83, "manual": [83, 87, 88, 112, 117, 126, 129, 139, 143, 152, 158, 166, 183], "model_nam": [83, 84, 152], "__class__": [83, 84], "__name__": [83, 84], "804": 83, "underli": [83, 84, 87, 97, 111, 117, 143], "wrongli": [83, 88], "held": [83, 94, 115, 119, 124, 153], "642352": 84, "1087": 84, "077721": 84, "665311": 84, "431247": 84, "725748": 84, "7522": 84, "692939": 84, "407": 84, "110175": 84, "423952": 84, "99999": 84, "4356": 84, "span": [84, 134], "assumpt": [84, 87, 91, 103, 128, 142, 162, 163], "address": 84, "pair": [84, 107, 108, 109, 130, 135, 154], "solver": [84, 134, 148], "descent": [84, 107, 148], "scaler": [84, 93, 152, 157, 180, 182, 186], "standardscalerstandardscal": [84, 88, 93, 133, 142], "wherea": [84, 119, 132, 136, 137, 148, 150, 157], "fashion": [84, 164], "mean_": 84, "64235211": 84, "07772106": 84, "6653108": 84, "43124676": 84, "scale_": 84, "72556083": 84, "59025606": 84, "10461772": 84, "42378265": 84, "data_train_sc": 84, "17177061": 84, "14450843": 84, "71188483": 84, "28845333": 84, "02605707": 84, "22025127": 84, "27618374": 84, "33822677": 84, "77019645": 84, "77536738": 84, "03471139": 84, "53605445": 84, "48319243": 84, "69090725": 84, "perspect": [84, 90, 92, 105], "predefin": 84, "shorthand": 84, "preserv": [84, 102, 142, 151], "set_output": [84, 87, 131, 134, 136], "behaviour": [84, 103, 119, 128], "663100e": 84, "273364e": 84, "530310e": 84, "840667e": 84, "844684e": 84, "000014e": 84, "576792e": 84, "445084e": 84, "202513e": 84, "173852e": 84, "753674e": 84, "471139e": 84, "196565e": 84, "817680e": 84, "677425e": 84, "741752e": 84, "314865e": 84, "047970e": 84, "714245e": 84, "jointplot": 84, "clearer": 84, "num_points_to_plot": 84, "marginal_kw": 84, "dict": [84, 133, 152], "suptitl": [84, 133, 143, 146, 164], "nbefor": 84, "nafter": 84, "x27": [84, 88, 93, 99, 111, 133, 134, 139, 142, 151, 153, 155], "pipelinepipelin": [84, 88, 93, 133, 134, 139, 142, 151, 153, 155], "named_step": 84, "decision_funct": 84, "elapsed_tim": [84, 90, 92], "predicted_target": 84, "n_iter_": [84, 125], "093": 84, "174": 84, "scenario": [84, 88, 134, 141, 146], "kneighborsclassifierkneighborsclassifi": 85, "first_data_valu": 85, "first_predict": 85, "first_target_valu": 85, "number_of_correct_predict": 85, "number_of_predict": 85, "len": [85, 104, 110, 111, 118, 119, 133, 164], "8290379545978042": 85, "8177909714402702": 85, "data_numeric_train": 86, "data_numeric_test": 86, "class_to_predict": 86, "high_revenue_clf": 86, "234": 86, "low_revenue_clf": 86, "766": 86, "7607182343065395": 86, "appear": [86, 112], "most_freq_revenue_clf": 86, "frequent": [86, 91, 96, 101, 106, 155, 175], "reassur": [86, 124, 153], "arithmet": 87, "instruct": 87, "taken": [87, 110, 121, 140], "symbol": [87, 103], "sort_index": 87, "857": [87, 156], "cambodia": 87, "canada": 87, "182": 87, "china": 87, "122": [87, 104, 109, 110], "columbia": 87, "85": [87, 93, 104, 109, 110, 180], "cuba": 87, "138": 87, "dominican": 87, "republ": 87, "103": [87, 107, 148, 155, 158], "ecuador": 87, "el": 87, "salvador": 87, "155": [87, 155], "england": 87, "franc": 87, "germani": 87, "206": [87, 163], "greec": 87, "guatemala": 87, "haiti": 87, "holand": 87, "netherland": 87, "hondura": 87, "hong": 87, "hungari": 87, "india": 87, "iran": 87, "ireland": 87, "itali": 87, "105": [87, 107], "jamaica": 87, "106": [87, 107], "japan": 87, "lao": 87, "mexico": 87, "951": 87, "nicaragua": 87, "outli": 87, "guam": 87, "usvi": 87, "peru": 87, "philippin": 87, "295": 87, "poland": 87, "portug": 87, "67": [87, 106, 107, 110], "puerto": 87, "rico": 87, "184": [87, 144, 147], "scotland": 87, "south": [87, 110], "115": [87, 104], "taiwan": 87, "thailand": 87, "trinadad": 87, "tobago": 87, "43832": 87, "vietnam": 87, "86": [87, 93, 104, 109, 110, 154], "yugoslavia": 87, "recogn": [87, 97], "categorical_columns_selector": [87, 88, 89, 90, 91, 92, 151, 153, 155], "dtype_includ": [87, 88, 89, 90, 91, 92, 121, 149, 151, 153, 155, 156], "unwant": [87, 109], "data_categor": [87, 89, 91], "education_column": 87, "education_encod": 87, "map": [87, 91, 133, 134, 137, 141, 157], "categories_": 87, "data_encod": 87, "downstream": [87, 136], "lexicograph": 87, "meaningless": [87, 112, 163], "l": [87, 97], "xl": 87, "alphabet": 87, "constructor": 87, "explicitli": [87, 144, 147, 155, 157], "mislead": [87, 92, 110], "altern": [87, 131, 136, 139, 141, 155, 162], "sparse_output": [87, 90, 92], "education_": 87, "spars": [87, 90, 92, 104, 109], "effici": [87, 111, 118, 121, 134, 139], "won": [87, 110], "becam": 87, "workclass_": 87, "feder": 87, "emp": 87, "inc": 87, "country_": 87, "amp": 87, "102": [87, 107], "violat": [87, 103], "realli": [87, 97, 103, 105, 107, 111, 137, 143], "misord": 87, "misus": 87, "ineffici": 87, "integr": [87, 118, 134], "abl": [87, 88, 100, 107, 112, 113, 117, 118, 121, 122, 142, 143, 144, 147, 154, 158, 161, 163, 165, 172, 183, 186], "bypass": 87, "keyword": 87, "min_frequ": 87, "collaps": 87, "rarest": 87, "enabl": [87, 186], "infrequent_if_exist": 87, "sandbox": [87, 180], "use_encoded_valu": [87, 88, 89, 90, 91, 92, 121, 149, 151, 153, 155, 156], "unknown_valu": [87, 88, 89, 90, 91, 92, 121, 149, 151, 153, 155, 156], "silenc": 87, "convergencewarn": 87, "87112451": 87, "77881455": 87, "79158235": 87, "78124523": 87, "78233767": 87, "03798509": 87, "03630471": 87, "03779101": 87, "03987718": 87, "03801203": 87, "83222438": 87, "83560242": 87, "82872645": 87, "83312858": 87, "83466421": 87, "833": [87, 91], "002": [87, 90, 91, 92, 152], "decoupl": [88, 143], "numerical_columns_selector": [88, 90, 92], "dtype_exclud": [88, 90, 92], "properli": [88, 99, 107, 115, 124, 142, 162], "format": [88, 103, 107, 135, 140], "elaps": [88, 127], "introspect": [88, 186], "send": 88, "columntransfom": 88, "categorical_preprocessor": [88, 90, 92, 149, 151, 153, 155, 156], "numerical_preprocessor": 88, "associ": [88, 97, 107, 109, 134, 143, 146, 151], "standard_scal": 88, "concaten": [88, 96, 97, 101, 102, 133, 139, 142, 153, 162], "columntransformercolumntransform": [88, 93, 151, 153, 155], "onehotencoderonehotencod": [88, 93], "prefer": 88, "raw": [88, 134, 137, 146, 186], "7762": 88, "56": [88, 106, 107, 122, 124, 147], "divorc": 88, "unmarri": 88, "23881": 88, "transport": 88, "30507": 88, "specialti": 88, "14344": 88, "28911": 88, "19484": 88, "wife": 88, "8575055278028008": 88, "usabl": 88, "0058949": 88, "03596926": 88, "93540072": 88, "00388241": 88, "9987452": 88, "04645991": 88, "04427958": 88, "04497743": 88, "04708195": 88, "04461789": 88, "8512642": 88, "8498311": 88, "84756347": 88, "8523751": 88, "85524161": 88, "851": [88, 121], "compound": 88, "isol": [88, 104, 119], "nice": [88, 111, 139], "fast": [88, 92, 117], "passthrough": [88, 90, 92, 121, 149, 151, 153, 155, 156], "977": 88, "8808451396282041": 88, "significantli": [88, 105, 110], "whenev": [88, 107], "popular": [88, 121], "datasci": 88, "practition": 88, "outperform": 88, "assembl": [89, 91, 117, 119], "rais": [89, 91, 111, 112, 121, 123, 144, 147], "warn": [89, 91, 111, 112, 118, 123, 134, 144, 147], "nan": [89, 91, 93, 102, 106, 144, 147], "traceback": [89, 91, 144, 147], "error_scor": [89, 91], "awai": [89, 91, 92, 112, 137, 146, 166], "handi": [89, 91, 104, 107, 144, 147], "empir": [90, 92, 104], "util": [90, 92, 93, 101, 106, 144, 147], "874": [90, 92], "131": 90, "detriment": [90, 92, 119, 121, 134], "dens": [90, 92], "workaround": [90, 92], "755": 91, "rel": [91, 96, 101, 104, 120, 128, 139, 143, 146], "anyth": [91, 103, 126, 129, 143], "constantli": [91, 96, 101], "761": 91, "messag": [91, 92], "873": 92, "194": 92, "217": 92, "signific": [92, 110, 119, 127, 133, 134, 153], "useless": [92, 124], "580": 92, "view": [92, 153], "longer": [92, 134, 137, 140, 152, 159, 164], "current": [92, 124, 178], "incomplet": 92, "unnecessari": [92, 115, 124], "unless": 92, "reproduc": [93, 107, 153], "script": 93, "event": 93, "rerecord": 93, "ui": 93, "releas": 93, "house_pric": [93, 106, 145, 146, 148], "na_valu": [93, 106], "id": [93, 97, 106], "mssubclass": [93, 106], "mszone": [93, 106], "street": [93, 106], "allei": [93, 106], "lotshap": [93, 106], "landcontour": [93, 106], "poolqc": [93, 106], "fenc": [93, 106], "miscfeatur": [93, 106], "mosold": [93, 106], "yrsold": [93, 106, 134], "saletyp": [93, 106], "salecondit": [93, 106], "rl": [93, 106], "8450": [93, 106], "pave": [93, 106], "reg": [93, 106, 110], "lvl": [93, 106], "allpub": [93, 106], "2008": [93, 106], "wd": [93, 106], "9600": [93, 106], "2007": [93, 106], "11250": [93, 106], "ir1": [93, 106], "9550": [93, 106], "2006": [93, 106], "abnorml": [93, 106], "14260": [93, 106], "1455": 93, "1456": 93, "62": [93, 106], "7917": 93, "1457": 93, "13175": 93, "mnprv": [93, 106], "2010": 93, "1458": 93, "66": [93, 106, 107, 155], "9042": 93, "gdprv": 93, "shed": [93, 106], "2500": 93, "1459": [93, 106], "9717": 93, "1460": [93, 106], "9937": 93, "cherri": 93, "retain": [93, 134], "numeric_featur": 93, "fullbath": [93, 106], "halfbath": [93, 106], "neighborhood": [93, 94, 106, 110], "housestyl": [93, 106], "imput": [93, 106], "simpleimput": [93, 106], "numeric_transform": 93, "categorical_transform": 93, "join": 93, "simpleimputersimpleimput": 93, "859": [93, 156], "018": [93, 118], "dollar": [93, 94, 104, 109, 134], "necessarili": [93, 104, 105, 120, 133, 134, 148, 151, 183], "richer": [93, 139], "level": [93, 99, 101, 119, 121, 126, 127, 129, 133, 137, 143, 160, 161, 162, 164, 165, 178], "coars": 93, "dummyregressor": [94, 146], "overview": [94, 95, 98, 100, 104, 105, 109, 111, 113, 114, 115, 118, 120, 121, 122, 123, 124, 130, 131, 132, 134, 135, 136, 137, 138, 139, 140, 141, 143, 144, 145, 146, 147, 148, 158, 160, 161, 162, 163, 164, 165, 166], "fetch_california_h": [94, 98, 104, 105, 109, 110, 113, 115, 116, 117, 118, 119, 120, 122, 124, 125, 150, 157], "return_x_i": [94, 99, 102, 110, 113, 115, 116, 117, 118, 119, 120, 122, 124, 125, 150, 157, 180], "as_fram": [94, 98, 102, 104, 105, 109, 110, 113, 115, 116, 117, 118, 119, 120, 122, 124, 125, 150, 157], "rescal": [94, 98, 105, 113, 115, 116, 117, 118, 119, 120, 122, 124, 125, 134, 146, 150, 152, 157], "splitter": 94, "cv_results_tree_regressor": 94, "n_job": [94, 97, 98, 99, 100, 101, 103, 105, 109, 110, 117, 118, 119, 120, 121, 122, 124, 125, 127, 129, 134, 136, 151, 153, 155, 157], "errors_tree_regressor": 94, "774882": 94, "137125": 94, "533398": 94, "841918": 94, "033639": 94, "512544": 94, "47": [94, 104, 106, 155], "969062": 94, "result_dummi": 94, "errors_dummy_regressor": 94, "91": [94, 106], "140009": 94, "821140": 94, "757566": 94, "543652": 94, "034555": 94, "979007": 94, "477244": 94, "all_error": 94, "concat": [94, 101, 102, 110, 125, 127, 128, 137], "170466": 94, "713153": 94, "605570": 94, "539353": 94, "483618": 94, "941912": 94, "982259": 94, "213912": 94, "692293": 94, "015862": 94, "422448": 94, "542490": 94, "893328": 94, "130930": 94, "732185": 94, "947952": 94, "793400": 94, "991373": 94, "416833": 94, "023571": 94, "020024": 94, "556965": 94, "047253": 94, "539567": 94, "987471": 94, "185225": 94, "910118": 94, "298971": 94, "738824": 94, "084639": 94, "252201": 94, "984471": 94, "060866": 94, "981744": 94, "731943": 94, "547140": 94, "962591": 94, "820219": 94, "768721": 94, "092553": 94, "305556": 94, "604933": 94, "503017": 94, "544447": 94, "147974": 94, "352055": 94, "386320": 94, "121120": 94, "815660": 94, "307338": 94, "216574": 94, "138339": 94, "107460": 94, "548585": 94, "620318": 94, "29": [94, 106, 110, 118, 127, 139], "165331": 94, "linspac": [94, 98, 100, 101, 112, 117, 123, 130, 135, 138, 140, 154, 164], "edgecolor": [94, 97, 101, 104, 105, 106, 107, 108, 109, 133, 154, 164], "legend": [94, 97, 101, 102, 103, 107, 109, 111, 112, 117, 123, 135, 137, 141, 143, 154, 158, 162, 163, 164, 165], "bbox_to_anchor": [94, 97, 101, 102, 103, 107, 109, 111, 112, 117, 123, 135, 137, 143, 154, 158, 162, 164], "loc": [94, 97, 101, 102, 103, 107, 109, 111, 112, 117, 123, 132, 135, 137, 141, 143, 154, 158, 162, 164], "upper": [94, 97, 101, 102, 103, 107, 109, 110, 112, 117, 123, 137, 143, 158, 162, 164], "xlabel": [94, 97, 99, 100, 101, 102, 104, 105, 106, 107, 108, 110, 124, 125, 127, 128, 133, 134, 136, 141, 143], "Such": [94, 134], "extrem": [94, 99, 108, 109, 126, 129, 133, 134], "gamma": [95, 99, 100, 133, 137, 142], "svm": [95, 99, 100, 139, 142], "form": [95, 97, 99, 100, 110, 130, 131, 135, 136, 138, 140, 146, 152], "accomplish": [95, 100], "rbf": [95, 100, 133, 137, 142], "svc": [95, 99, 100, 142], "scheme": [95, 100, 103, 111, 163], "validationcurvedisplai": [95, 100, 105, 124, 131, 136], "10e": [95, 100], "10e2": [95, 100], "logarithm": [95, 100], "svc__gamma": [95, 100], "retriev": [95, 100, 104, 110, 134], "learningcurvedisplai": [95, 98, 100], "half": [96, 101, 142, 143], "uniform": [96, 101, 109, 112, 133, 155], "handwritten": 97, "digit": 97, "load_digit": 97, "recreat": 97, "minmaxscal": [97, 112, 134, 186], "kfold": [97, 99, 102, 125, 145, 148, 153], "test_score_no_shuffl": 97, "931": 97, "026": 97, "test_score_with_shuffl": 97, "966": 97, "010": [97, 156], "all_scor": [97, 99], "xlim": [97, 110, 117, 143], "impos": [97, 119, 155], "94166667": 97, "89722222": 97, "94986072": 97, "9637883": 97, "90250696": 97, "ship": 97, "descr": [97, 104, 109], "_digits_dataset": 97, "optic": 97, "recognit": 97, "characterist": [97, 104, 109, 143], "1797": 97, "64": [97, 106, 107, 147, 155], "8x8": 97, "pixel": 97, "creator": 97, "alpaydin": 97, "boun": 97, "edu": 97, "tr": 97, "juli": 97, "1998": 97, "copi": [97, 104, 107, 110, 130, 135, 180], "uci": 97, "ic": 97, "nist": 97, "bitmap": 97, "preprint": 97, "32x32": 97, "nonoverlap": 97, "block": [97, 103, 104, 109, 110, 118], "4x4": 97, "invari": [97, 133], "distort": 97, "garri": 97, "j": 97, "candela": 97, "dimmick": 97, "geist": 97, "grother": 97, "janet": 97, "wilson": 97, "handprint": 97, "nistir": 97, "5469": 97, "kaynak": 97, "1995": 97, "Their": [97, 141], "msc": 97, "thesi": 97, "institut": 97, "graduat": 97, "bogazici": 97, "univers": 97, "cascad": 97, "kybernetika": 97, "ken": 97, "tang": 97, "ponnuthurai": 97, "n": [97, 99, 100, 109, 112, 118, 122, 125, 130, 134, 135, 137, 141, 143, 152, 153, 156, 158], "suganthan": 97, "xi": 97, "yao": 97, "kai": 97, "qin": 97, "dimensionalityreduct": 97, "lda": 97, "electr": [97, 106], "electron": 97, "nanyang": 97, "2005": 97, "claudio": 97, "gentil": 97, "nip": 97, "2000": 97, "writer": 97, "wrote": 97, "certain": [97, 125], "130": [97, 118], "hypothesi": [97, 103, 134], "itertool": [97, 106], "bound": [97, 143, 146], "writer_boundari": 97, "256": [97, 118, 119, 155], "386": 97, "516": 97, "646": 97, "776": 97, "915": [97, 117], "1029": 97, "1157": 97, "1287": 97, "1415": 97, "1545": 97, "1667": 97, "zeros_lik": [97, 111], "lower_bound": 97, "upper_bound": 97, "group_id": 97, "lb": 97, "zip": [97, 107, 117, 130, 133, 135], "ytick": [97, 102], "xtick": 97, "ylabel": [97, 102, 103, 105, 124, 125, 133, 134, 136, 141, 143, 158], "groupkfold": 97, "928": 97, "014": [97, 99, 118], "realiti": 97, "synthet": [98, 112, 117, 127, 133, 143, 161, 162, 163, 165], "train_siz": [98, 100, 149, 156], "endpoint": 98, "325": [98, 107], "775": 98, "displai": [98, 114, 123, 141, 143, 154, 180], "from_estim": [98, 100, 105, 111, 124, 132, 133, 136, 137, 141, 142, 143, 158, 162, 164], "score_typ": [98, 100], "negate_scor": [98, 105, 124, 136], "neg_": [98, 104, 131, 136, 148], "score_nam": [98, 100], "std_display_styl": [98, 100, 105, 124, 136], "errorbar": [98, 100, 105, 124, 134, 136], "ax_": [98, 100, 105, 124, 136, 137, 143], "xscale": [98, 134], "log": [98, 134, 146, 154, 155], "alon": [98, 133], "anymor": [98, 101, 103, 104, 119, 142], "bay": 98, "especi": [98, 134], "report": [98, 99, 104], "problemat": [99, 134, 155], "underestim": 99, "philosoph": 99, "breast": 99, "cancer": 99, "load_breast_canc": 99, "param_grid": [99, 120, 122, 151, 153, 162, 180, 186], "model_to_tun": 99, "gridsearchcvgridsearchcv": [99, 151, 153], "svcsvc": [99, 142], "best_params_": [99, 125, 150, 151, 153, 155, 157, 162, 180, 186], "best_score_": 99, "627": 99, "stage": [99, 102, 118, 126, 127, 129, 139, 143, 164], "misinterpret": 99, "forget": 99, "pitfal": 99, "emb": [99, 153], "dedic": [99, 146], "declar": 99, "inner_cv": 99, "outer_cv": 99, "trial": 99, "test_score_not_nest": 99, "test_score_nest": 99, "n_trial": 99, "non_nest": 99, "append": [99, 102, 110, 112, 123, 125, 137, 148], "merg": [99, 127], "whisker": [99, 109, 125, 127, 128, 134, 147], "vert": [99, 109, 125, 127, 128, 134, 147], "highest": [99, 111, 126, 127, 129, 143, 146, 154, 155], "lure": 99, "overli": [99, 104], "021278": 100, "003896": 100, "680000": 100, "021131": 100, "003630": 100, "746667": 100, "020016": 100, "003548": 100, "786667": 100, "019274": 100, "003748": 100, "800000": 100, "020104": 100, "003524": 100, "019360": 100, "003528": 100, "019182": 100, "003642": 100, "018040": 100, "003457": 100, "826667": 100, "018451": 100, "003804": 100, "018714": 100, "003438": 100, "733333": 100, "765": 100, "043": 100, "param_nam": [100, 105, 124, 136, 151, 154, 155, 180, 186], "disp": [100, 105, 124, 136, 137, 143], "errorbar_kw": 100, "transpar": 100, "regim": 100, "oscil": 100, "donat": [100, 108, 143, 144, 147], "simplist": 100, "imposs": [100, 142], "cv_results_logistic_regress": 101, "test_score_logistic_regress": 101, "815937": 101, "813849": 101, "815036": 101, "815569": 101, "810982": 101, "814709": 101, "813112": 101, "810327": 101, "812416": 101, "816388": 101, "most_frequent_classifi": 101, "cv_results_most_frequ": 101, "test_score_most_frequ": 101, "760329": 101, "756808": 101, "759142": 101, "760739": 101, "761681": 101, "761885": 101, "757463": 101, "757176": 101, "763114": 101, "all_test_scor": 101, "stratified_dummi": 101, "cv_results_stratifi": 101, "test_score_dummy_stratifi": 101, "uniform_dummi": 101, "cv_results_uniform": 101, "test_score_dummy_uniform": 101, "wrong": [101, 126, 129, 154], "henc": [101, 110, 117, 134, 155], "uniformli": [101, 112, 137], "weakest": 101, "argu": 101, "permutation_test_scor": 101, "permut": [101, 180], "quit": [101, 102, 103, 105, 107, 118, 141], "strongest": 101, "load_iri": [102, 180], "toi": [102, 139, 142], "nine": 102, "data_random": 102, "randn": [102, 112, 117, 126, 129, 139], "train_index": 102, "test_index": 102, "six": 102, "train_cv_count": 102, "test_cv_count": 102, "fold_idx": 102, "train_idx": 102, "test_idx": 102, "enumer": [102, 111, 112, 123, 125, 127, 130, 135, 153], "idx": [102, 127, 164], "953": 102, "009": 102, "frequenc": [102, 108, 143], "stratifiedkfold": [102, 144, 147], "960": 102, "016": 102, "past": [103, 108, 130, 135, 143], "ident": [103, 104, 118, 143, 153], "financi": 103, "quotat": 103, "tot": 103, "xom": 103, "exxon": 103, "cvx": 103, "chevron": 103, "cop": 103, "conocophillip": 103, "vlo": 103, "valero": 103, "template_nam": 103, "quot": 103, "stock": 103, "2f": [103, 104, 119, 122, 124, 130, 134, 135, 137, 138, 139, 140, 143, 151, 155, 158, 164], "94": [103, 111], "surprisingli": [103, 104, 109, 129], "outstand": 103, "eas": [103, 104, 133, 139, 142], "r2_score": 103, "verifi": [103, 115, 124, 139], "doesn": 103, "proper": [103, 109, 139, 153], "to_period": 103, "q": 103, "69": [103, 106, 111], "forecast": 103, "ulterior": 103, "timeseriessplit": 103, "nuniqu": [103, 107, 162, 186], "74": [103, 106], "shelv": 103, "absurd": 103, "intend": [104, 108, 178], "dive": 104, "area": [104, 105, 106, 112, 137, 142, 143, 162], "geograph": [104, 109, 120], "_california_housing_dataset": [104, 109], "20640": [104, 109], "medinc": [104, 109, 110], "houseag": [104, 109, 110], "averoom": [104, 109, 110, 157], "household": [104, 109], "avebedrm": [104, 109, 110], "aveoccup": [104, 109, 110], "member": [104, 109], "latitud": [104, 109, 110], "longitud": [104, 109, 110], "statlib": [104, 109], "dcc": [104, 109], "fc": [104, 109], "pt": [104, 109], "ltorgo": [104, 109], "cal_hous": [104, 109], "district": [104, 109, 110, 120], "hundr": [104, 109, 127], "deriv": [104, 107, 109, 131, 136, 139], "1990": [104, 109], "u": [104, 109], "smallest": [104, 109, 118, 134], "bureau": [104, 109], "600": [104, 109], "resid": [104, 109], "home": [104, 109], "empti": [104, 109], "vacat": [104, 109], "resort": [104, 109], "pace": [104, 109], "kellei": [104, 109], "ronald": [104, 109], "barri": [104, 109], "spatial": [104, 109], "autoregress": [104, 109], "1997": [104, 109], "291": [104, 109], "297": [104, 109], "3252": [104, 109, 110], "984127": [104, 109, 110], "023810": [104, 109, 110], "322": [104, 109, 110, 118], "555556": [104, 109, 110], "3014": [104, 109, 110], "238137": [104, 109, 110], "971880": [104, 109, 110], "2401": [104, 109, 110], "109842": [104, 109, 110], "2574": [104, 109, 110], "288136": [104, 109, 110], "073446": [104, 109, 110], "496": [104, 109, 110, 154, 155], "802260": [104, 109, 110], "6431": [104, 109, 110], "817352": [104, 109, 110], "073059": [104, 109, 110], "558": [104, 109, 110], "547945": [104, 109, 110], "8462": [104, 109, 110], "281853": [104, 109, 110], "081081": [104, 109, 110], "565": [104, 109, 110], "181467": [104, 109, 110], "452": 104, "358": 104, "352": 104, "341": 104, "342": 104, "medhousev": [104, 109, 110], "decisiontreeregressordecisiontreeregressor": [104, 139, 165], "mean_absolute_error": [104, 115, 122, 123, 124, 138, 146], "grown": [104, 115, 119, 124], "leaf": [104, 119, 151, 155, 156, 158, 162, 164, 174, 175], "node": [104, 119, 121, 151, 156, 158, 162, 164, 173, 174, 175], "phenomena": 104, "unstabl": [104, 134], "wouldn": 104, "unlimit": [104, 119], "lucki": 104, "easiest": 104, "variant": 104, "226245": 104, "004727": 104, "909797": 104, "228429": 104, "004796": 104, "421170": 104, "224813": 104, "004612": 104, "411089": 104, "225663": 104, "004545": 104, "319824": 104, "220283": 104, "004752": 104, "607875": 104, "front": 104, "revert": [104, 131, 136], "negat": 104, "test_error": [104, 134], "226878": 104, "004689": 104, "901300": 104, "224951": 104, "004616": 104, "572767": 104, "225966": 104, "004643": 104, "194585": 104, "227141": 104, "004674": 104, "590236": 104, "229660": 104, "004721": 104, "727998": 104, "percentag": [104, 112, 146], "tag": [104, 130, 135], "expert": [104, 139, 142], "25903583": 104, "25394607": 104, "25143719": 104, "2595458": 104, "25119472": 104, "003268": 104, "00340438": 104, "00354171": 104, "00333428": 104, "00355721": 104, "26291527": 104, "41947109": 104, "44492564": 104, "23357874": 104, "40788361": 104, "overal": [104, 115, 119, 120, 124, 134, 137, 143, 162], "fluctuat": [105, 139, 151], "hopefulli": [105, 119, 138], "302": 105, "318": 105, "harm": 105, "matter": [105, 128, 153], "compromis": [105, 143], "dispers": [105, 118], "directori": [106, 107, 108], "charact": 106, "marker": [106, 111, 143, 164], "pars": [106, 107], "lotconfig": 106, "208500": 106, "fr2": 106, "181500": 106, "223500": 106, "corner": [106, 143], "140000": 106, "250000": 106, "nin": 106, "tail": [106, 107, 109, 141], "coupl": [106, 107, 109, 118, 119, 134, 155], "core": [106, 107, 108, 109, 117, 118], "rangeindex": [106, 107, 108, 109], "null": [106, 107, 108, 109, 141], "1201": 106, "landslop": 106, "condition1": 106, "condition2": 106, "bldgtype": 106, "yearremodadd": 106, "roofstyl": 106, "roofmatl": 106, "exterior1st": 106, "exterior2nd": 106, "masvnrtyp": 106, "588": 106, "1452": 106, "exterqu": 106, "extercond": 106, "foundat": 106, "bsmtqual": 106, "1423": 106, "bsmtcond": 106, "bsmtexposur": 106, "1422": 106, "bsmtfintype1": 106, "bsmtfintype2": 106, "heat": 106, "heatingqc": 106, "centralair": 106, "bsmtfullbath": 106, "bsmthalfbath": 106, "kitchenqu": 106, "fireplacequ": 106, "770": 106, "garagetyp": 106, "1379": 106, "garageyrblt": 106, "garagefinish": 106, "garagequ": 106, "garagecond": 106, "paveddr": 106, "72": 106, "281": 106, "901": 106, "kb": [106, 108], "numerical_data": 106, "410": 106, "layout": 106, "subplots_adjust": [106, 107, 109, 110], "hspace": [106, 107, 109], "wspace": [106, 109], "criterion": [106, 110, 158], "swim": 106, "pool": [106, 129], "string_data": 106, "490": 106, "ceil": 106, "zip_longest": 106, "n_string_featur": 106, "nrow": [106, 143, 164], "ncol": [106, 133, 135, 143, 146, 164], "fig": [106, 110, 133, 134, 143, 146, 154, 157, 158, 159, 180], "subplot": [106, 110, 133, 134, 143, 146, 158, 162, 163, 164], "ravel": [106, 107, 135, 141, 164], "barh": [106, 108, 110, 137, 141, 143], "set_titl": [106, 139, 140, 143, 164], "databas": [106, 157], "grvl": 106, "gd": 106, "make_column_transform": [106, 121], "most_frequent_imput": 106, "mean_imput": 106, "ames_housing_preprocess": 106, "tolist": [106, 158, 164], "timestamp": 107, "150": [107, 111], "0880": 107, "033870": 107, "161": [107, 118, 158], "336": 107, "0842": 107, "033571": 107, "163": 107, "409": 107, "0234": 107, "033223": 107, "156": 107, "445": 107, "0016": 107, "032908": 107, "148": 107, "441": 107, "1144": 107, "38254": 107, "38253": 107, "mb": [107, 109], "str": 107, "datetim": 107, "direct": [107, 133, 137, 155], "reopen": 107, "explan": [107, 159], "soup": 107, "blender": 107, "blend": [107, 133], "veget": 107, "instantan": 107, "profession": 107, "calibr": 107, "track": 107, "spent": [107, 127], "food": 107, "uranium": 107, "petrol": 107, "ga": 107, "coal": 107, "plant": 107, "400": 107, "cheaper": [107, 110], "w": [107, 146, 164], "deliv": 107, "breakout": 107, "kilomet": 107, "costli": [107, 137, 150, 151, 157], "cruis": 107, "datetime64": 107, "ns": 107, "freq": 107, "august": 107, "septemb": 107, "date_first_rid": 107, "cycling_rid": 107, "data_rid": 107, "target_rid": 107, "tempor": 107, "resolut": [107, 155], "smoother": [107, 112], "set_xlabel": [107, 146, 164], "extremum": 107, "rng": [107, 109, 110, 112, 117, 129, 139], "randomst": [107, 109, 110, 112, 117, 129, 133, 139], "arang": [107, 109, 110, 112, 162, 163, 165], "quantiz": [107, 109], "midpoint": [107, 109], "interv": [107, 109, 112, 114, 117, 123, 161, 163, 165], "qcut": [107, 109], "retbin": [107, 109], "lambda": [107, 109, 154, 180], "mid": [107, 109], "palett": [107, 109, 111, 137, 141, 142, 158, 162, 164], "viridi": [107, 109, 154, 164, 180], "uphil": 107, "physiolog": 107, "stimuli": 107, "recenc": [108, 143], "monetari": [108, 143], "12500": 108, "98": [108, 110, 158], "3250": [108, 140], "4000": 108, "6000": 108, "748": 108, "747": 108, "noth": [108, 112], "shock": 108, "her": 108, "762032": 108, "237968": 108, "strike": 108, "fetch": 109, "internet": 109, "california_h": 109, "526": 109, "585": 109, "521": [109, 143], "413": [109, 155], "422": [109, 143], "demographi": 109, "granular": [109, 143], "20639": 109, "640": [109, 158], "unnotic": 109, "features_of_interest": [109, 134], "429000": 109, "096675": 109, "070655": 109, "1425": 109, "476744": 109, "474173": 109, "473911": 109, "386050": 109, "1132": 109, "462122": 109, "846154": 109, "333333": 109, "692308": 109, "440716": 109, "006079": 109, "429741": 109, "787": [109, 152], "229129": 109, "048780": 109, "818116": 109, "1166": 109, "052381": 109, "099526": 109, "282261": 109, "1725": 109, "141": 109, "909091": 109, "066667": 109, "1243": 109, "35682": 109, "huge": 109, "datapoint": [109, 137], "coast": 109, "big": [109, 146], "citi": [109, 146], "san": 109, "diego": 109, "lo": 109, "angel": 109, "jose": 109, "francisco": 109, "columns_drop": 109, "distinguish": 109, "curiou": [109, 142, 186], "553": [109, 143], "062": 109, "coef": [109, 110, 134, 137, 141], "est": [109, 134], "spot": [109, 134], "10000": 110, "100k": 110, "assert": [110, 119, 186], "un": [110, 134], "bin_var": 110, "randint": [110, 122, 126, 129], "rnd_bin": 110, "num_var": 110, "rnd_num": 110, "x_with_rnd_feat": 110, "x_train": 110, "x_test": 110, "y_train": [110, 175], "y_test": 110, "train_dataset": 110, "insert": [110, 137], "kde": 110, "scatter_kw": 110, "x_i": 110, "versu": [110, 146, 166], "6013466090490024": 110, "5975757793803438": 110, "Its": 110, "somehow": 110, "rest": [110, 139, 164], "worth": 110, "habit": 110, "nb": 110, "outcom": [110, 141, 143, 157], "shall": [110, 112], "rise": 110, "80k": 110, "gaug": 110, "decad": 110, "visibl": [110, 146], "dev": 110, "6013157556102924": 110, "5972410717953726": 110, "safe": 110, "perturb": 110, "repeatedkfold": 110, "cv_model": 110, "n_repeat": [110, 127, 128], "boxplot": 110, "cyan": 110, "satur": 110, "pretti": 110, "l1": 110, "015": 110, "5899811014945939": 110, "5769786920519312": 110, "partli": 110, "multivari": 110, "instabl": 110, "teas": 110, "9796463093530234": 110, "8467693464367002": 110, "formal": 110, "brought": 110, "argsort": [110, 127], "set_ytick": 110, "set_yticklabel": 110, "9798863545214676": 110, "8465346522200555": 110, "def": [110, 112, 117, 130, 133, 135, 137, 139, 140, 151, 154, 155, 162, 180], "get_score_after_permut": 110, "curr_feat": 110, "x_permut": 110, "col_idx": 110, "permuted_scor": 110, "get_feature_import": 110, "baseline_score_train": 110, "permuted_score_train": 110, "feature_import": 110, "661": [110, 123], "list_feature_import": 110, "n_round": 110, "00879": 110, "heavili": 110, "permutation_import": 110, "calcul": [110, 111, 143], "importances_mean": 110, "importances_std": 110, "plot_feature_import": 110, "perm_importance_result": 110, "feat_nam": 110, "xerr": 110, "perm_importance_result_train": 110, "realist": [110, 141], "unclear": 110, "culmen_column": [111, 132, 137, 141, 158, 159, 160, 164], "purposefulli": 111, "unlik": [111, 115, 124, 158], "misclassifi": [111, 133, 137], "decisiontreeclassifi": [111, 121, 144, 147, 158, 162, 164], "tab": [111, 112, 117, 133, 137, 141, 142, 143, 158, 162, 163, 164], "decisiontreeclassifierdecisiontreeclassifi": [111, 158, 164], "misclassified_samples_idx": 111, "flatnonzero": 111, "data_misclassifi": 111, "decisionboundarydisplai": [111, 132, 133, 137, 141, 142, 158, 160, 162, 164], "response_method": [111, 133, 137, 141, 142, 158, 162, 164], "cmap": [111, 133, 137, 141, 142, 151, 158, 162, 164], "rdbu": [111, 133, 142, 162], "center": [111, 133, 135, 154, 157, 162], "nwith": [111, 117], "misclassif": [111, 137, 143], "sample_weight": 111, "trick": [111, 142], "drastic": 111, "qualit": [111, 112, 130, 135, 164], "newly_misclassified_samples_idx": 111, "remaining_misclassified_samples_idx": 111, "intersect1d": 111, "ensemble_weight": 111, "935672514619883": 111, "6929824561403509": 111, "adaboostclassifi": 111, "samm": 111, "adaboostclassifieradaboostclassifi": 111, "boosting_round": 111, "estimators_": [111, 112, 114, 123], "to_numpi": [111, 112, 123, 143], "640x480": 111, "estimator_weights_": 111, "58351894": 111, "46901998": 111, "03303773": 111, "estimator_errors_": 111, "05263158": 111, "05864198": 111, "08787269": 111, "sens": [111, 165], "generate_data": [112, 117], "x_min": [112, 117], "x_max": [112, 117], "capabl": [112, 117, 134, 143, 161, 163, 165], "y_pred": [112, 144, 146, 147], "data_bootstrap": 112, "target_bootstrap": 112, "bootstrap_sampl": 112, "bootstrap_indic": 112, "n_bootstrap": 112, "bootstrap_idx": 112, "facecolor": 112, "180": [112, 140], "linewidth": [112, 133, 137, 162], "darker": [112, 137, 141], "data_train_hug": 112, "data_test_hug": 112, "target_train_hug": 112, "100_000": 112, "data_bootstrap_sampl": 112, "target_bootstrap_sampl": 112, "ratio_unique_sampl": 112, "bag_of_tre": 112, "tree_idx": [112, 123], "tree_predict": [112, 123], "feed": 112, "bag_predict": 112, "unbroken": [112, 117], "whole": [112, 114, 119, 121, 123, 134, 139], "meta": 112, "wrap": [112, 134, 137, 166], "snippet": [112, 180], "smooth": [112, 133, 137, 142], "bagged_tre": [112, 121], "bagged_trees_predict": 112, "els": [112, 139, 162], "opac": 112, "appreci": 112, "space": [112, 114, 116, 117, 123, 125, 129, 131, 133, 134, 136, 137, 141, 158, 163, 164], "polynomialfeatur": [112, 131, 133, 134, 136, 139], "polynomial_regressor": 112, "1e": [112, 118, 137, 152, 155], "intention": 112, "simpli": [112, 164], "regressor_predict": 112, "base_model_lin": 112, "bagging_predict": 112, "ylim": [112, 143], "shade": 112, "randomizedsearchcv": [113, 119, 122, 150, 155, 157, 180], "penguins_regress": [114, 123, 130, 135, 138, 140, 159, 161, 162, 163, 165], "evenli": [114, 123], "170": [114, 123], "230": [114, 123], "newli": [114, 123], "conduct": [115, 124, 157], "learning_r": [115, 116, 119, 124, 125, 149, 151, 154, 155, 156, 180, 182], "slower": [115, 124, 136, 153], "offer": [115, 124, 155], "certainli": [115, 124], "n_iter_no_chang": [115, 124], "max_leaf_nod": [116, 119, 125, 149, 151, 153, 154, 155, 156, 162, 180, 182], "residu": [117, 119, 146, 155], "back": [117, 141, 143, 154, 158], "len_x": 117, "rand": [117, 139], "target_train_predict": 117, "target_test_predict": 117, "line_predict": 117, "lines_residu": 117, "edit": 117, "initi": [117, 153, 183], "tree_residu": 117, "target_train_predicted_residu": 117, "target_test_predicted_residu": 117, "manag": 117, "x_sampl": 117, "target_tru": 117, "target_true_residu": 117, "commit": [117, 146], "y_pred_first_tre": 117, "517": 117, "393": 117, "145": 117, "248": [117, 118], "y_pred_first_and_second_tre": 117, "gradientboostingregressor": [117, 118, 124], "gradient_boost": [117, 118], "cv_results_gbdt": [117, 118], "416": 117, "144": [117, 155], "012": 117, "random_forest": [117, 121], "cv_results_rf": 117, "465": 117, "315": 117, "032": 117, "197": 117, "brute": [118, 138], "overcom": [118, 120, 133, 139], "benchmark": 118, "392": 118, "914": 118, "042": 118, "011": 118, "kbinsdiscret": [118, 133, 139], "n_bin": [118, 133, 139], "quantil": [118, 133, 142], "data_tran": 118, "opt": [118, 134, 144, 147], "hostedtoolcach": [118, 134, 144, 147], "x64": [118, 134, 144, 147], "lib": [118, 134, 144, 147], "python3": [118, 134, 144, 147], "site": [118, 134, 144, 147], "_discret": 118, "py": [118, 134, 144, 147], "userwarn": [118, 144, 147], "249": 118, "231": 118, "162": 118, "203": 118, "242": 118, "125": 118, "160": 118, "126": 118, "136": [118, 144, 147], "199": 118, "col": 118, "253": [118, 156], "207": 118, "235": [118, 123, 165], "773": 118, "273": 118, "histogram_gradient_boost": 118, "cv_results_hgbdt": 118, "758": 118, "694": 118, "862": 118, "077": 118, "clariti": 119, "doubl": [119, 151, 152], "max_featur": [119, 121, 122], "grow": [119, 120, 162, 180], "uncorrel": 119, "symmetr": [119, 134, 146, 162], "constraint": [119, 134, 162], "min_samples_leaf": [119, 120, 154, 155, 162, 180], "branch": [119, 162], "promot": 119, "altogeth": 119, "param_distribut": [119, 155, 157], "search_cv": 119, "n_iter": [119, 122, 150, 155, 157, 180], "param_": [119, 122, 125, 151, 155], "mean_test_error": [119, 122], "std_test_error": [119, 122], "cv_results_": [119, 122, 125, 151, 153, 155, 157, 180], "mean_test_scor": [119, 122, 125, 151, 153, 154, 155, 157, 180], "std_test_scor": [119, 122, 151, 153, 154, 155], "sort_valu": [119, 122, 151, 155, 157], "param_max_featur": [119, 122], "param_max_leaf_nod": 119, "param_min_samples_leaf": 119, "996708": 119, "575388": 119, "013965": 119, "522837": 119, "290532": 119, "320069": 119, "169996": 119, "486971": 119, "425679": 119, "597833": 119, "856788": 119, "543134": 119, "927604": 119, "800344": 119, "100456": 119, "635957": 119, "515785": 119, "833755": 119, "640989": 119, "856759": 119, "role": 119, "inter": 119, "refit": [119, 149, 153, 156], "overlook": 119, "stat": [119, 122, 155], "loguniform": [119, 155], "param_max_it": 119, "param_learning_r": 119, "01864": 119, "043016": 119, "262257": 119, "047293": 119, "811893": 119, "229961": 119, "176656": 119, "410615": 119, "243557": 119, "297739": 119, "740945": 119, "360870": 119, "083745": 119, "095718": 119, "274735": 119, "215543": 119, "275814": 119, "216063": 119, "067503": 119, "780658": 119, "237595": 119, "05929": 119, "855942": 119, "418406": 119, "160519": 119, "270716": 119, "416068": 119, "125207": 119, "914995": 119, "557058": 119, "054511": 119, "224344": 119, "623883": 119, "248463": 119, "147930": 119, "842348": 119, "906226": 119, "494647": 119, "710124": 119, "061034": 119, "568261": 119, "551379": 119, "079415": 119, "455489": 119, "944949": 119, "0351": 119, "503834": 119, "949876": 119, "019923": 119, "624869": 119, "045625": 119, "039361": 119, "818311": 119, "083471": 119, "019351": 119, "377257": 119, "051528": 119, "01724": 119, "941795": 119, "084528": 119, "rank": [119, 125, 186], "hgbt": 119, "hassl": 120, "354": 120, "087": 120, "min_samples_split": [120, 162], "523": [120, 135], "107": 120, "bagging_regressor": 120, "642": 120, "083": 120, "decent": [120, 154, 155], "modif": 121, "inject": 121, "decorrel": 121, "categorical_encod": 121, "scores_tre": 121, "820": 121, "006": [121, 125], "scores_bagged_tre": 121, "846": 121, "005": 121, "randomforestclassifi": [121, 127, 128], "scores_random_forest": 121, "004": 121, "disabl": 121, "sqrt": 121, "literatur": 121, "agnost": 121, "param": [122, 125, 151, 154], "bootstrap_featur": 122, "estimator__ccp_alpha": 122, "estimator__criterion": 122, "estimator__max_depth": 122, "estimator__max_featur": 122, "estimator__max_leaf_nod": 122, "estimator__min_impurity_decreas": 122, "estimator__min_samples_leaf": 122, "estimator__min_samples_split": 122, "estimator__min_weight_fraction_leaf": 122, "estimator__random_st": 122, "estimator__splitt": 122, "max_sampl": 122, "oob_scor": 122, "verbos": [122, 152, 155, 157, 182], "warm_start": 122, "param_n_estim": 122, "param_max_sampl": 122, "param_estimator__max_depth": 122, "281680": 122, "061146": 122, "475610": 122, "121340": 122, "602077": 122, "070860": 122, "326435": 122, "174542": 122, "956380": 122, "278850": 122, "017761": 122, "674627": 122, "135453": 122, "005112": [122, 154], "224306": 122, "316641": 122, "070459": 122, "053769": 122, "759904": 122, "679971": 122, "334637": 122, "125204": 122, "528335": 122, "972150": 122, "872540": 122, "686614": 122, "949551": 122, "721352": 122, "529438": 122, "429014": 122, "750573": 122, "081410": 122, "841505": 122, "968520": 122, "258303": 122, "351126": 122, "840351": 122, "744600": 122, "889776": 122, "075650": 122, "gram": [123, 131, 136, 138], "366": 123, "data_rang": 123, "forest_predict": 123, "n_estimators_": 124, "243": [124, 148], "hist_gbdt": 125, "839": [125, 144, 147], "best_estimator_": 125, "528": 125, "447": 125, "576": 125, "290": 125, "414": 125, "index_column": 125, "inner_cv_result": 125, "cv_idx": 125, "search_cv_result": 125, "set_index": [125, 132, 137, 141, 148], "renam": [125, 151, 154, 155, 157, 180], "coincid": [125, 143], "bioinformat": [126, 129], "rna": [126, 129], "seq": [126, 129], "ten": [126, 129], "anova": [126, 127, 129], "feature_select": [126, 127, 128, 129], "selectkbest": [126, 127, 129], "f_classif": [126, 127, 129], "pre": [126, 129], "princip": 127, "make_classif": [127, 128], "n_inform": [127, 128], "n_redund": [127, 128], "univari": 127, "model_without_select": [127, 128], "model_with_select": [127, 128], "score_func": [127, 129], "cv_results_without_select": [127, 128], "incorpor": 127, "cv_results_with_select": [127, 128], "analyz": [127, 134, 180], "swap": 127, "swaplevel": [127, 128], "Of": 127, "scores_": 127, "percentil": 127, "alien": 127, "primari": 127, "feature_importances_": 128, "suffici": [128, 133], "class_sep": 128, "selectfrommodel": 128, "feature_selector": [128, 129], "overestim": 128, "100000": 129, "550": 129, "data_subset": 129, "940": 129, "succeed": 129, "legit": 129, "leak": 129, "data_train_subset": 129, "520": 129, "460": 129, "boilerpl": 129, "linear_model_flipper_mass": [130, 135, 140], "flipper_length": [130, 135, 140], "weight_flipper_length": [130, 135, 138, 140], "intercept_body_mass": [130, 135, 138, 140], "body_mass": [130, 135, 140], "flipper_length_rang": [130, 135, 138, 140], "goodness_fit_measur": [130, 135], "true_valu": [130, 135], "scalar": [130, 135], "model_idx": [130, 135], "x1": [131, 136, 141], "x2": [131, 136], "x3": [131, 136], "penguins_non_miss": [131, 136, 186], "181": [131, 136, 140], "186": [131, 136, 140], "195": [131, 136, 140], "193": [131, 136, 140], "190": [131, 136, 140, 155], "sign": [131, 136], "interaction_onli": [131, 136], "intermedi": [131, 136, 139, 153, 154], "infinit": [132, 137], "yourself": [132, 137], "penguins_train": [132, 137, 141], "penguins_test": [132, 137, 141], "candid": [132, 137, 155, 157, 158], "cs": [132, 137], "nevertheless": 133, "moon": [133, 142], "crescent": 133, "make_moon": [133, 142], "newaxi": [133, 142, 162], "data_moon": [133, 142], "target_moon": [133, 142], "gaussian": [133, 142], "edg": 133, "concentr": 133, "make_gaussian_quantil": [133, 142], "n_class": [133, 141, 142, 164], "gauss": [133, 142], "data_gauss": [133, 142], "target_gauss": [133, 142], "xor": 133, "OR": 133, "target_xor": 133, "logical_xor": 133, "int32": [133, 150, 157, 162], "data_xor": 133, "glanc": 133, "listedcolormap": 133, "constrained_layout": 133, "common_scatter_plot_param": 133, "plot_decision_boundari": [133, 137], "plot_method": [133, 137], "pcolormesh": [133, 137], "vmin": [133, 137, 151, 158, 164], "vmax": [133, 137, 151, 158, 164], "middl": [133, 152], "colormap": [133, 137, 141, 164], "contour": [133, 137], "set_ylabel": [133, 146, 164], "soft": [133, 141], "unsur": [133, 141], "attempt": [133, 134, 137], "leverag": 133, "spline": [133, 139], "kbinsdiscretizerkbinsdiscret": [133, 139], "segment": 133, "rectangular": 133, "drawn": 133, "n_knot": 133, "splinetransformersplinetransform": [133, 139], "favor": 133, "curvi": [133, 137], "knot": 133, "include_bia": [133, 134, 136, 139], "polynomialfeaturespolynomialfeatur": [133, 134, 139], "nystr\u00f6m": [133, 136], "kernel_approxim": [133, 136, 137, 139], "coef0": [133, 141], "nystroemnystroem": [133, 139], "expans": [133, 139, 142], "intract": 133, "radial": [133, 142], "basi": [133, 142], "furthemor": 133, "induct": 133, "rotation": 133, "everywher": [133, 137], "drawback": 133, "orign": 133, "despit": 133, "augment": [133, 134, 142], "interplai": 133, "linear_regress": [134, 136, 138, 139, 165], "train_error": 134, "2e": 134, "85e": 134, "63e": 134, "69e": 134, "47e": 134, "fortun": 134, "feature_names_in_": 134, "model_first_fold": 134, "linearregressionlinearregress": [134, 138, 139], "queri": [134, 137], "weights_linear_regress": 134, "symlog": 134, "homogen": 134, "choleski": 134, "_ridg": 134, "linalgwarn": 134, "rcond": 134, "59923e": 134, "linalg": 134, "xy": 134, "assume_a": 134, "po": 134, "overwrite_a": 134, "59556e": 134, "59609e": 134, "11828e": 134, "06109e": 134, "60121e": 134, "61694e": 134, "59735e": 134, "59566e": 134, "72304e": 134, "60047e": 134, "59824e": 134, "59593e": 134, "59564e": 134, "5959e": 134, "59553e": 134, "59686e": 134, "60737e": 134, "5957e": 134, "60243e": 134, "90e": 134, "56e": 134, "55e": 134, "68e": 134, "weights_ridg": 134, "shrunk": 134, "worst": [134, 143], "saga": 134, "lsqr": 134, "re": [134, 178, 186], "resolv": 134, "omit": 134, "annual": 134, "neutral": [134, 164], "ahead": 134, "scaled_ridg": 134, "78e": 134, "21e": 134, "83e": 134, "17e": 134, "sweet": 134, "weights_ridge_scaled_data": 134, "ridge_large_alpha": 134, "1_000_000": 134, "unpredict": 134, "occurr": 134, "presenc": [134, 148], "divis": 134, "beforehand": 134, "store_cv_valu": 134, "12e": 134, "25e": 134, "50e": 134, "40e": 134, "mse_alpha": 134, "cv_values_": 134, "cv_alpha": 134, "000000e": 134, "841881e": 134, "347783e": 134, "321941e": 134, "837563e": 134, "343115e": 134, "747528e": 134, "831866e": 134, "336956e": 134, "310130e": 134, "824352e": 134, "328835e": 134, "053856e": 134, "814452e": 134, "318133e": 134, "274549e": 134, "319038e": 134, "337394e": 134, "328761e": 134, "324503e": 134, "338181e": 134, "722368e": 134, "328652e": 134, "338778e": 134, "564633e": 134, "331799e": 134, "339232e": 134, "334185e": 134, "339576e": 134, "yerr": 134, "yscale": 134, "salt": 134, "cook": 134, "best_alpha": 134, "11497569953977356": 134, "35111917342151344": 134, "1519911082952933": 134, "4641588833612782": 134, "08697490026177834": 134, "6135907273413176": 134, "stem": [134, 146], "summari": 134, "wasn": 134, "disproportion": 134, "15000": 135, "14000": 135, "predicted_body_mass": [135, 138, 140], "misleadingli": 135, "mse": [135, 139, 146, 148], "ab": [135, 139], "2764": 135, "854": 135, "338": 135, "573": 135, "041": 135, "337": 136, "071": 136, "868": 136, "poly_featur": 136, "linear_regression_interact": 136, "7077": 136, "3384": 136, "731": 136, "7347": 136, "3236": 136, "687": 136, "7858": 136, "3510": 136, "725": 136, "7083": 136, "3724": 136, "708": 136, "7467": 136, "3914": 136, "809": 136, "flipper_length_first_sampl": 136, "culmen_depth_first_sampl": 136, "301": 136, "790": 136, "340": 136, "spread": [136, 137, 154, 180], "enrich": 136, "nystroem_regress": [136, 139], "nystroem__n_compon": 136, "set_param": [136, 137, 152, 156, 182, 186], "331": 136, "832": 136, "4950": 136, "5050": 136, "footprint": 136, "scalabl": 136, "metion": 137, "invers": 137, "diverg": [137, 141, 157, 164], "rdbu_r": [137, 141], "1e6": 137, "logisticregression__c": [137, 180, 182], "sigmoid": [137, 141], "dark": 137, "nearli": 137, "steep": 137, "deduc": [137, 159], "lai": 137, "zone": 137, "weaker": 137, "light": 137, "lr_weight": 137, "perpendicular": [137, 158], "lowest": [137, 138, 146], "anywher": 137, "minor": 137, "blob": [137, 162], "frontier": 137, "conjunct": 137, "certainti": [137, 164], "68556640610011": 138, "5780": 138, "831358077066": 138, "mean_squared_error": [138, 139, 146], "inferred_body_mass": 138, "model_error": 138, "154546": 138, "313": 138, "occas": 139, "cubic": [139, 175], "said": [139, 146, 148], "data_max": 139, "data_min": 139, "len_data": 139, "sort": 139, "full_data": 139, "input_featur": 139, "reshap": [139, 146, 164], "fit_score_plot_regress": 139, "global": 139, "data_expand": 139, "polynomial_expans": 139, "polynomial_regress": 139, "encourag": [139, 146], "svr": 139, "svrsvr": 139, "medium": 139, "10_000": [139, 158], "binned_regress": 139, "spline_regress": 139, "expand": 139, "3750": 140, "3800": 140, "3450": 140, "3650": 140, "2700": 140, "6300": 140, "heavier": [140, 159], "formula": 140, "shorter": 140, "13000": 140, "millimet": 140, "body_mass_180": 140, "body_mass_181": 140, "7200": 140, "7240": 140, "goe": [140, 143], "170mm": 140, "230mm": 140, "redefin": 140, "groupbi": 141, "inclin": 141, "x0": 141, "coef1": 141, "obliqu": [141, 158], "724988": 141, "096500": 141, "readi": 141, "barplot": 141, "horizont": [141, 162, 164], "vertic": 141, "coordin": [141, 153, 154, 157, 180], "hypothet": 141, "test_penguin": 141, "y_pred_proba": [141, 158], "17145312": 141, "82854688": 141, "y_proba_sampl": 141, "classes_": [141, 143, 158, 164, 182], "insist": 141, "overconfid": 141, "underconfid": 141, "softer": 141, "asymptot": 141, "softmax": 141, "hold": [142, 146, 154, 157, 180, 186], "interlac": [142, 162], "depict": [142, 159], "push": 142, "surround": 142, "kernel_model": 142, "donor": 143, "ago": 143, "new_donor": 143, "That": [143, 148, 151, 153], "258": 143, "505": 143, "665": 143, "615": 143, "743": 143, "374": 143, "7780748663101604": 143, "accuracy_scor": 143, "778": 143, "finer": 143, "confusionmatrixdisplai": 143, "incorrect": 143, "erron": 143, "tp": 143, "tn": 143, "fn": 143, "fp": 143, "precision_scor": [143, 144, 147], "recall_scor": 143, "pos_label": [143, 144, 147], "688": 143, "124": 143, "mislabel": 143, "ratio": 143, "dummy_classifi": 143, "762": 143, "balanced_accuracy_scor": 143, "haven": 143, "target_proba_predict": 143, "271820": 143, "728180": 143, "451764": 143, "548236": 143, "445211": 143, "554789": 143, "441577": 143, "558423": 143, "870583": 143, "129417": 143, "equivalence_pred_proba": 143, "idxmax": 143, "graph": 143, "precisionrecalldisplai": 143, "tpr": 143, "ppv": 143, "ap": 143, "preval": 143, "discrimin": 143, "roccurvedisplai": 143, "dash": 143, "plot_chance_level": 143, "pr": 143, "chance_level_kw": 143, "ambigu": [144, 147], "valueerror": [144, 147], "exc": [144, 147], "_valid": [144, 147], "recent": [144, 147], "_scorer": [144, 147], "__call__": [144, 147], "scorer": [144, 145, 147, 148], "_score": [144, 147], "355": [144, 147], "_sign": [144, 147], "_score_func": [144, 147], "y_true": [144, 146, 147], "scoring_kwarg": [144, 147], "_param_valid": [144, 147], "211": [144, 147], "wrapper": [144, 147], "arg": [144, 147, 155], "kwarg": [144, 147, 155], "_classif": [144, 147], "2127": [144, 147], "precision_recall_fscore_support": [144, 147], "1721": [144, 147], "_check_set_wise_label": [144, 147], "1507": [144, 147], "catch": [144, 147], "make_scor": [144, 147], "syntax": [145, 148], "iowa": 146, "intro": [146, 166], "996": 146, "902": 146, "2064": 146, "736": 146, "6872520581075487": 146, "dummy_regressor": 146, "608": 146, "disadvantag": 146, "median_absolute_error": 146, "137": 146, "mean_absolute_percentage_error": 146, "574": 146, "obsev": 146, "unobserv": 146, "extern": [146, 153], "cloud": 146, "against": 146, "exhibit": 146, "predictionerrordisplai": 146, "from_predict": 146, "actual_vs_predict": 146, "scatter_kwarg": 146, "residual_vs_predict": 146, "nwithout": 146, "banana": 146, "smile": 146, "clue": 146, "monoton": 146, "quantiletransform": [146, 186], "transformedtargetregressor": 146, "n_quantil": [146, 186], "900": 146, "output_distribut": 146, "model_transformed_target": 146, "ntransform": 146, "406": 146, "327": [146, 155], "disapprov": 146, "statistician": 146, "justifi": 146, "poissonregressor": 146, "tweedieregressor": 146, "reachabl": 146, "623": 147, "507": 147, "108": 147, "255": [147, 155], "166": 147, "00379062": 147, "00376248": 147, "0038867": 147, "00365186": 147, "00371385": 147, "00387788": 147, "00366783": 147, "00371575": 147, "00371671": 147, "00378752": 147, "00309134": 147, "00321937": 147, "00310946": 147, "00320387": 147, "00321031": 147, "00326419": 147, "00317121": 147, "00320053": 147, "00322223": 147, "00360751": 147, "test_accuraci": 147, "29333333": 147, "53333333": 147, "74666667": 147, "65333333": 147, "69333333": 147, "77333333": 147, "63513514": 147, "75675676": 147, "test_balanced_accuraci": 147, "42105263": 147, "48391813": 147, "62426901": 147, "40643275": 147, "48684211": 147, "55116959": 147, "73684211": 147, "45356037": 147, "51186791": 147, "794": 148, "892": 148, "225": 148, "test_r2": 148, "test_neg_mean_absolute_error": 148, "848721": 148, "256799": 148, "816374": 148, "084083": 148, "813513": 148, "113367": 148, "814138": 148, "448279": 148, "637473": 148, "370341": 148, "defaultdict": 148, "loss_funct": 148, "squared_error": 148, "absolute_error": 148, "loss_func": 148, "test_neg_mean_squared_error": 148, "923": 148, "344": [148, 155], "evolv": 148, "discontinu": 148, "surrog": 148, "substitut": 148, "log_loss": 148, "exhaust": [149, 156, 183], "cat_preprocessor": [149, 151, 153, 155, 156], "kneighborsregressor": [150, 157], "with_mean": [150, 157], "with_std": [150, 157], "reload": [151, 155], "dealt": 151, "ordinalencoderordinalencod": [151, 153, 155], "remainderpassthroughpassthroughhistgradientboostingclassifierhistgradientboostingclassifi": [151, 153, 155], "classifier__learning_r": [151, 153, 155, 156], "classifier__max_leaf_nod": [151, 153, 155, 156], "model_grid_search": [151, 153], "charg": 151, "rapidli": 151, "ascend": [151, 155, 157], "mean_fit_tim": [151, 154], "std_fit_tim": [151, 154], "mean_score_tim": [151, 154], "std_score_tim": [151, 154], "param_classifier__learning_r": [151, 153, 154], "param_classifier__max_leaf_nod": [151, 153, 154], "split0_test_scor": [151, 154], "split1_test_scor": [151, 154], "rank_test_scor": [151, 153, 154, 155], "489168": 151, "050132": 151, "224362": 151, "016874": 151, "868912": 151, "867213": 151, "868063": 151, "000850": 151, "370372": 151, "009651": 151, "203127": 151, "004503": 151, "866783": 151, "866066": 151, "866425": 151, "000359": 151, "118699": 151, "000410": 151, "093414": 151, "007336": 151, "classifier__": 151, "858648": 151, "862408": [151, 153, 154], "860528": 151, "001880": 151, "128271": 151, "002882": 151, "099234": 151, "011471": 151, "859358": 151, "859514": 151, "859436": 151, "000078": 151, "132225": 151, "003397": 151, "083718": 151, "000626": 151, "855536": 151, "856129": 151, "855832": 151, "000296": 151, "shorten": 151, "param_classifier__": 151, "prefix": [151, 154], "column_result": [151, 155], "shorten_param": [151, 154, 155, 180], "__": [151, 152, 154, 155, 180], "rsplit": [151, 154, 155, 180], "853266": 151, "000515": 151, "843330": 151, "002917": 151, "817832": 151, "001124": 151, "797166": 151, "000715": 151, "288200": 151, "050539": 151, "283476": 151, "003775": 151, "262564": 151, "006326": 151, "heatmap": [151, 154], "pivoted_cv_result": 151, "pivot_t": 151, "ylgnbu": 151, "invert_yaxi": 151, "degrad": 151, "patholog": 151, "accordingli": 151, "hyperparamt": [151, 158], "recogniz": 152, "spell": 152, "classifier__c": [152, 180, 182], "hyperparameter_nam": 152, "preprocessor__copi": 152, "preprocessor__with_mean": 152, "preprocessor__with_std": 152, "classifier__class_weight": 152, "classifier__du": 152, "classifier__fit_intercept": 152, "classifier__intercept_sc": 152, "classifier__l1_ratio": 152, "classifier__max_it": 152, "classifier__multi_class": 152, "classifier__n_job": 152, "classifier__penalti": 152, "classifier__random_st": 152, "classifier__solv": 152, "classifier__tol": 152, "classifier__verbos": 152, "classifier__warm_start": 152, "001": [152, 155], "799": 152, "523512": 153, "084637": 153, "863241": 153, "519701": 153, "086653": 153, "860784": 153, "521355": 153, "085747": 153, "860360": [153, 154], "517670": 153, "087460": 153, "523147": 153, "086819": 153, "866912": 153, "863": 153, "embed": 153, "864195": 153, "000061": 153, "870910": 153, "869743": 153, "000532": 153, "866058": 153, "001515": 153, "concern": 153, "877": 153, "schemat": 153, "green": [153, 158, 164], "rough": 153, "cv_test_scor": 153, "871": 153, "apprehend": 153, "cv_inner": 153, "cv_outer": 153, "greed": 153, "cv_fold": 153, "estimator_in_fold": 153, "vote": 153, "randomized_search_result": [154, 155, 180], "param_classifier__l2_regular": 154, "param_classifier__max_bin": 154, "param_classifier__min_samples_leaf": 154, "split2_test_scor": 154, "split3_test_scor": 154, "split4_test_scor": 154, "540456": 154, "062725": 154, "052069": 154, "002661": 154, "467047": 154, "550075": 154, "classifier__l2_regular": [154, 155], "4670474863": 154, "856558": 154, "862271": 154, "857767": 154, "854491": 154, "856675": 154, "857552": 154, "002586": 154, "110536": 154, "033403": 154, "074142": 154, "002165": 154, "015449": 154, "001146": 154, "0154488709": 154, "758974": 154, "758941": 154, "758947": [154, 155], "000013": [154, 155], "323": [154, 158], "137484": 154, "053150": 154, "092993": 154, "029005": 154, "095093": 154, "004274": 154, "0950934559": 154, "783267": 154, "776413": 154, "779143": 154, "771341": 154, "010357": 154, "311": 154, "935108": 154, "202993": 154, "118105": 154, "023658": 154, "003621": 154, "001305": 154, "164": 154, "0036210968": 154, "255219": 154, "038301": 154, "056048": 154, "016736": 154, "000081": 154, "407382": 154, "97": [154, 164, 186], "1060737427": 154, "495": 154, "452411": 154, "023006": 154, "055563": 154, "000846": 154, "000075": 154, "364373": 154, "4813767874": 154, "858332": 154, "865001": 154, "862681": 154, "860770": 154, "861429": 154, "002258": 154, "133042": 154, "014456": 154, "078186": 154, "002199": 154, "065946": 154, "001222": 154, "0659455480": 154, "497": [154, 155], "911828": 154, "017167": 154, "076563": 154, "005130": 154, "460025": 154, "044408": 154, "4600250010": 154, "839907": 154, "849713": 154, "846847": 154, "846028": 154, "844390": 154, "845377": 154, "003234": 154, "140": 154, "498": 154, "168120": 154, "121819": 154, "061283": 154, "000760": 154, "000068": 154, "287904": 154, "227": 154, "146": [154, 155], "7755366885": 154, "861881": 154, "859951": 154, "861862": 154, "862221": 154, "001623": 154, "499": [154, 155], "823774": 154, "120686": 154, "060351": 154, "014958": 154, "445218": 154, "4452178932": 154, "764569": 154, "765902": 154, "764947": 154, "765083": 154, "765281": 154, "000535": 154, "319": 154, "l2_regular": [154, 155, 180], "max_bin": [154, 155, 180], "score_bin": 154, "cut": [154, 162], "set_palett": 154, "ylgnbu_r": 154, "set_xscal": 154, "set_yscal": 154, "band": 154, "plotli": [154, 157, 180], "px": [154, 157, 180], "parallel_coordin": [154, 157, 180], "log10": [154, 180], "log2": [154, 180], "color_continuous_scal": [154, 157, 180], "undo": 154, "yellow": [154, 164], "tick": 154, "invert": 154, "consecut": 155, "untract": 155, "situat": 155, "stochast": 155, "loguniform_int": 155, "__init__": 155, "_distribut": 155, "rv": 155, "processor": 155, "1e3": 155, "classifier__min_samples_leaf": 155, "classifier__max_bin": 155, "model_random_search": [155, 157], "histgradientboostingc": 155, "_distn_infrastructur": 155, "rv_continuous_frozen": 155, "0x7fcf3f891a00": 155, "0x7fcf3ebd97f0": 155, "__main__": 155, "0x7fcf3ebe0100": 155, "0x7fcf3ec7dfa0": 155, "0x7fcf3ebd9340": 155, "randomizedsearchcvrandomizedsearchcv": 155, "pprint": 155, "05267903307568315": 155, "10798958387414": 155, "232": 155, "052679": 155, "10799": 155, "870738": 155, "001633": 155, "001174": 155, "02105": 155, "855478": 155, "003486": 155, "000003": 155, "322713": 155, "854741": 155, "003185": 155, "000026": 155, "026509": 155, "853075": 155, "002667": 155, "428258": 155, "272481": 155, "813901": 155, "001062": 155, "906324": 155, "026156": 155, "806448": 155, "001279": 155, "000267": 155, "029741": 155, "183": 155, "799541": 155, "001546": 155, "000007": 155, "00541": 155, "762278": 155, "000332": 155, "000002": 155, "001527": 155, "171": 155, "005833": 155, "001013": 155, "to_csv": 155, "208": 155, "011775": 155, "076653": 155, "871393": 155, "001588": 155, "343": 155, "000404": 155, "244503": 155, "229": 155, "871339": 155, "002741": 155, "994918": 155, "077047": 155, "192": 155, "870793": 155, "001993": 155, "328": 155, "036232": 155, "224702": 155, "236": 155, "869837": 155, "000808": 155, "733808": 155, "036786": 155, "241": 155, "869673": 155, "002417": 155, "000097": 155, "976823": 155, "448205": 155, "253714": 155, "000001": 155, "828574": 155, "091079": 155, "000444": 155, "236325": 155, "344629": 155, "207156": 155, "357": 155, "075318": 155, "241053": 155, "valuabl": 155, "allevi": 155, "best_scor": 156, "best_param": 156, "lr": 156, "mln": 156, "mean_scor": 156, "789": 156, "813": 156, "842": 156, "847": 156, "855": 156, "835": 156, "828": 156, "288": 156, "437": 156, "best_lr": 156, "best_mln": 156, "870": 156, "kneighborsregressor__n_neighbor": 157, "standardscaler__with_mean": 157, "standardscaler__with_std": 157, "welcom": 157, "column_name_map": 157, "param_kneighborsregressor__n_neighbor": 157, "param_standardscaler__with_mean": 157, "param_standardscaler__with_std": 157, "boolean": 157, "column_scal": 157, "687926": 157, "674812": 157, "668778": 157, "648317": 157, "629772": 157, "215": 157, "617295": 157, "464": 157, "567164": 157, "508809": 157, "486503": 157, "103390": 157, "061394": 157, "033122": 157, "017583": 157, "007987": 157, "002900": 157, "238830": 157, "tealros": 157, "kneighbor": 157, "mpl": [158, 164], "tab10_norm": [158, 164], "dbd": 158, "tab10": [158, 164], "norm": [158, 164], "plot_tre": [158, 160, 162, 163, 164], "class_nam": [158, 164], "impur": [158, 164], "inferior": 158, "superior": 158, "settabl": 158, "45mm": 158, "test_penguin_1": 158, "test_penguin_2": 158, "y_proba_class_0": 158, "adelie_proba": 158, "chinstrap_proba": 158, "gentoo_proba": 158, "037": 158, "disregard": 158, "moment": 158, "test_penguin_3": 158, "63975155": 158, "32298137": 158, "03726708": 158, "fairli": 158, "palmer": 159, "anatom": 159, "set_size_inch": 159, "superimpos": [161, 165], "data_clf_column": 162, "target_clf_column": 162, "data_clf": 162, "data_reg_column": 162, "target_reg_column": 162, "data_reg": 162, "fit_and_plot_classif": 162, "fit_and_plot_regress": 162, "tree_clf": 162, "tree_reg": 162, "adequ": 162, "asymmetri": 162, "make_blob": 162, "x_1": 162, "y_1": 162, "x_2": 162, "y_2": 162, "min_impurity_decreas": 162, "asymmetr": 162, "priori": 163, "3698": 163, "5032": 163, "tricki": 164, "spectr": 164, "purpl": 164, "xx": 164, "yy": 164, "meshgrid": 164, "xfull": 164, "proba": 164, "sharei": 164, "class_of_interest": 164, "imshow_handl": 164, "imshow": 164, "extent": 164, "colorbar": 164, "cax": 164, "binar": 164, "impress": 164, "target_predicted_linear_regress": 165, "target_predicted_tre": 165, "interpol": 165, "offset": 165, "175": 165, "shortest": 165, "longest": 165, "m3": [166, 179, 181], "m5": [166, 168, 169, 170, 177], "acknowledg": 166, "prune": 172, "children": 173, "increment": 174, "refin": 174, "author": 178, "circular": 180, "budget": [180, 184], "badli": 180, "histgradientbosstingclassifi": 182, "get_paramet": 182, "anim": 186, "param_valu": 186, "powertransform": 186, "all_preprocessor": 186, "cox": 186, "classifier__n_neighbor": 186, "forgot": 186}, "objects": {}, "objtypes": {}, "objnames": {}, "titleterms": {"acknowledg": 0, "figur": 0, "attribut": [0, 3], "The": [1, 6, 76, 79, 106, 107, 108, 109, 143, 159, 166], "adult": [1, 76], "censu": [1, 76], "dataset": [1, 2, 6, 76, 82, 83, 93, 106, 107, 108, 109, 110, 153, 159], "descript": 2, "glossari": 3, "main": [3, 14, 23, 34, 40, 60, 74, 130, 135, 172, 184], "term": 3, "us": [3, 6, 11, 79, 88, 127, 128, 138, 151, 155], "thi": [3, 6], "cours": [3, 36], "api": 3, "classif": [3, 30, 141, 142, 143, 158, 159, 168], "classifi": [3, 143], "cross": [3, 20, 21, 79, 88, 98, 99, 104], "valid": [3, 6, 20, 21, 61, 69, 79, 88, 98, 99, 104, 105], "data": [3, 6, 65, 67, 70, 76, 79, 82, 83, 84, 87, 88, 103, 130, 135], "matrix": [3, 143], "input": 3, "earli": 3, "stop": 3, "estim": [3, 104, 141, 164], "featur": [3, 32, 41, 84, 87, 90, 92, 110, 127, 128, 133, 134, 137, 139, 166], "variabl": [3, 76, 87, 88, 90, 92, 110], "descriptor": 3, "covari": 3, "gener": [3, 105, 162], "perform": [3, 94, 166], "predict": [3, 6, 83, 87, 141, 143, 151, 153, 155, 164, 166], "statist": 3, "hyperparamet": [3, 12, 119, 121, 151, 152, 153, 154, 155, 162, 166, 169, 185], "infer": 3, "learn": [3, 6, 13, 22, 33, 36, 39, 52, 58, 61, 67, 72, 73, 83, 93, 98, 110, 112, 138, 140, 152, 166, 171, 183], "paramet": [3, 134, 137, 162], "meta": 3, "model": [3, 6, 8, 9, 19, 38, 41, 47, 48, 50, 67, 69, 79, 83, 84, 88, 93, 94, 110, 120, 128, 130, 133, 134, 135, 141, 151, 153, 155, 166, 167, 170], "overfit": [3, 59, 64, 105], "predictor": 3, "regress": [3, 31, 133, 134, 138, 139, 140, 146, 159, 163, 177], "regressor": 3, "regular": [3, 47, 50, 134, 137], "penal": 3, "sampl": [3, 97, 98], "instanc": 3, "observ": 3, "supervis": 3, "target": [3, 83], "label": [3, 6], "annot": 3, "test": [3, 56, 82, 83, 104], "set": [3, 152], "train": [3, 56, 82, 83, 104], "fit": [3, 67, 83, 84, 88], "transform": 3, "underfit": [3, 59, 64, 105], "unsupervis": 3, "other": [3, 162], "notebook": [4, 76, 79, 82, 83, 139], "time": [4, 6, 13, 22, 33, 39, 58, 73, 171, 183], "tabl": [5, 166], "content": [5, 166], "conclud": [6, 7, 166], "remark": [6, 7, 166], "last": 6, "lesson": [6, 110], "goal": 6, "big": 6, "messag": [6, 133], "mooc": [6, 36], "1": [6, 75, 110], "machin": [6, 52, 166], "pipelin": [6, 72, 87, 90, 92, 93, 112, 166], "2": [6, 62, 110], "adapt": [6, 111], "complex": [6, 112], "3": [6, 110, 186], "specif": [6, 88], "go": [6, 14, 23, 34, 40, 60, 74, 172, 184], "further": [6, 14, 23, 34, 40, 60, 74, 172, 184], "more": [6, 88, 104], "about": [6, 121], "scikit": [6, 36, 67, 72, 83, 93, 112, 138, 140, 152], "we": [6, 93], "ar": 6, "an": [6, 87], "open": 6, "sourc": 6, "commun": 6, "topic": 6, "have": 6, "cover": 6, "studi": 6, "bring": 6, "valu": 6, "bigger": 6, "pictur": 6, "beyond": [6, 142], "evalu": [6, 79, 87, 88, 143, 153, 166], "matter": 6, "small": 6, "part": 6, "problem": [6, 164], "most": 6, "technic": 6, "craft": 6, "all": 6, "how": 6, "choic": [6, 20], "output": 6, "bias": 6, "versu": [6, 54, 57], "causal": 6, "societ": 6, "impact": [6, 137], "intuit": [8, 9, 38, 48, 50, 167, 170], "ensembl": [8, 9, 10, 11, 12, 120, 166], "bag": [8, 112], "boost": [9, 10, 111, 117, 118, 119], "base": [10, 87, 88, 167, 170], "method": [11, 12], "bootstrap": [11, 112], "tune": [12, 119, 134, 151, 153, 155, 166, 179, 181], "modul": [13, 22, 33, 39, 58, 73, 171, 183], "overview": [13, 22, 33, 39, 58, 73, 171, 183], "what": [13, 22, 33, 39, 58, 73, 171, 183], "you": [13, 22, 33, 39, 58, 73, 171, 183], "befor": [13, 22, 33, 39, 58, 73, 171, 183], "get": [13, 22, 33, 39, 58, 73, 152, 171, 183], "start": [13, 22, 33, 39, 58, 73, 171, 183], "object": [13, 22, 33, 39, 58, 73, 171, 183], "schedul": [13, 22, 33, 39, 58, 73, 171, 183], "take": [14, 23, 34, 40, 60, 74, 110, 133, 172, 184], "awai": [14, 23, 34, 40, 60, 74, 110, 133, 172, 184], "wrap": [14, 18, 23, 29, 34, 40, 49, 60, 62, 74, 75, 172, 178, 184, 186], "up": [14, 18, 23, 29, 34, 40, 49, 60, 62, 74, 75, 118, 172, 178, 184, 186], "To": [14, 23, 34, 40, 60, 74, 172, 184], "quiz": [15, 16, 17, 18, 24, 25, 26, 27, 28, 29, 35, 37, 42, 43, 44, 45, 46, 49, 51, 53, 55, 62, 63, 66, 68, 71, 75, 173, 174, 175, 176, 178, 180, 182, 186], "m6": [15, 16, 17, 113, 114, 115, 116, 122, 123, 124, 125], "01": [15, 24, 42, 51, 63, 66, 77, 78, 95, 96, 100, 101, 113, 122, 126, 129, 130, 135, 149, 156, 160, 164, 173, 182], "question": [15, 16, 17, 18, 24, 25, 26, 27, 28, 29, 35, 37, 42, 43, 44, 45, 46, 49, 51, 53, 55, 62, 63, 66, 68, 71, 75, 173, 174, 175, 176, 178, 180, 182, 186], "02": [16, 25, 43, 55, 68, 80, 85, 114, 123, 131, 136, 144, 147, 150, 157, 161, 165, 174, 180], "03": [17, 26, 44, 53, 71, 81, 86, 115, 124, 132, 137, 145, 148, 175], "6": 18, "compar": [19, 56, 94], "simpl": [19, 94], "baselin": [19, 94, 143], "nest": [21, 99], "m7": [24, 25, 26, 27, 28, 96, 101, 144, 145, 147, 148], "04": [27, 45, 89, 91, 116, 125, 176], "05": [28, 46, 90, 92], "7": 29, "metric": [30, 31, 143], "caveat": 32, "select": [32, 87, 88, 127, 128, 166], "introduct": 36, "present": [36, 110], "welcom": 36, "follow": 36, "prerequisit": [36, 130, 135], "materi": 36, "social": 36, "network": 36, "linear": [38, 41, 47, 48, 50, 110, 133, 134, 137, 138, 139, 140, 141, 142, 166], "non": [41, 103, 133, 137, 139], "engin": [41, 133, 137, 139], "m4": [42, 43, 44, 45, 46, 130, 131, 132, 135, 136, 137], "4": 49, "intro": 51, "introduc": 52, "concept": [52, 166], "m2": [53, 55, 63, 95, 100], "bia": [54, 57], "varianc": [54, 57], "error": [56, 104], "trade": 57, "off": 57, "curv": [61, 98, 105], "tabular": 65, "explor": 65, "m1": [66, 68, 71, 77, 78, 80, 81, 85, 86, 89, 90, 91, 92], "numer": [67, 82, 84, 88, 90, 92], "handl": 70, "categor": [70, 87, 88, 90, 92], "visual": [72, 76, 93], "jupyt": [72, 93], "first": [76, 83, 93], "look": [76, 121], "our": [76, 87, 151, 153, 155], "load": [76, 82, 83, 93, 130, 135, 153], "column": [76, 88], "inspect": [76, 110], "creat": [76, 93, 162], "decis": [76, 117, 119, 137, 158, 162, 163, 166, 168, 169, 177], "rule": 76, "hand": 76, "recap": [76, 79, 82, 83, 139], "exercis": [77, 78, 80, 81, 85, 86, 89, 90, 91, 92, 95, 96, 100, 101, 113, 114, 115, 116, 122, 123, 124, 125, 126, 129, 130, 131, 132, 135, 136, 137, 144, 145, 147, 148, 149, 150, 156, 157, 160, 161, 164, 165], "solut": [78, 85, 86, 91, 92, 100, 101, 122, 123, 124, 125, 129, 135, 136, 137, 147, 148, 156, 157, 164, 165], "prepar": [79, 84], "need": 79, "work": 82, "entir": 82, "identifi": [82, 87], "split": [82, 83], "panda": 83, "separ": [83, 142], "make": 83, "preprocess": 84, "encod": [87, 90, 92], "type": [87, 88], "strategi": 87, "categori": [87, 90, 92], "ordin": 87, "nomin": 87, "without": [87, 140, 153], "assum": 87, "ani": 87, "order": 87, "choos": 87, "togeth": 88, "dispatch": 88, "processor": 88, "power": 88, "refer": [90, 92], "scale": [90, 92, 110, 134], "integ": [90, 92], "code": [90, 92], "One": [90, 92], "hot": [90, 92], "analysi": [92, 154, 185], "Then": 93, "final": 93, "score": 93, "group": 97, "effect": [98, 134, 162], "size": 98, "summari": [98, 104, 105, 133], "stratif": 102, "i": 103, "d": 103, "framework": 104, "vs": [104, 105], "stabil": 104, "detail": [104, 121], "regard": 104, "cross_valid": 104, "am": 106, "hous": [106, 109], "bike": 107, "ride": 107, "blood": 108, "transfus": 108, "california": 109, "import": [110, 162], "0": 110, "sign": 110, "coeffici": 110, "A": [110, 121], "surpris": 110, "associ": 110, "check": 110, "spars": 110, "lasso": 110, "randomforest": 110, "feature_importances_": 110, "permut": 110, "discuss": 110, "adaboost": 111, "resampl": 112, "aggreg": 112, "gradient": [117, 118, 119], "tree": [117, 119, 158, 162, 163, 166, 167, 168, 169, 170, 177], "gbdt": 117, "speed": 118, "random": [119, 121, 155], "forest": [119, 121], "histogram": 119, "introductori": 120, "exampl": 120, "default": 121, "benefit": 127, "limit": 128, "definit": [130, 135], "logist": 133, "addit": 133, "interact": 133, "multi": [133, 164], "step": 133, "influenc": 137, "c": 137, "boundari": 137, "weight": 137, "probabl": [141, 143, 164], "accuraci": 143, "confus": 143, "deriv": 143, "issu": 143, "class": [143, 164], "imbal": 143, "differ": 143, "threshold": 143, "m3": [149, 150, 156, 157, 180, 182], "grid": 151, "search": [151, 154, 155, 185], "With": 153, "result": [154, 185], "build": 158, "penguin": 159, "m5": [160, 161, 164, 165, 173, 174, 175, 176], "helper": 162, "function": 162, "max_depth": 162, "best": 166, "appendix": 166, "interpret": 166, "5": 178, "autom": 179, "manual": 181}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 6, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx": 56}})